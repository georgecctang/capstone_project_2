{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference Dates\n",
    "\n",
    "Num Training Weeks = 4  \n",
    "Num Test/Val Days = 15\n",
    "\n",
    "- Train: 5/30/2017 (Tues), 6/6/2017,6/13/2017,6/20/2017  \n",
    "- Val: 7/11/2017 (Tues) - 7/25/2017 (Wed)  \n",
    "- Test: 8/1/2017 (Tues)  - 8/15/2017 (Wed)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from datetime import date, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import LSTM\n",
    "from keras import callbacks\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\n",
    "    '../input/train.csv', usecols=[1, 2, 3, 4, 5],\n",
    "    dtype={'onpromotion': bool},\n",
    "    converters={'unit_sales': lambda u: np.log1p(\n",
    "        float(u)) if float(u) > 0 else 0},\n",
    "    parse_dates=[\"date\"],\n",
    "    skiprows=range(1, 66458909)  # 2016-01-01\n",
    ")\n",
    "\n",
    "df_test = pd.read_csv(\n",
    "    \"../input/test.csv\", usecols=[0, 1, 2, 3, 4],\n",
    "    dtype={'onpromotion': bool},\n",
    "    parse_dates=[\"date\"]  # , date_parser=parser\n",
    ").set_index(\n",
    "    ['store_nbr', 'item_nbr', 'date']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = pd.read_csv(\n",
    "    \"../input/items.csv\",\n",
    ").set_index(\"item_nbr\")\n",
    "\n",
    "stores = pd.read_csv(\n",
    "    \"../input/stores.csv\",\n",
    ").set_index(\"store_nbr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family</th>\n",
       "      <th>class</th>\n",
       "      <th>perishable</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_nbr</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96995</th>\n",
       "      <td>GROCERY I</td>\n",
       "      <td>1093</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99197</th>\n",
       "      <td>GROCERY I</td>\n",
       "      <td>1067</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103501</th>\n",
       "      <td>CLEANING</td>\n",
       "      <td>3008</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103520</th>\n",
       "      <td>GROCERY I</td>\n",
       "      <td>1028</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103665</th>\n",
       "      <td>BREAD/BAKERY</td>\n",
       "      <td>2712</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                family  class  perishable\n",
       "item_nbr                                 \n",
       "96995        GROCERY I   1093           0\n",
       "99197        GROCERY I   1067           0\n",
       "103501        CLEANING   3008           0\n",
       "103520       GROCERY I   1028           0\n",
       "103665    BREAD/BAKERY   2712           1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>type</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_nbr</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Santo Domingo</td>\n",
       "      <td>Santo Domingo de los Tsachilas</td>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    city                           state type  cluster\n",
       "store_nbr                                                             \n",
       "1                  Quito                       Pichincha    D       13\n",
       "2                  Quito                       Pichincha    D       13\n",
       "3                  Quito                       Pichincha    D        8\n",
       "4                  Quito                       Pichincha    D        9\n",
       "5          Santo Domingo  Santo Domingo de los Tsachilas    D        4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147226"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2017 = df_train.loc[df_train.date>=pd.datetime(2017,1,1)]\n",
    "del df_train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>unit_sales</th>\n",
       "      <th>onpromotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35229871</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>25</td>\n",
       "      <td>99197</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35229872</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>25</td>\n",
       "      <td>103665</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35229873</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>25</td>\n",
       "      <td>105574</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35229874</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>25</td>\n",
       "      <td>105857</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35229875</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>25</td>\n",
       "      <td>106716</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               date  store_nbr  item_nbr  unit_sales  onpromotion\n",
       "35229871 2017-01-01         25     99197    0.693147        False\n",
       "35229872 2017-01-01         25    103665    2.079442        False\n",
       "35229873 2017-01-01         25    105574    0.693147        False\n",
       "35229874 2017-01-01         25    105857    1.609438        False\n",
       "35229875 2017-01-01         25    106716    1.098612        False"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2017.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "promo_2017_train = df_2017.set_index(\n",
    "    [\"store_nbr\", \"item_nbr\", \"date\"])[[\"onpromotion\"]].unstack(\n",
    "        level=-1).fillna(False)\n",
    "promo_2017_train.columns = promo_2017_train.columns.get_level_values(1)\n",
    "promo_2017_test = df_test[[\"onpromotion\"]].unstack(level=-1).fillna(False)\n",
    "promo_2017_test.columns = promo_2017_test.columns.get_level_values(1)\n",
    "promo_2017_test = promo_2017_test.reindex(promo_2017_train.index).fillna(False)\n",
    "promo_2017 = pd.concat([promo_2017_train, promo_2017_test], axis=1)\n",
    "del promo_2017_test, promo_2017_train, df_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>2017-01-01</th>\n",
       "      <th>2017-01-02</th>\n",
       "      <th>2017-01-03</th>\n",
       "      <th>2017-01-04</th>\n",
       "      <th>2017-01-05</th>\n",
       "      <th>2017-01-06</th>\n",
       "      <th>2017-01-07</th>\n",
       "      <th>2017-01-08</th>\n",
       "      <th>2017-01-09</th>\n",
       "      <th>2017-01-10</th>\n",
       "      <th>...</th>\n",
       "      <th>2017-08-22</th>\n",
       "      <th>2017-08-23</th>\n",
       "      <th>2017-08-24</th>\n",
       "      <th>2017-08-25</th>\n",
       "      <th>2017-08-26</th>\n",
       "      <th>2017-08-27</th>\n",
       "      <th>2017-08-28</th>\n",
       "      <th>2017-08-29</th>\n",
       "      <th>2017-08-30</th>\n",
       "      <th>2017-08-31</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>96995</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99197</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103520</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103665</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105574</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 243 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "date                2017-01-01  2017-01-02  2017-01-03  2017-01-04  \\\n",
       "store_nbr item_nbr                                                   \n",
       "1         96995          False       False       False       False   \n",
       "          99197          False       False       False       False   \n",
       "          103520         False       False       False       False   \n",
       "          103665         False       False       False       False   \n",
       "          105574         False       False        True       False   \n",
       "\n",
       "date                2017-01-05  2017-01-06  2017-01-07  2017-01-08  \\\n",
       "store_nbr item_nbr                                                   \n",
       "1         96995          False       False       False       False   \n",
       "          99197          False       False       False       False   \n",
       "          103520         False       False       False       False   \n",
       "          103665         False       False       False       False   \n",
       "          105574         False        True       False       False   \n",
       "\n",
       "date                2017-01-09  2017-01-10  ...  2017-08-22  2017-08-23  \\\n",
       "store_nbr item_nbr                          ...                           \n",
       "1         96995          False       False  ...       False       False   \n",
       "          99197          False       False  ...       False       False   \n",
       "          103520         False       False  ...       False       False   \n",
       "          103665         False       False  ...       False       False   \n",
       "          105574         False       False  ...       False       False   \n",
       "\n",
       "date                2017-08-24  2017-08-25  2017-08-26  2017-08-27  \\\n",
       "store_nbr item_nbr                                                   \n",
       "1         96995          False       False       False       False   \n",
       "          99197          False       False       False       False   \n",
       "          103520         False       False       False       False   \n",
       "          103665         False       False       False       False   \n",
       "          105574         False       False       False       False   \n",
       "\n",
       "date                2017-08-28  2017-08-29  2017-08-30  2017-08-31  \n",
       "store_nbr item_nbr                                                  \n",
       "1         96995          False       False       False       False  \n",
       "          99197          False       False       False       False  \n",
       "          103520         False       False       False       False  \n",
       "          103665         False       False       False       False  \n",
       "          105574         False       False       False       False  \n",
       "\n",
       "[5 rows x 243 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "promo_2017.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2017 = df_2017.set_index(\n",
    "    [\"store_nbr\", \"item_nbr\", \"date\"])[[\"unit_sales\"]].unstack(\n",
    "        level=-1).fillna(0)\n",
    "df_2017.columns = df_2017.columns.get_level_values(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2017_index = df_2017.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2017.to_csv('../derived_datasets/df_2017_index.csv', columns = [], header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>2017-01-01</th>\n",
       "      <th>2017-01-02</th>\n",
       "      <th>2017-01-03</th>\n",
       "      <th>2017-01-04</th>\n",
       "      <th>2017-01-05</th>\n",
       "      <th>2017-01-06</th>\n",
       "      <th>2017-01-07</th>\n",
       "      <th>2017-01-08</th>\n",
       "      <th>2017-01-09</th>\n",
       "      <th>2017-01-10</th>\n",
       "      <th>...</th>\n",
       "      <th>2017-08-06</th>\n",
       "      <th>2017-08-07</th>\n",
       "      <th>2017-08-08</th>\n",
       "      <th>2017-08-09</th>\n",
       "      <th>2017-08-10</th>\n",
       "      <th>2017-08-11</th>\n",
       "      <th>2017-08-12</th>\n",
       "      <th>2017-08-13</th>\n",
       "      <th>2017-08-14</th>\n",
       "      <th>2017-08-15</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>96995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99197</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103520</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103665</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>...</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105574</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.609438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 227 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "date                2017-01-01  2017-01-02  2017-01-03  2017-01-04  \\\n",
       "store_nbr item_nbr                                                   \n",
       "1         96995            0.0    0.000000    0.000000    0.000000   \n",
       "          99197            0.0    0.000000    1.386294    0.693147   \n",
       "          103520           0.0    0.693147    1.098612    0.000000   \n",
       "          103665           0.0    0.000000    0.000000    1.386294   \n",
       "          105574           0.0    0.000000    1.791759    2.564949   \n",
       "\n",
       "date                2017-01-05  2017-01-06  2017-01-07  2017-01-08  \\\n",
       "store_nbr item_nbr                                                   \n",
       "1         96995       0.000000    0.000000    0.000000    0.000000   \n",
       "          99197       0.693147    0.693147    1.098612    0.000000   \n",
       "          103520      1.098612    1.386294    0.693147    0.000000   \n",
       "          103665      1.098612    1.098612    0.693147    1.098612   \n",
       "          105574      2.302585    1.945910    1.609438    1.098612   \n",
       "\n",
       "date                2017-01-09  2017-01-10  ...  2017-08-06  2017-08-07  \\\n",
       "store_nbr item_nbr                          ...                           \n",
       "1         96995       0.000000    0.000000  ...    1.098612    1.098612   \n",
       "          99197       0.000000    0.693147  ...    0.000000    1.098612   \n",
       "          103520      0.693147    0.693147  ...    0.000000    0.000000   \n",
       "          103665      0.000000    2.079442  ...    0.693147    1.098612   \n",
       "          105574      1.386294    2.302585  ...    0.000000    1.791759   \n",
       "\n",
       "date                2017-08-08  2017-08-09  2017-08-10  2017-08-11  \\\n",
       "store_nbr item_nbr                                                   \n",
       "1         96995       0.000000    0.000000    0.693147    0.000000   \n",
       "          99197       0.000000    1.098612    0.000000    0.000000   \n",
       "          103520      1.386294    0.000000    1.386294    0.693147   \n",
       "          103665      0.000000    2.079442    2.302585    1.098612   \n",
       "          105574      2.079442    1.945910    2.397895    1.791759   \n",
       "\n",
       "date                2017-08-12  2017-08-13  2017-08-14  2017-08-15  \n",
       "store_nbr item_nbr                                                  \n",
       "1         96995       0.000000    0.000000    0.000000    0.000000  \n",
       "          99197       0.000000    0.000000    0.000000    0.000000  \n",
       "          103520      0.693147    0.693147    0.000000    0.000000  \n",
       "          103665      0.000000    0.000000    0.693147    0.693147  \n",
       "          105574      1.791759    0.000000    1.386294    1.609438  \n",
       "\n",
       "[5 rows x 227 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2017.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "items['class'] = items['class'].astype('category')\n",
    "items = pd.get_dummies(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>perishable</th>\n",
       "      <th>family_AUTOMOTIVE</th>\n",
       "      <th>family_BABY CARE</th>\n",
       "      <th>family_BEAUTY</th>\n",
       "      <th>family_BEVERAGES</th>\n",
       "      <th>family_BOOKS</th>\n",
       "      <th>family_BREAD/BAKERY</th>\n",
       "      <th>family_CELEBRATION</th>\n",
       "      <th>family_CLEANING</th>\n",
       "      <th>family_DAIRY</th>\n",
       "      <th>...</th>\n",
       "      <th>class_6920</th>\n",
       "      <th>class_6922</th>\n",
       "      <th>class_6924</th>\n",
       "      <th>class_6936</th>\n",
       "      <th>class_6954</th>\n",
       "      <th>class_6960</th>\n",
       "      <th>class_7002</th>\n",
       "      <th>class_7016</th>\n",
       "      <th>class_7034</th>\n",
       "      <th>class_7780</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_nbr</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99197</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103501</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103520</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103665</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          perishable  family_AUTOMOTIVE  family_BABY CARE  family_BEAUTY  \\\n",
       "item_nbr                                                                   \n",
       "96995              0                  0                 0              0   \n",
       "99197              0                  0                 0              0   \n",
       "103501             0                  0                 0              0   \n",
       "103520             0                  0                 0              0   \n",
       "103665             1                  0                 0              0   \n",
       "\n",
       "          family_BEVERAGES  family_BOOKS  family_BREAD/BAKERY  \\\n",
       "item_nbr                                                        \n",
       "96995                    0             0                    0   \n",
       "99197                    0             0                    0   \n",
       "103501                   0             0                    0   \n",
       "103520                   0             0                    0   \n",
       "103665                   0             0                    1   \n",
       "\n",
       "          family_CELEBRATION  family_CLEANING  family_DAIRY  ...  class_6920  \\\n",
       "item_nbr                                                     ...               \n",
       "96995                      0                0             0  ...           0   \n",
       "99197                      0                0             0  ...           0   \n",
       "103501                     0                1             0  ...           0   \n",
       "103520                     0                0             0  ...           0   \n",
       "103665                     0                0             0  ...           0   \n",
       "\n",
       "          class_6922  class_6924  class_6936  class_6954  class_6960  \\\n",
       "item_nbr                                                               \n",
       "96995              0           0           0           0           0   \n",
       "99197              0           0           0           0           0   \n",
       "103501             0           0           0           0           0   \n",
       "103520             0           0           0           0           0   \n",
       "103665             0           0           0           0           0   \n",
       "\n",
       "          class_7002  class_7016  class_7034  class_7780  \n",
       "item_nbr                                                  \n",
       "96995              0           0           0           0  \n",
       "99197              0           0           0           0  \n",
       "103501             0           0           0           0  \n",
       "103520             0           0           0           0  \n",
       "103665             0           0           0           0  \n",
       "\n",
       "[5 rows x 371 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = items.reindex(df_2017.index.get_level_values(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(167515, 371)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>type</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_nbr</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Santo Domingo</td>\n",
       "      <td>Santo Domingo de los Tsachilas</td>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    city                           state type  cluster\n",
       "store_nbr                                                             \n",
       "1                  Quito                       Pichincha    D       13\n",
       "2                  Quito                       Pichincha    D       13\n",
       "3                  Quito                       Pichincha    D        8\n",
       "4                  Quito                       Pichincha    D        9\n",
       "5          Santo Domingo  Santo Domingo de los Tsachilas    D        4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores['cluster'] = stores.cluster.astype('category')\n",
    "stores = pd.get_dummies(stores)\n",
    "stores = stores.reindex(df_2017.index.get_level_values(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_Ambato</th>\n",
       "      <th>city_Babahoyo</th>\n",
       "      <th>city_Cayambe</th>\n",
       "      <th>city_Cuenca</th>\n",
       "      <th>city_Daule</th>\n",
       "      <th>city_El Carmen</th>\n",
       "      <th>city_Esmeraldas</th>\n",
       "      <th>city_Guaranda</th>\n",
       "      <th>city_Guayaquil</th>\n",
       "      <th>city_Ibarra</th>\n",
       "      <th>...</th>\n",
       "      <th>cluster_8</th>\n",
       "      <th>cluster_9</th>\n",
       "      <th>cluster_10</th>\n",
       "      <th>cluster_11</th>\n",
       "      <th>cluster_12</th>\n",
       "      <th>cluster_13</th>\n",
       "      <th>cluster_14</th>\n",
       "      <th>cluster_15</th>\n",
       "      <th>cluster_16</th>\n",
       "      <th>cluster_17</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_nbr</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           city_Ambato  city_Babahoyo  city_Cayambe  city_Cuenca  city_Daule  \\\n",
       "store_nbr                                                                      \n",
       "1                    0              0             0            0           0   \n",
       "1                    0              0             0            0           0   \n",
       "1                    0              0             0            0           0   \n",
       "1                    0              0             0            0           0   \n",
       "1                    0              0             0            0           0   \n",
       "\n",
       "           city_El Carmen  city_Esmeraldas  city_Guaranda  city_Guayaquil  \\\n",
       "store_nbr                                                                   \n",
       "1                       0                0              0               0   \n",
       "1                       0                0              0               0   \n",
       "1                       0                0              0               0   \n",
       "1                       0                0              0               0   \n",
       "1                       0                0              0               0   \n",
       "\n",
       "           city_Ibarra  ...  cluster_8  cluster_9  cluster_10  cluster_11  \\\n",
       "store_nbr               ...                                                 \n",
       "1                    0  ...          0          0           0           0   \n",
       "1                    0  ...          0          0           0           0   \n",
       "1                    0  ...          0          0           0           0   \n",
       "1                    0  ...          0          0           0           0   \n",
       "1                    0  ...          0          0           0           0   \n",
       "\n",
       "           cluster_12  cluster_13  cluster_14  cluster_15  cluster_16  \\\n",
       "store_nbr                                                               \n",
       "1                   0           1           0           0           0   \n",
       "1                   0           1           0           0           0   \n",
       "1                   0           1           0           0           0   \n",
       "1                   0           1           0           0           0   \n",
       "1                   0           1           0           0           0   \n",
       "\n",
       "           cluster_17  \n",
       "store_nbr              \n",
       "1                   0  \n",
       "1                   0  \n",
       "1                   0  \n",
       "1                   0  \n",
       "1                   0  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(167515, 60)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sum of sales for each item across all stores for each day\n",
    "#df_2017_item = df_2017.groupby('item_nbr')[df_2017.columns].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sum of promotion for each item across all stores for each day\n",
    "#promo_2017_item = promo_2017.groupby('item_nbr')[promo_2017.columns].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum of sales in each class (multiple items) for each store for each day \n",
    "# df_2017_store_class = df_2017.reset_index()\n",
    "# df_2017_store_class['class'] = items['class'].values\n",
    "# df_2017_store_class_index = df_2017_store_class[['class', 'store_nbr']]\n",
    "# df_2017_store_class = df_2017_store_class.groupby(['class', 'store_nbr'])[df_2017.columns].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_2017_store_class_index.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_2017_store_class.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_2017_store_class.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum of promotions in each class (multiple items) for each store for each day \n",
    "\n",
    "# df_2017_promo_store_class = promo_2017.reset_index()\n",
    "# df_2017_promo_store_class['class'] = items['class'].values\n",
    "# df_2017_promo_store_class_index = df_2017_promo_store_class[['class', 'store_nbr']]\n",
    "# df_2017_promo_store_class = df_2017_promo_store_class.groupby(['class', 'store_nbr'])[promo_2017.columns].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timespan(df, dt, minus, periods, freq='D'):\n",
    "    return df[pd.date_range(dt - timedelta(days=minus), periods=periods, freq=freq)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(df, promo_df, t2017, is_train=True, name_prefix=None):\n",
    "    X = {\n",
    "        \"promo_7_2017\": get_timespan(promo_df, t2017, 7, 7).sum(axis=1).values,\n",
    "        \"promo_14_2017\": get_timespan(promo_df, t2017, 14, 14).sum(axis=1).values,\n",
    "        \"promo_30_2017\": get_timespan(promo_df, t2017, 30, 30).sum(axis=1).values,\n",
    "        \"promo_3_2017_aft\": get_timespan(promo_df, t2017 + timedelta(days=15), 14, 3).sum(axis=1).values,\n",
    "        \"promo_7_2017_aft\": get_timespan(promo_df, t2017 + timedelta(days=15), 14, 7).sum(axis=1).values,\n",
    "        \"promo_14_2017_aft\": get_timespan(promo_df, t2017 + timedelta(days=15), 14, 14).sum(axis=1).values,\n",
    "    }\n",
    "\n",
    "# Removed due to the presence of nan values \n",
    "#     for i in [3, 7, 14, 30]:\n",
    "#         tmp1 = get_timespan(df, t2017, i, i)\n",
    "#         tmp2 = (get_timespan(promo_df, t2017, i, i) > 0) * 1\n",
    "\n",
    "#         X['has_promo_mean_%s' % i] = (tmp1 * tmp2.replace(0, np.nan)).mean(axis=1).values\n",
    "#         X['no_promo_mean_%s' % i] = (tmp1 * (1 - tmp2).replace(0, np.nan)).mean(axis=1).values\n",
    "                \n",
    "        \n",
    "    for i in [3, 7, 14, 30]:\n",
    "        tmp = get_timespan(df, t2017, i, i)\n",
    "        X['diff_%s_mean' % i] = tmp.diff(axis=1).mean(axis=1).values\n",
    "        X['mean_%s' % i] = tmp.mean(axis=1).values\n",
    "        X['median_%s' % i] = tmp.median(axis=1).values\n",
    "        X['min_%s' % i] = tmp.min(axis=1).values\n",
    "        X['max_%s' % i] = tmp.max(axis=1).values\n",
    "        X['std_%s' % i] = tmp.std(axis=1).values\n",
    "\n",
    "    for i in [7, 14, 30]:\n",
    "        tmp = get_timespan(df, t2017, i, i)\n",
    "        X['has_sales_days_in_last_%s' % i] = (tmp > 0).sum(axis=1).values\n",
    "        X['last_has_sales_day_in_last_%s' % i] = i - ((tmp > 0) * np.arange(i)).max(axis=1).values\n",
    "        X['first_has_sales_day_in_last_%s' % i] = ((tmp > 0) * np.arange(i, 0, -1)).max(axis=1).values\n",
    "\n",
    "        tmp = get_timespan(promo_df, t2017, i, i)\n",
    "        X['has_promo_days_in_last_%s' % i] = (tmp > 0).sum(axis=1).values\n",
    "        X['last_has_promo_day_in_last_%s' % i] = i - ((tmp > 0) * np.arange(i)).max(axis=1).values\n",
    "        X['first_has_promo_day_in_last_%s' % i] = ((tmp > 0) * np.arange(i, 0, -1)).max(axis=1).values\n",
    "\n",
    "    tmp = get_timespan(promo_df, t2017 + timedelta(days=15), 14, 14)\n",
    "    X['has_promo_days_in_after_14_days'] = (tmp > 0).sum(axis=1).values\n",
    "    X['last_has_promo_day_in_after_14_days'] = i - ((tmp > 0) * np.arange(14)).max(axis=1).values\n",
    "    X['first_has_promo_day_in_after_14_days'] = ((tmp > 0) * np.arange(14, 0, -1)).max(axis=1).values\n",
    "\n",
    "    for i in range(1, 15):\n",
    "        X['day_%s_2017' % i] = get_timespan(df, t2017, i, 1).values.ravel()\n",
    "\n",
    "    for i in range(7):\n",
    "        X['mean_4_dow{}_2017'.format(i)] = get_timespan(df, t2017, 28-i, 4, freq='7D').mean(axis=1).values\n",
    "        X['mean_20_dow{}_2017'.format(i)] = get_timespan(df, t2017, 140-i, 20, freq='7D').mean(axis=1).values        \n",
    "        \n",
    "    for i in range(-14, 15):\n",
    "        X[\"promo_{}\".format(i)] = promo_df[t2017 + timedelta(days=i)].values.astype(np.uint8)\n",
    "\n",
    "    X = pd.DataFrame(X)\n",
    "\n",
    "    if is_train:\n",
    "        y = df[\n",
    "            pd.date_range(t2017, periods=15)\n",
    "        ].values\n",
    "        return X, y\n",
    "    if name_prefix is not None:\n",
    "        X.columns = ['%s_%s' % (name_prefix, c) for c in X.columns]\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:09<00:00,  2.28s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Preparing dataset...\")\n",
    "t2017 = date(2017, 5, 30)\n",
    "num_days = 4\n",
    "X_l, y_l = [], []\n",
    "for i in tqdm(range(num_days)):\n",
    "    delta = timedelta(days=7 * i)\n",
    "    X_tmp, y_tmp = prepare_dataset(df_2017, promo_2017, t2017 + delta)\n",
    "\n",
    "    X_tmp = pd.concat([X_tmp, items.reset_index(drop=True), stores.reset_index(drop=True)], axis=1)\n",
    "    X_l.append(X_tmp)\n",
    "    y_l.append(y_tmp)\n",
    "\n",
    "X_train = pd.concat(X_l, axis=0)\n",
    "y_train = np.concatenate(y_l, axis=0)\n",
    "\n",
    "del X_l, y_l\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, y_val = prepare_dataset(df_2017, promo_2017, date(2017, 7, 11))\n",
    "\n",
    "# X_val2 = prepare_dataset(df_2017_item, promo_2017_item, date(2017, 7, 26), is_train=False, name_prefix='item')\n",
    "# X_val2.index = df_2017_item.index\n",
    "# X_val2 = X_val2.reindex(df_2017.index.get_level_values(1)).reset_index(drop=True)\n",
    "\n",
    "# X_val3 = prepare_dataset(df_2017_store_class, df_2017_promo_store_class, date(2017, 7, 26), is_train=False, name_prefix='store_class')\n",
    "# X_val3.index = df_2017_store_class.index\n",
    "# X_val3 = X_val3.reindex(df_2017_store_class_index).reset_index(drop=True)\n",
    "\n",
    "X_val = pd.concat([X_val, items.reset_index(drop=True), stores.reset_index(drop=True)], axis=1)\n",
    "\n",
    "X_test, y_test = prepare_dataset(df_2017, promo_2017, date(2017, 8, 1))\n",
    "\n",
    "# X_test2 = prepare_dataset(df_2017_item, promo_2017_item, date(2017, 8, 16), is_train=False, name_prefix='item')\n",
    "# X_test2.index = df_2017_item.index\n",
    "# X_test2 = X_test2.reindex(df_2017.index.get_level_values(1)).reset_index(drop=True)\n",
    "\n",
    "# X_test3 = prepare_dataset(df_2017_store_class, df_2017_promo_store_class, date(2017, 8, 16), is_train=False, name_prefix='store_class')\n",
    "# X_test3.index = df_2017_store_class.index\n",
    "# X_test3 = X_test3.reindex(df_2017_store_class_index).reset_index(drop=True)\n",
    "\n",
    "X_test = pd.concat([X_test, items.reset_index(drop=True), stores.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# del X_test2, X_val2, df_2017_item, promo_2017_item, df_2017_store_class, df_2017_promo_store_class, df_2017_store_class_index\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_1005\n",
      "class_1328\n",
      "class_1334\n"
     ]
    }
   ],
   "source": [
    "for col in X_train.columns:\n",
    "    if X_train[col].nunique() == 1:\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#there are columns with unique values but will leave it here for simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((670060, 539), (670060, 15))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((167515, 539), (167515, 15))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((167515, 539), (167515, 15))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df_2017, promo_2017\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(pd.concat([X_train, X_val, X_test]))\n",
    "X_train[:] = scaler.transform(X_train)\n",
    "X_val[:] = scaler.transform(X_val)\n",
    "X_test[:] = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "X_val = X_val.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((670060, 539), (670060, 15))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((167515, 539), (167515, 15))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((167515, 539), (167515, 15))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Model 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "512 x 256 x 128 x 64 x 32 x 16 x 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, input_dim=X_train.shape[1]))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())\n",
    "#     model.add(Dropout(.2))\n",
    "\n",
    "    model.add(Dense(256, input_dim=X_train.shape[1]))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())\n",
    "#     model.add(Dropout(.1))\n",
    "\n",
    "    model.add(Dense(128, input_dim=X_train.shape[1]))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())\n",
    "#     model.add(Dropout(.05))\n",
    "#     model.add(Dropout(0.1))\n",
    "    \n",
    "    model.add(Dense(64))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())\n",
    "#     model.add(Dropout(.05))\n",
    "\n",
    "    model.add(Dense(32))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())\n",
    "#     model.add(Dropout(.05))\n",
    "\n",
    "    model.add(Dense(16))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())\n",
    "#     model.add(Dropout(.05))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Step 1\n",
      "==================================================\n",
      "Train on 670060 samples, validate on 167515 samples\n",
      "Epoch 1/2000\n",
      " - 32s - loss: 0.4553 - mse: 0.4288 - val_loss: 0.3796 - val_mse: 0.3796\n",
      "Epoch 2/2000\n",
      " - 30s - loss: 0.3426 - mse: 0.3235 - val_loss: 0.3309 - val_mse: 0.3309\n",
      "Epoch 3/2000\n",
      " - 31s - loss: 0.3294 - mse: 0.3114 - val_loss: 0.3239 - val_mse: 0.3239\n",
      "Epoch 4/2000\n",
      " - 30s - loss: 0.3214 - mse: 0.3040 - val_loss: 0.3190 - val_mse: 0.3190\n",
      "Epoch 5/2000\n",
      " - 31s - loss: 0.3162 - mse: 0.2992 - val_loss: 0.3219 - val_mse: 0.3219\n",
      "Epoch 6/2000\n",
      " - 30s - loss: 0.3115 - mse: 0.2948 - val_loss: 0.3186 - val_mse: 0.3186\n",
      "Epoch 7/2000\n",
      " - 31s - loss: 0.3081 - mse: 0.2917 - val_loss: 0.3200 - val_mse: 0.3200\n",
      "Epoch 8/2000\n",
      " - 30s - loss: 0.3050 - mse: 0.2888 - val_loss: 0.3220 - val_mse: 0.3220\n",
      "Epoch 9/2000\n",
      " - 31s - loss: 0.3016 - mse: 0.2856 - val_loss: 0.3229 - val_mse: 0.3229\n",
      "Epoch 10/2000\n",
      " - 30s - loss: 0.2982 - mse: 0.2825 - val_loss: 0.3247 - val_mse: 0.3247\n",
      "Epoch 11/2000\n",
      " - 30s - loss: 0.2959 - mse: 0.2804 - val_loss: 0.3237 - val_mse: 0.3237\n",
      "Epoch 12/2000\n",
      " - 30s - loss: 0.2926 - mse: 0.2773 - val_loss: 0.3281 - val_mse: 0.3281\n",
      "Epoch 13/2000\n",
      " - 31s - loss: 0.2898 - mse: 0.2746 - val_loss: 0.3264 - val_mse: 0.3264\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 14/2000\n",
      " - 31s - loss: 0.2721 - mse: 0.2583 - val_loss: 0.3255 - val_mse: 0.3255\n",
      "Epoch 15/2000\n",
      " - 31s - loss: 0.2640 - mse: 0.2508 - val_loss: 0.3284 - val_mse: 0.3284\n",
      "Epoch 16/2000\n",
      " - 30s - loss: 0.2600 - mse: 0.2471 - val_loss: 0.3295 - val_mse: 0.3295\n",
      "==================================================\n",
      "Step 2\n",
      "==================================================\n",
      "Train on 670060 samples, validate on 167515 samples\n",
      "Epoch 1/2000\n",
      " - 32s - loss: 0.5261 - mse: 0.4967 - val_loss: 0.4331 - val_mse: 0.4331\n",
      "Epoch 2/2000\n",
      " - 30s - loss: 0.3516 - mse: 0.3335 - val_loss: 0.3388 - val_mse: 0.3388\n",
      "Epoch 3/2000\n",
      " - 30s - loss: 0.3347 - mse: 0.3181 - val_loss: 0.3238 - val_mse: 0.3238\n",
      "Epoch 4/2000\n",
      " - 30s - loss: 0.3253 - mse: 0.3095 - val_loss: 0.3191 - val_mse: 0.3191\n",
      "Epoch 5/2000\n",
      " - 30s - loss: 0.3192 - mse: 0.3038 - val_loss: 0.3177 - val_mse: 0.3177\n",
      "Epoch 6/2000\n",
      " - 30s - loss: 0.3140 - mse: 0.2989 - val_loss: 0.3197 - val_mse: 0.3197\n",
      "Epoch 7/2000\n",
      " - 30s - loss: 0.3102 - mse: 0.2954 - val_loss: 0.3214 - val_mse: 0.3214\n",
      "Epoch 8/2000\n",
      " - 30s - loss: 0.3065 - mse: 0.2920 - val_loss: 0.3211 - val_mse: 0.3211\n",
      "Epoch 9/2000\n",
      " - 30s - loss: 0.3034 - mse: 0.2890 - val_loss: 0.3220 - val_mse: 0.3220\n",
      "Epoch 10/2000\n",
      " - 30s - loss: 0.3003 - mse: 0.2861 - val_loss: 0.3251 - val_mse: 0.3251\n",
      "Epoch 11/2000\n",
      " - 30s - loss: 0.2976 - mse: 0.2835 - val_loss: 0.3240 - val_mse: 0.3240\n",
      "Epoch 12/2000\n",
      " - 30s - loss: 0.2946 - mse: 0.2807 - val_loss: 0.3294 - val_mse: 0.3294\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 13/2000\n",
      " - 30s - loss: 0.2791 - mse: 0.2664 - val_loss: 0.3233 - val_mse: 0.3233\n",
      "Epoch 14/2000\n",
      " - 30s - loss: 0.2722 - mse: 0.2599 - val_loss: 0.3253 - val_mse: 0.3253\n",
      "Epoch 15/2000\n",
      " - 30s - loss: 0.2692 - mse: 0.2571 - val_loss: 0.3272 - val_mse: 0.3272\n",
      "==================================================\n",
      "Step 3\n",
      "==================================================\n",
      "Train on 670060 samples, validate on 167515 samples\n",
      "Epoch 1/2000\n",
      " - 32s - loss: 0.4663 - mse: 0.4402 - val_loss: 0.3843 - val_mse: 0.3843\n",
      "Epoch 2/2000\n",
      " - 30s - loss: 0.3656 - mse: 0.3455 - val_loss: 0.3471 - val_mse: 0.3471\n",
      "Epoch 3/2000\n",
      " - 30s - loss: 0.3540 - mse: 0.3347 - val_loss: 0.3438 - val_mse: 0.3438\n",
      "Epoch 4/2000\n",
      " - 30s - loss: 0.3466 - mse: 0.3278 - val_loss: 0.3440 - val_mse: 0.3440\n",
      "Epoch 5/2000\n",
      " - 30s - loss: 0.3407 - mse: 0.3223 - val_loss: 0.3434 - val_mse: 0.3434\n",
      "Epoch 6/2000\n",
      " - 30s - loss: 0.3363 - mse: 0.3182 - val_loss: 0.3465 - val_mse: 0.3465\n",
      "Epoch 7/2000\n",
      " - 31s - loss: 0.3322 - mse: 0.3144 - val_loss: 0.3498 - val_mse: 0.3498\n",
      "Epoch 8/2000\n",
      " - 30s - loss: 0.3287 - mse: 0.3111 - val_loss: 0.3532 - val_mse: 0.3532\n",
      "Epoch 9/2000\n",
      " - 30s - loss: 0.3255 - mse: 0.3081 - val_loss: 0.3524 - val_mse: 0.3524\n",
      "Epoch 10/2000\n",
      " - 30s - loss: 0.3217 - mse: 0.3046 - val_loss: 0.3521 - val_mse: 0.3521\n",
      "Epoch 11/2000\n",
      " - 30s - loss: 0.3185 - mse: 0.3017 - val_loss: 0.3534 - val_mse: 0.3534\n",
      "Epoch 12/2000\n",
      " - 31s - loss: 0.3158 - mse: 0.2992 - val_loss: 0.3573 - val_mse: 0.3573\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 13/2000\n",
      " - 31s - loss: 0.2978 - mse: 0.2825 - val_loss: 0.3541 - val_mse: 0.3541\n",
      "Epoch 14/2000\n",
      " - 31s - loss: 0.2890 - mse: 0.2744 - val_loss: 0.3568 - val_mse: 0.3568\n",
      "Epoch 15/2000\n",
      " - 30s - loss: 0.2848 - mse: 0.2704 - val_loss: 0.3593 - val_mse: 0.3593\n",
      "==================================================\n",
      "Step 4\n",
      "==================================================\n",
      "Train on 670060 samples, validate on 167515 samples\n",
      "Epoch 1/2000\n",
      " - 32s - loss: 0.5080 - mse: 0.4794 - val_loss: 0.4340 - val_mse: 0.4340\n",
      "Epoch 2/2000\n",
      " - 30s - loss: 0.3711 - mse: 0.3519 - val_loss: 0.3602 - val_mse: 0.3602\n",
      "Epoch 3/2000\n",
      " - 30s - loss: 0.3554 - mse: 0.3374 - val_loss: 0.3473 - val_mse: 0.3473\n",
      "Epoch 4/2000\n",
      " - 31s - loss: 0.3465 - mse: 0.3292 - val_loss: 0.3440 - val_mse: 0.3440\n",
      "Epoch 5/2000\n",
      " - 30s - loss: 0.3395 - mse: 0.3227 - val_loss: 0.3459 - val_mse: 0.3459\n",
      "Epoch 6/2000\n",
      " - 30s - loss: 0.3346 - mse: 0.3180 - val_loss: 0.3452 - val_mse: 0.3452\n",
      "Epoch 7/2000\n",
      " - 30s - loss: 0.3305 - mse: 0.3142 - val_loss: 0.3487 - val_mse: 0.3487\n",
      "Epoch 8/2000\n",
      " - 30s - loss: 0.3263 - mse: 0.3103 - val_loss: 0.3480 - val_mse: 0.3480\n",
      "Epoch 9/2000\n",
      " - 30s - loss: 0.3228 - mse: 0.3070 - val_loss: 0.3499 - val_mse: 0.3499\n",
      "Epoch 10/2000\n",
      " - 30s - loss: 0.3196 - mse: 0.3040 - val_loss: 0.3542 - val_mse: 0.3542\n",
      "Epoch 11/2000\n",
      " - 30s - loss: 0.3161 - mse: 0.3007 - val_loss: 0.3548 - val_mse: 0.3548\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 12/2000\n",
      " - 30s - loss: 0.2994 - mse: 0.2852 - val_loss: 0.3485 - val_mse: 0.3485\n",
      "Epoch 13/2000\n",
      " - 30s - loss: 0.2921 - mse: 0.2783 - val_loss: 0.3496 - val_mse: 0.3496\n",
      "Epoch 14/2000\n",
      " - 30s - loss: 0.2886 - mse: 0.2751 - val_loss: 0.3515 - val_mse: 0.3515\n",
      "==================================================\n",
      "Step 5\n",
      "==================================================\n",
      "Train on 670060 samples, validate on 167515 samples\n",
      "Epoch 1/2000\n",
      " - 32s - loss: 0.5554 - mse: 0.5241 - val_loss: 0.4280 - val_mse: 0.4280\n",
      "Epoch 2/2000\n",
      " - 30s - loss: 0.3903 - mse: 0.3692 - val_loss: 0.3799 - val_mse: 0.3799\n",
      "Epoch 3/2000\n",
      " - 30s - loss: 0.3755 - mse: 0.3554 - val_loss: 0.3707 - val_mse: 0.3707\n",
      "Epoch 4/2000\n",
      " - 30s - loss: 0.3665 - mse: 0.3471 - val_loss: 0.3678 - val_mse: 0.3678\n",
      "Epoch 5/2000\n",
      " - 31s - loss: 0.3595 - mse: 0.3406 - val_loss: 0.3667 - val_mse: 0.3667\n",
      "Epoch 6/2000\n",
      " - 30s - loss: 0.3540 - mse: 0.3354 - val_loss: 0.3710 - val_mse: 0.3710\n",
      "Epoch 7/2000\n",
      " - 30s - loss: 0.3494 - mse: 0.3312 - val_loss: 0.3728 - val_mse: 0.3728\n",
      "Epoch 8/2000\n",
      " - 30s - loss: 0.3451 - mse: 0.3272 - val_loss: 0.3676 - val_mse: 0.3676\n",
      "Epoch 9/2000\n",
      " - 30s - loss: 0.3408 - mse: 0.3231 - val_loss: 0.3725 - val_mse: 0.3725\n",
      "Epoch 10/2000\n",
      " - 30s - loss: 0.3371 - mse: 0.3197 - val_loss: 0.3729 - val_mse: 0.3729\n",
      "Epoch 11/2000\n",
      " - 30s - loss: 0.3335 - mse: 0.3163 - val_loss: 0.3798 - val_mse: 0.3798\n",
      "Epoch 12/2000\n",
      " - 30s - loss: 0.3300 - mse: 0.3131 - val_loss: 0.3790 - val_mse: 0.3790\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 13/2000\n",
      " - 30s - loss: 0.3106 - mse: 0.2951 - val_loss: 0.3732 - val_mse: 0.3732\n",
      "Epoch 14/2000\n",
      " - 30s - loss: 0.3022 - mse: 0.2873 - val_loss: 0.3768 - val_mse: 0.3768\n",
      "Epoch 15/2000\n",
      " - 30s - loss: 0.2981 - mse: 0.2835 - val_loss: 0.3795 - val_mse: 0.3795\n",
      "==================================================\n",
      "Step 6\n",
      "==================================================\n",
      "Train on 670060 samples, validate on 167515 samples\n",
      "Epoch 1/2000\n",
      " - 32s - loss: 0.5605 - mse: 0.5296 - val_loss: 0.4434 - val_mse: 0.4434\n",
      "Epoch 2/2000\n",
      " - 31s - loss: 0.4042 - mse: 0.3822 - val_loss: 0.3917 - val_mse: 0.3917\n",
      "Epoch 3/2000\n",
      " - 31s - loss: 0.3876 - mse: 0.3669 - val_loss: 0.3805 - val_mse: 0.3805\n",
      "Epoch 4/2000\n",
      " - 30s - loss: 0.3778 - mse: 0.3579 - val_loss: 0.3791 - val_mse: 0.3791\n",
      "Epoch 5/2000\n",
      " - 31s - loss: 0.3702 - mse: 0.3508 - val_loss: 0.3780 - val_mse: 0.3780\n",
      "Epoch 6/2000\n",
      " - 31s - loss: 0.3641 - mse: 0.3452 - val_loss: 0.3783 - val_mse: 0.3783\n",
      "Epoch 7/2000\n",
      " - 31s - loss: 0.3589 - mse: 0.3403 - val_loss: 0.3804 - val_mse: 0.3804\n",
      "Epoch 8/2000\n",
      " - 31s - loss: 0.3543 - mse: 0.3361 - val_loss: 0.3790 - val_mse: 0.3790\n",
      "Epoch 9/2000\n",
      " - 30s - loss: 0.3502 - mse: 0.3322 - val_loss: 0.3834 - val_mse: 0.3834\n",
      "Epoch 10/2000\n",
      " - 30s - loss: 0.3469 - mse: 0.3292 - val_loss: 0.3913 - val_mse: 0.3913\n",
      "Epoch 11/2000\n",
      " - 31s - loss: 0.3429 - mse: 0.3255 - val_loss: 0.3819 - val_mse: 0.3819\n",
      "Epoch 12/2000\n",
      " - 30s - loss: 0.3393 - mse: 0.3221 - val_loss: 0.3907 - val_mse: 0.3907\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 13/2000\n",
      " - 30s - loss: 0.3200 - mse: 0.3043 - val_loss: 0.3838 - val_mse: 0.3838\n",
      "Epoch 14/2000\n",
      " - 30s - loss: 0.3119 - mse: 0.2967 - val_loss: 0.3850 - val_mse: 0.3850\n",
      "Epoch 15/2000\n",
      " - 31s - loss: 0.3081 - mse: 0.2933 - val_loss: 0.3872 - val_mse: 0.3872\n",
      "==================================================\n",
      "Step 7\n",
      "==================================================\n",
      "Train on 670060 samples, validate on 167515 samples\n",
      "Epoch 1/2000\n",
      " - 34s - loss: 0.5051 - mse: 0.4754 - val_loss: 0.4233 - val_mse: 0.4233\n",
      "Epoch 2/2000\n",
      " - 31s - loss: 0.3879 - mse: 0.3656 - val_loss: 0.3806 - val_mse: 0.3806\n",
      "Epoch 3/2000\n",
      " - 30s - loss: 0.3738 - mse: 0.3526 - val_loss: 0.3716 - val_mse: 0.3716\n",
      "Epoch 4/2000\n",
      " - 32s - loss: 0.3659 - mse: 0.3453 - val_loss: 0.3729 - val_mse: 0.3729\n",
      "Epoch 5/2000\n",
      " - 30s - loss: 0.3596 - mse: 0.3395 - val_loss: 0.3713 - val_mse: 0.3713\n",
      "Epoch 6/2000\n",
      " - 30s - loss: 0.3545 - mse: 0.3348 - val_loss: 0.3739 - val_mse: 0.3739\n",
      "Epoch 7/2000\n",
      " - 30s - loss: 0.3504 - mse: 0.3310 - val_loss: 0.3751 - val_mse: 0.3751\n",
      "Epoch 8/2000\n",
      " - 30s - loss: 0.3464 - mse: 0.3272 - val_loss: 0.3766 - val_mse: 0.3766\n",
      "Epoch 9/2000\n",
      " - 31s - loss: 0.3422 - mse: 0.3233 - val_loss: 0.3797 - val_mse: 0.3797\n",
      "Epoch 10/2000\n",
      " - 31s - loss: 0.3390 - mse: 0.3204 - val_loss: 0.3785 - val_mse: 0.3785\n",
      "Epoch 11/2000\n",
      " - 30s - loss: 0.3352 - mse: 0.3168 - val_loss: 0.3820 - val_mse: 0.3820\n",
      "Epoch 12/2000\n",
      " - 31s - loss: 0.3317 - mse: 0.3136 - val_loss: 0.3846 - val_mse: 0.3846\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 13/2000\n",
      " - 32s - loss: 0.3126 - mse: 0.2959 - val_loss: 0.3848 - val_mse: 0.3848\n",
      "Epoch 14/2000\n",
      " - 30s - loss: 0.3027 - mse: 0.2868 - val_loss: 0.3867 - val_mse: 0.3867\n",
      "Epoch 15/2000\n",
      " - 36s - loss: 0.2983 - mse: 0.2827 - val_loss: 0.3897 - val_mse: 0.3897\n",
      "==================================================\n",
      "Step 8\n",
      "==================================================\n",
      "Train on 670060 samples, validate on 167515 samples\n",
      "Epoch 1/2000\n",
      " - 42s - loss: 0.4734 - mse: 0.4457 - val_loss: 0.3899 - val_mse: 0.3899\n",
      "Epoch 2/2000\n",
      " - 45s - loss: 0.3756 - mse: 0.3551 - val_loss: 0.3639 - val_mse: 0.3639\n",
      "Epoch 3/2000\n",
      " - 41s - loss: 0.3622 - mse: 0.3429 - val_loss: 0.3581 - val_mse: 0.3581\n",
      "Epoch 4/2000\n",
      " - 40s - loss: 0.3538 - mse: 0.3352 - val_loss: 0.3585 - val_mse: 0.3585\n",
      "Epoch 5/2000\n",
      " - 42s - loss: 0.3478 - mse: 0.3297 - val_loss: 0.3576 - val_mse: 0.3576\n",
      "Epoch 6/2000\n",
      " - 44s - loss: 0.3427 - mse: 0.3249 - val_loss: 0.3608 - val_mse: 0.3608\n",
      "Epoch 7/2000\n",
      " - 47s - loss: 0.3385 - mse: 0.3211 - val_loss: 0.3613 - val_mse: 0.3613\n",
      "Epoch 8/2000\n",
      " - 40s - loss: 0.3346 - mse: 0.3174 - val_loss: 0.3618 - val_mse: 0.3618\n",
      "Epoch 9/2000\n",
      " - 42s - loss: 0.3311 - mse: 0.3141 - val_loss: 0.3663 - val_mse: 0.3663\n",
      "Epoch 10/2000\n",
      " - 45s - loss: 0.3274 - mse: 0.3107 - val_loss: 0.3682 - val_mse: 0.3682\n",
      "Epoch 11/2000\n",
      " - 42s - loss: 0.3240 - mse: 0.3075 - val_loss: 0.3686 - val_mse: 0.3686\n",
      "Epoch 12/2000\n",
      " - 61s - loss: 0.3204 - mse: 0.3042 - val_loss: 0.3732 - val_mse: 0.3732\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 13/2000\n",
      " - 52s - loss: 0.3019 - mse: 0.2870 - val_loss: 0.3699 - val_mse: 0.3699\n",
      "Epoch 14/2000\n",
      " - 42s - loss: 0.2931 - mse: 0.2788 - val_loss: 0.3728 - val_mse: 0.3728\n",
      "Epoch 15/2000\n",
      " - 48s - loss: 0.2886 - mse: 0.2746 - val_loss: 0.3763 - val_mse: 0.3763\n",
      "==================================================\n",
      "Step 9\n",
      "==================================================\n",
      "Train on 670060 samples, validate on 167515 samples\n",
      "Epoch 1/2000\n",
      " - 38s - loss: 0.5188 - mse: 0.4895 - val_loss: 0.4062 - val_mse: 0.4062\n",
      "Epoch 2/2000\n",
      " - 35s - loss: 0.3678 - mse: 0.3494 - val_loss: 0.3657 - val_mse: 0.3657\n",
      "Epoch 3/2000\n",
      " - 68s - loss: 0.3510 - mse: 0.3341 - val_loss: 0.3556 - val_mse: 0.3556\n",
      "Epoch 4/2000\n",
      " - 68s - loss: 0.3414 - mse: 0.3252 - val_loss: 0.3524 - val_mse: 0.3524\n",
      "Epoch 5/2000\n",
      " - 80s - loss: 0.3352 - mse: 0.3195 - val_loss: 0.3558 - val_mse: 0.3558\n",
      "Epoch 6/2000\n",
      " - 63s - loss: 0.3302 - mse: 0.3148 - val_loss: 0.3530 - val_mse: 0.3530\n",
      "Epoch 7/2000\n",
      " - 69s - loss: 0.3260 - mse: 0.3109 - val_loss: 0.3544 - val_mse: 0.3544\n",
      "Epoch 8/2000\n",
      " - 69s - loss: 0.3226 - mse: 0.3077 - val_loss: 0.3542 - val_mse: 0.3542\n",
      "Epoch 9/2000\n",
      " - 65s - loss: 0.3195 - mse: 0.3047 - val_loss: 0.3565 - val_mse: 0.3565\n",
      "Epoch 10/2000\n",
      " - 58s - loss: 0.3157 - mse: 0.3012 - val_loss: 0.3577 - val_mse: 0.3577\n",
      "Epoch 11/2000\n",
      " - 88s - loss: 0.3127 - mse: 0.2984 - val_loss: 0.3589 - val_mse: 0.3589\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 12/2000\n",
      " - 72s - loss: 0.2966 - mse: 0.2833 - val_loss: 0.3565 - val_mse: 0.3565\n",
      "Epoch 13/2000\n",
      " - 79s - loss: 0.2898 - mse: 0.2769 - val_loss: 0.3586 - val_mse: 0.3586\n",
      "Epoch 14/2000\n",
      " - 63s - loss: 0.2866 - mse: 0.2740 - val_loss: 0.3596 - val_mse: 0.3596\n",
      "==================================================\n",
      "Step 10\n",
      "==================================================\n",
      "Train on 670060 samples, validate on 167515 samples\n",
      "Epoch 1/2000\n",
      " - 52s - loss: 0.5065 - mse: 0.4769 - val_loss: 0.4189 - val_mse: 0.4189\n",
      "Epoch 2/2000\n",
      " - 36s - loss: 0.3708 - mse: 0.3502 - val_loss: 0.3771 - val_mse: 0.3771\n",
      "Epoch 3/2000\n",
      " - 35s - loss: 0.3577 - mse: 0.3381 - val_loss: 0.3663 - val_mse: 0.3663\n",
      "Epoch 4/2000\n",
      " - 33s - loss: 0.3497 - mse: 0.3307 - val_loss: 0.3650 - val_mse: 0.3650\n",
      "Epoch 5/2000\n",
      " - 31s - loss: 0.3436 - mse: 0.3251 - val_loss: 0.3667 - val_mse: 0.3667\n",
      "Epoch 6/2000\n",
      " - 35s - loss: 0.3390 - mse: 0.3208 - val_loss: 0.3676 - val_mse: 0.3676\n",
      "Epoch 7/2000\n",
      " - 36s - loss: 0.3348 - mse: 0.3169 - val_loss: 0.3702 - val_mse: 0.3702\n",
      "Epoch 8/2000\n",
      " - 37s - loss: 0.3312 - mse: 0.3135 - val_loss: 0.3698 - val_mse: 0.3698\n",
      "Epoch 9/2000\n",
      " - 32s - loss: 0.3273 - mse: 0.3099 - val_loss: 0.3737 - val_mse: 0.3737\n",
      "Epoch 10/2000\n",
      " - 38s - loss: 0.3238 - mse: 0.3067 - val_loss: 0.3748 - val_mse: 0.3748\n",
      "Epoch 11/2000\n",
      " - 34s - loss: 0.3204 - mse: 0.3035 - val_loss: 0.3758 - val_mse: 0.3758\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 12/2000\n",
      " - 39s - loss: 0.3027 - mse: 0.2871 - val_loss: 0.3776 - val_mse: 0.3776\n",
      "Epoch 13/2000\n",
      " - 46s - loss: 0.2952 - mse: 0.2801 - val_loss: 0.3799 - val_mse: 0.3799\n",
      "Epoch 14/2000\n",
      " - 38s - loss: 0.2917 - mse: 0.2768 - val_loss: 0.3816 - val_mse: 0.3816\n",
      "==================================================\n",
      "Step 11\n",
      "==================================================\n",
      "Train on 670060 samples, validate on 167515 samples\n",
      "Epoch 1/2000\n",
      " - 79s - loss: 0.4828 - mse: 0.4564 - val_loss: 0.4125 - val_mse: 0.4125\n",
      "Epoch 2/2000\n",
      " - 60s - loss: 0.3729 - mse: 0.3538 - val_loss: 0.3705 - val_mse: 0.3705\n",
      "Epoch 3/2000\n",
      " - 68s - loss: 0.3579 - mse: 0.3400 - val_loss: 0.3655 - val_mse: 0.3655\n",
      "Epoch 4/2000\n",
      " - 87s - loss: 0.3492 - mse: 0.3319 - val_loss: 0.3667 - val_mse: 0.3667\n",
      "Epoch 5/2000\n",
      " - 95s - loss: 0.3429 - mse: 0.3261 - val_loss: 0.3678 - val_mse: 0.3678\n",
      "Epoch 6/2000\n",
      " - 61s - loss: 0.3382 - mse: 0.3217 - val_loss: 0.3690 - val_mse: 0.3690\n",
      "Epoch 7/2000\n",
      " - 56s - loss: 0.3338 - mse: 0.3176 - val_loss: 0.3680 - val_mse: 0.3680\n",
      "Epoch 8/2000\n",
      " - 85s - loss: 0.3297 - mse: 0.3138 - val_loss: 0.3693 - val_mse: 0.3693\n",
      "Epoch 9/2000\n",
      " - 92s - loss: 0.3260 - mse: 0.3103 - val_loss: 0.3720 - val_mse: 0.3720\n",
      "Epoch 10/2000\n",
      " - 90s - loss: 0.3232 - mse: 0.3077 - val_loss: 0.3717 - val_mse: 0.3717\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 11/2000\n",
      " - 114s - loss: 0.3050 - mse: 0.2907 - val_loss: 0.3690 - val_mse: 0.3690\n",
      "Epoch 12/2000\n",
      " - 95s - loss: 0.2974 - mse: 0.2837 - val_loss: 0.3707 - val_mse: 0.3707\n",
      "Epoch 13/2000\n",
      " - 97s - loss: 0.2938 - mse: 0.2803 - val_loss: 0.3730 - val_mse: 0.3730\n",
      "==================================================\n",
      "Step 12\n",
      "==================================================\n",
      "Train on 670060 samples, validate on 167515 samples\n",
      "Epoch 1/2000\n",
      " - 57s - loss: 0.5236 - mse: 0.4945 - val_loss: 0.4342 - val_mse: 0.4342\n",
      "Epoch 2/2000\n",
      " - 78s - loss: 0.4092 - mse: 0.3875 - val_loss: 0.3993 - val_mse: 0.3993\n",
      "Epoch 3/2000\n",
      " - 87s - loss: 0.3936 - mse: 0.3729 - val_loss: 0.3983 - val_mse: 0.3983\n",
      "Epoch 4/2000\n",
      " - 100s - loss: 0.3837 - mse: 0.3637 - val_loss: 0.4004 - val_mse: 0.4004\n",
      "Epoch 5/2000\n",
      " - 112s - loss: 0.3771 - mse: 0.3577 - val_loss: 0.3993 - val_mse: 0.3993\n",
      "Epoch 6/2000\n",
      " - 88s - loss: 0.3707 - mse: 0.3517 - val_loss: 0.4018 - val_mse: 0.4018\n",
      "Epoch 7/2000\n",
      " - 109s - loss: 0.3658 - mse: 0.3471 - val_loss: 0.4002 - val_mse: 0.4002\n",
      "Epoch 8/2000\n",
      " - 118s - loss: 0.3607 - mse: 0.3423 - val_loss: 0.4094 - val_mse: 0.4094\n",
      "Epoch 9/2000\n",
      " - 96s - loss: 0.3560 - mse: 0.3380 - val_loss: 0.4125 - val_mse: 0.4125\n",
      "Epoch 10/2000\n",
      " - 71s - loss: 0.3521 - mse: 0.3343 - val_loss: 0.4089 - val_mse: 0.4089\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 11/2000\n",
      " - 53s - loss: 0.3324 - mse: 0.3161 - val_loss: 0.4023 - val_mse: 0.4023\n",
      "Epoch 12/2000\n",
      " - 88s - loss: 0.3238 - mse: 0.3082 - val_loss: 0.4048 - val_mse: 0.4048\n",
      "Epoch 13/2000\n",
      " - 93s - loss: 0.3198 - mse: 0.3044 - val_loss: 0.4078 - val_mse: 0.4078\n",
      "==================================================\n",
      "Step 13\n",
      "==================================================\n",
      "Train on 670060 samples, validate on 167515 samples\n",
      "Epoch 1/2000\n",
      " - 79s - loss: 0.5462 - mse: 0.5159 - val_loss: 0.4595 - val_mse: 0.4595\n",
      "Epoch 2/2000\n",
      " - 91s - loss: 0.4223 - mse: 0.3999 - val_loss: 0.4181 - val_mse: 0.4181\n",
      "Epoch 3/2000\n",
      " - 88s - loss: 0.4040 - mse: 0.3829 - val_loss: 0.4083 - val_mse: 0.4083\n",
      "Epoch 4/2000\n",
      " - 88s - loss: 0.3923 - mse: 0.3720 - val_loss: 0.4052 - val_mse: 0.4052\n",
      "Epoch 5/2000\n",
      " - 92s - loss: 0.3842 - mse: 0.3645 - val_loss: 0.4126 - val_mse: 0.4126\n",
      "Epoch 6/2000\n",
      " - 81s - loss: 0.3779 - mse: 0.3585 - val_loss: 0.4121 - val_mse: 0.4121\n",
      "Epoch 7/2000\n",
      " - 95s - loss: 0.3722 - mse: 0.3533 - val_loss: 0.4204 - val_mse: 0.4204\n",
      "Epoch 8/2000\n",
      " - 119s - loss: 0.3665 - mse: 0.3479 - val_loss: 0.4162 - val_mse: 0.4162\n",
      "Epoch 9/2000\n",
      " - 94s - loss: 0.3621 - mse: 0.3439 - val_loss: 0.4240 - val_mse: 0.4240\n",
      "Epoch 10/2000\n",
      " - 103s - loss: 0.3575 - mse: 0.3395 - val_loss: 0.4279 - val_mse: 0.4279\n",
      "Epoch 11/2000\n",
      " - 37s - loss: 0.3527 - mse: 0.3350 - val_loss: 0.4241 - val_mse: 0.4241\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 12/2000\n",
      " - 44s - loss: 0.3323 - mse: 0.3161 - val_loss: 0.4192 - val_mse: 0.4192\n",
      "Epoch 13/2000\n",
      " - 34s - loss: 0.3229 - mse: 0.3075 - val_loss: 0.4217 - val_mse: 0.4217\n",
      "Epoch 14/2000\n",
      " - 33s - loss: 0.3187 - mse: 0.3036 - val_loss: 0.4246 - val_mse: 0.4246\n",
      "==================================================\n",
      "Step 14\n",
      "==================================================\n",
      "Train on 670060 samples, validate on 167515 samples\n",
      "Epoch 1/2000\n",
      " - 65s - loss: 0.5265 - mse: 0.4964 - val_loss: 0.4443 - val_mse: 0.4443\n",
      "Epoch 2/2000\n",
      " - 95s - loss: 0.4010 - mse: 0.3783 - val_loss: 0.4055 - val_mse: 0.4055\n",
      "Epoch 3/2000\n",
      " - 59s - loss: 0.3874 - mse: 0.3658 - val_loss: 0.4038 - val_mse: 0.4038\n",
      "Epoch 4/2000\n",
      " - 74s - loss: 0.3788 - mse: 0.3578 - val_loss: 0.4027 - val_mse: 0.4027\n",
      "Epoch 5/2000\n",
      " - 49s - loss: 0.3722 - mse: 0.3517 - val_loss: 0.4051 - val_mse: 0.4051\n",
      "Epoch 6/2000\n",
      " - 84s - loss: 0.3669 - mse: 0.3467 - val_loss: 0.4068 - val_mse: 0.4068\n",
      "Epoch 7/2000\n",
      " - 60s - loss: 0.3616 - mse: 0.3419 - val_loss: 0.4065 - val_mse: 0.4065\n",
      "Epoch 8/2000\n",
      " - 80s - loss: 0.3575 - mse: 0.3380 - val_loss: 0.4094 - val_mse: 0.4094\n",
      "Epoch 9/2000\n",
      " - 42s - loss: 0.3531 - mse: 0.3339 - val_loss: 0.4113 - val_mse: 0.4113\n",
      "Epoch 10/2000\n",
      " - 40s - loss: 0.3500 - mse: 0.3310 - val_loss: 0.4116 - val_mse: 0.4116\n",
      "Epoch 11/2000\n",
      " - 37s - loss: 0.3457 - mse: 0.3270 - val_loss: 0.4200 - val_mse: 0.4200\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 12/2000\n",
      " - 45s - loss: 0.3253 - mse: 0.3081 - val_loss: 0.4177 - val_mse: 0.4177\n",
      "Epoch 13/2000\n",
      " - 44s - loss: 0.3163 - mse: 0.2998 - val_loss: 0.4195 - val_mse: 0.4195\n",
      "Epoch 14/2000\n",
      " - 34s - loss: 0.3119 - mse: 0.2958 - val_loss: 0.4203 - val_mse: 0.4203\n",
      "==================================================\n",
      "Step 15\n",
      "==================================================\n",
      "Train on 670060 samples, validate on 167515 samples\n",
      "Epoch 1/2000\n",
      " - 40s - loss: 0.5002 - mse: 0.4712 - val_loss: 0.4603 - val_mse: 0.4603\n",
      "Epoch 2/2000\n",
      " - 49s - loss: 0.3913 - mse: 0.3699 - val_loss: 0.3942 - val_mse: 0.3942\n",
      "Epoch 3/2000\n",
      " - 57s - loss: 0.3775 - mse: 0.3571 - val_loss: 0.3917 - val_mse: 0.3917\n",
      "Epoch 4/2000\n",
      " - 58s - loss: 0.3692 - mse: 0.3495 - val_loss: 0.3877 - val_mse: 0.3877\n",
      "Epoch 5/2000\n",
      " - 51s - loss: 0.3627 - mse: 0.3434 - val_loss: 0.3930 - val_mse: 0.3930\n",
      "Epoch 6/2000\n",
      " - 62s - loss: 0.3574 - mse: 0.3385 - val_loss: 0.3901 - val_mse: 0.3901\n",
      "Epoch 7/2000\n",
      " - 56s - loss: 0.3525 - mse: 0.3340 - val_loss: 0.3939 - val_mse: 0.3939\n",
      "Epoch 8/2000\n",
      " - 46s - loss: 0.3488 - mse: 0.3305 - val_loss: 0.3976 - val_mse: 0.3976\n",
      "Epoch 9/2000\n",
      " - 53s - loss: 0.3439 - mse: 0.3260 - val_loss: 0.4011 - val_mse: 0.4011\n",
      "Epoch 10/2000\n",
      " - 74s - loss: 0.3404 - mse: 0.3227 - val_loss: 0.4019 - val_mse: 0.4019\n",
      "Epoch 11/2000\n",
      " - 62s - loss: 0.3365 - mse: 0.3191 - val_loss: 0.4002 - val_mse: 0.4002\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 12/2000\n",
      " - 53s - loss: 0.3177 - mse: 0.3017 - val_loss: 0.3992 - val_mse: 0.3992\n",
      "Epoch 13/2000\n",
      " - 47s - loss: 0.3094 - mse: 0.2940 - val_loss: 0.4022 - val_mse: 0.4022\n",
      "Epoch 14/2000\n",
      " - 63s - loss: 0.3052 - mse: 0.2901 - val_loss: 0.4044 - val_mse: 0.4044\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 2000\n",
    "\n",
    "val_pred = []\n",
    "test_pred = []\n",
    "# wtpath = 'weights.hdf5'  # To save best epoch. But need Keras bug to be fixed first.\n",
    "sample_weights=np.array( pd.concat([items[\"perishable\"]] * num_days) * 0.25 + 1 )\n",
    "for i in range(15):\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Step %d\" % (i+1))\n",
    "    print(\"=\" * 50)\n",
    "    y = y_train[:, i]\n",
    "    y_mean = y.mean()\n",
    "    xv = X_val\n",
    "    yv = y_val[:, i]\n",
    "    model = build_model()\n",
    "\n",
    "    opt = optimizers.Adam(lr=0.001)\n",
    "#     opt = optimizers.RMSprop(learning_rate=0.001, rho=0.9)\n",
    "    model.compile(loss='mse', optimizer=opt, metrics=['mse'])\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=10, verbose=0),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=7, verbose=1, min_delta=1e-4, mode='min')\n",
    "        ]\n",
    "    \n",
    "    #smaller batch size runs faster\n",
    "    #batch_size = 65536\n",
    "    batch_size = 8192\n",
    "\n",
    "    model.fit(X_train, y - y_mean, batch_size = batch_size, epochs = N_EPOCHS, verbose=2,\n",
    "               sample_weight=sample_weights, validation_data=(xv,yv-y_mean), callbacks=callbacks )\n",
    "    val_pred.append(model.predict(X_val)+y_mean)\n",
    "    test_pred.append(model.predict(X_test)+y_mean)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation nwrmsle = 0.615181004370035\n"
     ]
    }
   ],
   "source": [
    "weight = items[\"perishable\"] * 0.25 + 1\n",
    "val_err = (y_val - np.array(val_pred).squeeze(axis=2).transpose())**2\n",
    "val_err = val_err.sum(axis=1) * weight\n",
    "#change to 15 days\n",
    "val_err = np.sqrt(val_err.sum() / weight.sum() / 15)\n",
    "print('validation nwrmsle = {}'.format(val_err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test nwrmsle = 0.6287589748678302\n"
     ]
    }
   ],
   "source": [
    "test_err = (y_test - np.array(test_pred).squeeze(axis=2).transpose())**2\n",
    "test_err = test_err.sum(axis=1) * weight\n",
    "#change to 15 days\n",
    "test_err = np.sqrt(test_err.sum() / weight.sum() / 15)\n",
    "print('test nwrmsle = {}'.format(test_err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_test = pd.DataFrame(np.array(test_pred).squeeze(axis=2).transpose(), \n",
    "                            index = df_2017_index, columns = pd.date_range('2017-08-01',periods=15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_test.to_csv('../derived_datasets/nn_test_pred_model_1.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
