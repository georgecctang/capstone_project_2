{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference Dates\n",
    "\n",
    "Num Training Weeks = 4  \n",
    "Num Test/Val Days = 15\n",
    "\n",
    "- Train: 5/30/2017 (Tues), 6/6/2017,6/13/2017,6/20/2017  \n",
    "- Val: 7/11/2017 (Tues) - 7/25/2017 (Wed)  \n",
    "- Test: 8/1/2017 (Tues)  - 8/15/2017 (Wed)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import callbacks\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\n",
    "    '../input/train.csv', usecols=[1, 2, 3, 4, 5],\n",
    "    dtype={'onpromotion': bool},\n",
    "    converters={'unit_sales': lambda u: np.log1p(\n",
    "        float(u)) if float(u) > 0 else 0},\n",
    "    parse_dates=[\"date\"],\n",
    "    skiprows=range(1, 66458909)  # 2016-01-01\n",
    ")\n",
    "\n",
    "df_test = pd.read_csv(\n",
    "    \"../input/test.csv\", usecols=[0, 1, 2, 3, 4],\n",
    "    dtype={'onpromotion': bool},\n",
    "    parse_dates=[\"date\"]  # , date_parser=parser\n",
    ").set_index(\n",
    "    ['store_nbr', 'item_nbr', 'date']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = pd.read_csv(\n",
    "    \"../input/items.csv\",\n",
    ").set_index(\"item_nbr\")\n",
    "\n",
    "stores = pd.read_csv(\n",
    "    \"../input/stores.csv\",\n",
    ").set_index(\"store_nbr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family</th>\n",
       "      <th>class</th>\n",
       "      <th>perishable</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_nbr</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96995</th>\n",
       "      <td>GROCERY I</td>\n",
       "      <td>1093</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99197</th>\n",
       "      <td>GROCERY I</td>\n",
       "      <td>1067</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103501</th>\n",
       "      <td>CLEANING</td>\n",
       "      <td>3008</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103520</th>\n",
       "      <td>GROCERY I</td>\n",
       "      <td>1028</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103665</th>\n",
       "      <td>BREAD/BAKERY</td>\n",
       "      <td>2712</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                family  class  perishable\n",
       "item_nbr                                 \n",
       "96995        GROCERY I   1093           0\n",
       "99197        GROCERY I   1067           0\n",
       "103501        CLEANING   3008           0\n",
       "103520       GROCERY I   1028           0\n",
       "103665    BREAD/BAKERY   2712           1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>type</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_nbr</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Santo Domingo</td>\n",
       "      <td>Santo Domingo de los Tsachilas</td>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    city                           state type  cluster\n",
       "store_nbr                                                             \n",
       "1                  Quito                       Pichincha    D       13\n",
       "2                  Quito                       Pichincha    D       13\n",
       "3                  Quito                       Pichincha    D        8\n",
       "4                  Quito                       Pichincha    D        9\n",
       "5          Santo Domingo  Santo Domingo de los Tsachilas    D        4"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2017 = df_train.loc[df_train.date>=pd.datetime(2017,1,1)]\n",
    "del df_train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>unit_sales</th>\n",
       "      <th>onpromotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35229871</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>25</td>\n",
       "      <td>99197</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35229872</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>25</td>\n",
       "      <td>103665</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35229873</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>25</td>\n",
       "      <td>105574</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35229874</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>25</td>\n",
       "      <td>105857</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35229875</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>25</td>\n",
       "      <td>106716</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               date  store_nbr  item_nbr  unit_sales  onpromotion\n",
       "35229871 2017-01-01         25     99197    0.693147        False\n",
       "35229872 2017-01-01         25    103665    2.079442        False\n",
       "35229873 2017-01-01         25    105574    0.693147        False\n",
       "35229874 2017-01-01         25    105857    1.609438        False\n",
       "35229875 2017-01-01         25    106716    1.098612        False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2017.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "promo_2017_train = df_2017.set_index(\n",
    "    [\"store_nbr\", \"item_nbr\", \"date\"])[[\"onpromotion\"]].unstack(\n",
    "        level=-1).fillna(False)\n",
    "promo_2017_train.columns = promo_2017_train.columns.get_level_values(1)\n",
    "promo_2017_test = df_test[[\"onpromotion\"]].unstack(level=-1).fillna(False)\n",
    "promo_2017_test.columns = promo_2017_test.columns.get_level_values(1)\n",
    "promo_2017_test = promo_2017_test.reindex(promo_2017_train.index).fillna(False)\n",
    "promo_2017 = pd.concat([promo_2017_train, promo_2017_test], axis=1)\n",
    "del promo_2017_test, promo_2017_train, df_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>2017-01-01</th>\n",
       "      <th>2017-01-02</th>\n",
       "      <th>2017-01-03</th>\n",
       "      <th>2017-01-04</th>\n",
       "      <th>2017-01-05</th>\n",
       "      <th>2017-01-06</th>\n",
       "      <th>2017-01-07</th>\n",
       "      <th>2017-01-08</th>\n",
       "      <th>2017-01-09</th>\n",
       "      <th>2017-01-10</th>\n",
       "      <th>...</th>\n",
       "      <th>2017-08-22</th>\n",
       "      <th>2017-08-23</th>\n",
       "      <th>2017-08-24</th>\n",
       "      <th>2017-08-25</th>\n",
       "      <th>2017-08-26</th>\n",
       "      <th>2017-08-27</th>\n",
       "      <th>2017-08-28</th>\n",
       "      <th>2017-08-29</th>\n",
       "      <th>2017-08-30</th>\n",
       "      <th>2017-08-31</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>96995</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99197</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103520</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103665</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105574</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 243 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "date                2017-01-01  2017-01-02  2017-01-03  2017-01-04  \\\n",
       "store_nbr item_nbr                                                   \n",
       "1         96995          False       False       False       False   \n",
       "          99197          False       False       False       False   \n",
       "          103520         False       False       False       False   \n",
       "          103665         False       False       False       False   \n",
       "          105574         False       False        True       False   \n",
       "\n",
       "date                2017-01-05  2017-01-06  2017-01-07  2017-01-08  \\\n",
       "store_nbr item_nbr                                                   \n",
       "1         96995          False       False       False       False   \n",
       "          99197          False       False       False       False   \n",
       "          103520         False       False       False       False   \n",
       "          103665         False       False       False       False   \n",
       "          105574         False        True       False       False   \n",
       "\n",
       "date                2017-01-09  2017-01-10  ...  2017-08-22  2017-08-23  \\\n",
       "store_nbr item_nbr                          ...                           \n",
       "1         96995          False       False  ...       False       False   \n",
       "          99197          False       False  ...       False       False   \n",
       "          103520         False       False  ...       False       False   \n",
       "          103665         False       False  ...       False       False   \n",
       "          105574         False       False  ...       False       False   \n",
       "\n",
       "date                2017-08-24  2017-08-25  2017-08-26  2017-08-27  \\\n",
       "store_nbr item_nbr                                                   \n",
       "1         96995          False       False       False       False   \n",
       "          99197          False       False       False       False   \n",
       "          103520         False       False       False       False   \n",
       "          103665         False       False       False       False   \n",
       "          105574         False       False       False       False   \n",
       "\n",
       "date                2017-08-28  2017-08-29  2017-08-30  2017-08-31  \n",
       "store_nbr item_nbr                                                  \n",
       "1         96995          False       False       False       False  \n",
       "          99197          False       False       False       False  \n",
       "          103520         False       False       False       False  \n",
       "          103665         False       False       False       False  \n",
       "          105574         False       False       False       False  \n",
       "\n",
       "[5 rows x 243 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "promo_2017.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2017 = df_2017.set_index(\n",
    "    [\"store_nbr\", \"item_nbr\", \"date\"])[[\"unit_sales\"]].unstack(\n",
    "        level=-1).fillna(0)\n",
    "df_2017.columns = df_2017.columns.get_level_values(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>2017-01-01</th>\n",
       "      <th>2017-01-02</th>\n",
       "      <th>2017-01-03</th>\n",
       "      <th>2017-01-04</th>\n",
       "      <th>2017-01-05</th>\n",
       "      <th>2017-01-06</th>\n",
       "      <th>2017-01-07</th>\n",
       "      <th>2017-01-08</th>\n",
       "      <th>2017-01-09</th>\n",
       "      <th>2017-01-10</th>\n",
       "      <th>...</th>\n",
       "      <th>2017-08-06</th>\n",
       "      <th>2017-08-07</th>\n",
       "      <th>2017-08-08</th>\n",
       "      <th>2017-08-09</th>\n",
       "      <th>2017-08-10</th>\n",
       "      <th>2017-08-11</th>\n",
       "      <th>2017-08-12</th>\n",
       "      <th>2017-08-13</th>\n",
       "      <th>2017-08-14</th>\n",
       "      <th>2017-08-15</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>96995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99197</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103520</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103665</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>...</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105574</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.609438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 227 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "date                2017-01-01  2017-01-02  2017-01-03  2017-01-04  \\\n",
       "store_nbr item_nbr                                                   \n",
       "1         96995            0.0    0.000000    0.000000    0.000000   \n",
       "          99197            0.0    0.000000    1.386294    0.693147   \n",
       "          103520           0.0    0.693147    1.098612    0.000000   \n",
       "          103665           0.0    0.000000    0.000000    1.386294   \n",
       "          105574           0.0    0.000000    1.791759    2.564949   \n",
       "\n",
       "date                2017-01-05  2017-01-06  2017-01-07  2017-01-08  \\\n",
       "store_nbr item_nbr                                                   \n",
       "1         96995       0.000000    0.000000    0.000000    0.000000   \n",
       "          99197       0.693147    0.693147    1.098612    0.000000   \n",
       "          103520      1.098612    1.386294    0.693147    0.000000   \n",
       "          103665      1.098612    1.098612    0.693147    1.098612   \n",
       "          105574      2.302585    1.945910    1.609438    1.098612   \n",
       "\n",
       "date                2017-01-09  2017-01-10  ...  2017-08-06  2017-08-07  \\\n",
       "store_nbr item_nbr                          ...                           \n",
       "1         96995       0.000000    0.000000  ...    1.098612    1.098612   \n",
       "          99197       0.000000    0.693147  ...    0.000000    1.098612   \n",
       "          103520      0.693147    0.693147  ...    0.000000    0.000000   \n",
       "          103665      0.000000    2.079442  ...    0.693147    1.098612   \n",
       "          105574      1.386294    2.302585  ...    0.000000    1.791759   \n",
       "\n",
       "date                2017-08-08  2017-08-09  2017-08-10  2017-08-11  \\\n",
       "store_nbr item_nbr                                                   \n",
       "1         96995       0.000000    0.000000    0.693147    0.000000   \n",
       "          99197       0.000000    1.098612    0.000000    0.000000   \n",
       "          103520      1.386294    0.000000    1.386294    0.693147   \n",
       "          103665      0.000000    2.079442    2.302585    1.098612   \n",
       "          105574      2.079442    1.945910    2.397895    1.791759   \n",
       "\n",
       "date                2017-08-12  2017-08-13  2017-08-14  2017-08-15  \n",
       "store_nbr item_nbr                                                  \n",
       "1         96995       0.000000    0.000000    0.000000    0.000000  \n",
       "          99197       0.000000    0.000000    0.000000    0.000000  \n",
       "          103520      0.693147    0.693147    0.000000    0.000000  \n",
       "          103665      0.000000    0.000000    0.693147    0.693147  \n",
       "          105574      1.791759    0.000000    1.386294    1.609438  \n",
       "\n",
       "[5 rows x 227 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2017.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "items['class'] = items['class'].astype('category')\n",
    "items = pd.get_dummies(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>perishable</th>\n",
       "      <th>family_AUTOMOTIVE</th>\n",
       "      <th>family_BABY CARE</th>\n",
       "      <th>family_BEAUTY</th>\n",
       "      <th>family_BEVERAGES</th>\n",
       "      <th>family_BOOKS</th>\n",
       "      <th>family_BREAD/BAKERY</th>\n",
       "      <th>family_CELEBRATION</th>\n",
       "      <th>family_CLEANING</th>\n",
       "      <th>family_DAIRY</th>\n",
       "      <th>...</th>\n",
       "      <th>class_6920</th>\n",
       "      <th>class_6922</th>\n",
       "      <th>class_6924</th>\n",
       "      <th>class_6936</th>\n",
       "      <th>class_6954</th>\n",
       "      <th>class_6960</th>\n",
       "      <th>class_7002</th>\n",
       "      <th>class_7016</th>\n",
       "      <th>class_7034</th>\n",
       "      <th>class_7780</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_nbr</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99197</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103501</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103520</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103665</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          perishable  family_AUTOMOTIVE  family_BABY CARE  family_BEAUTY  \\\n",
       "item_nbr                                                                   \n",
       "96995              0                  0                 0              0   \n",
       "99197              0                  0                 0              0   \n",
       "103501             0                  0                 0              0   \n",
       "103520             0                  0                 0              0   \n",
       "103665             1                  0                 0              0   \n",
       "\n",
       "          family_BEVERAGES  family_BOOKS  family_BREAD/BAKERY  \\\n",
       "item_nbr                                                        \n",
       "96995                    0             0                    0   \n",
       "99197                    0             0                    0   \n",
       "103501                   0             0                    0   \n",
       "103520                   0             0                    0   \n",
       "103665                   0             0                    1   \n",
       "\n",
       "          family_CELEBRATION  family_CLEANING  family_DAIRY  ...  class_6920  \\\n",
       "item_nbr                                                     ...               \n",
       "96995                      0                0             0  ...           0   \n",
       "99197                      0                0             0  ...           0   \n",
       "103501                     0                1             0  ...           0   \n",
       "103520                     0                0             0  ...           0   \n",
       "103665                     0                0             0  ...           0   \n",
       "\n",
       "          class_6922  class_6924  class_6936  class_6954  class_6960  \\\n",
       "item_nbr                                                               \n",
       "96995              0           0           0           0           0   \n",
       "99197              0           0           0           0           0   \n",
       "103501             0           0           0           0           0   \n",
       "103520             0           0           0           0           0   \n",
       "103665             0           0           0           0           0   \n",
       "\n",
       "          class_7002  class_7016  class_7034  class_7780  \n",
       "item_nbr                                                  \n",
       "96995              0           0           0           0  \n",
       "99197              0           0           0           0  \n",
       "103501             0           0           0           0  \n",
       "103520             0           0           0           0  \n",
       "103665             0           0           0           0  \n",
       "\n",
       "[5 rows x 371 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = items.reindex(df_2017.index.get_level_values(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(167515, 371)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>type</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_nbr</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Santo Domingo</td>\n",
       "      <td>Santo Domingo de los Tsachilas</td>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    city                           state type  cluster\n",
       "store_nbr                                                             \n",
       "1                  Quito                       Pichincha    D       13\n",
       "2                  Quito                       Pichincha    D       13\n",
       "3                  Quito                       Pichincha    D        8\n",
       "4                  Quito                       Pichincha    D        9\n",
       "5          Santo Domingo  Santo Domingo de los Tsachilas    D        4"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores['cluster'] = stores.cluster.astype('category')\n",
    "stores = pd.get_dummies(stores)\n",
    "stores = stores.reindex(df_2017.index.get_level_values(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_Ambato</th>\n",
       "      <th>city_Babahoyo</th>\n",
       "      <th>city_Cayambe</th>\n",
       "      <th>city_Cuenca</th>\n",
       "      <th>city_Daule</th>\n",
       "      <th>city_El Carmen</th>\n",
       "      <th>city_Esmeraldas</th>\n",
       "      <th>city_Guaranda</th>\n",
       "      <th>city_Guayaquil</th>\n",
       "      <th>city_Ibarra</th>\n",
       "      <th>...</th>\n",
       "      <th>cluster_8</th>\n",
       "      <th>cluster_9</th>\n",
       "      <th>cluster_10</th>\n",
       "      <th>cluster_11</th>\n",
       "      <th>cluster_12</th>\n",
       "      <th>cluster_13</th>\n",
       "      <th>cluster_14</th>\n",
       "      <th>cluster_15</th>\n",
       "      <th>cluster_16</th>\n",
       "      <th>cluster_17</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_nbr</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           city_Ambato  city_Babahoyo  city_Cayambe  city_Cuenca  city_Daule  \\\n",
       "store_nbr                                                                      \n",
       "1                    0              0             0            0           0   \n",
       "1                    0              0             0            0           0   \n",
       "1                    0              0             0            0           0   \n",
       "1                    0              0             0            0           0   \n",
       "1                    0              0             0            0           0   \n",
       "\n",
       "           city_El Carmen  city_Esmeraldas  city_Guaranda  city_Guayaquil  \\\n",
       "store_nbr                                                                   \n",
       "1                       0                0              0               0   \n",
       "1                       0                0              0               0   \n",
       "1                       0                0              0               0   \n",
       "1                       0                0              0               0   \n",
       "1                       0                0              0               0   \n",
       "\n",
       "           city_Ibarra  ...  cluster_8  cluster_9  cluster_10  cluster_11  \\\n",
       "store_nbr               ...                                                 \n",
       "1                    0  ...          0          0           0           0   \n",
       "1                    0  ...          0          0           0           0   \n",
       "1                    0  ...          0          0           0           0   \n",
       "1                    0  ...          0          0           0           0   \n",
       "1                    0  ...          0          0           0           0   \n",
       "\n",
       "           cluster_12  cluster_13  cluster_14  cluster_15  cluster_16  \\\n",
       "store_nbr                                                               \n",
       "1                   0           1           0           0           0   \n",
       "1                   0           1           0           0           0   \n",
       "1                   0           1           0           0           0   \n",
       "1                   0           1           0           0           0   \n",
       "1                   0           1           0           0           0   \n",
       "\n",
       "           cluster_17  \n",
       "store_nbr              \n",
       "1                   0  \n",
       "1                   0  \n",
       "1                   0  \n",
       "1                   0  \n",
       "1                   0  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(167515, 60)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sum of sales for each item across all stores for each day\n",
    "#df_2017_item = df_2017.groupby('item_nbr')[df_2017.columns].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sum of promotion for each item across all stores for each day\n",
    "#promo_2017_item = promo_2017.groupby('item_nbr')[promo_2017.columns].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum of sales in each class (multiple items) for each store for each day \n",
    "# df_2017_store_class = df_2017.reset_index()\n",
    "# df_2017_store_class['class'] = items['class'].values\n",
    "# df_2017_store_class_index = df_2017_store_class[['class', 'store_nbr']]\n",
    "# df_2017_store_class = df_2017_store_class.groupby(['class', 'store_nbr'])[df_2017.columns].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_2017_store_class_index.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_2017_store_class.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_2017_store_class.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum of promotions in each class (multiple items) for each store for each day \n",
    "\n",
    "# df_2017_promo_store_class = promo_2017.reset_index()\n",
    "# df_2017_promo_store_class['class'] = items['class'].values\n",
    "# df_2017_promo_store_class_index = df_2017_promo_store_class[['class', 'store_nbr']]\n",
    "# df_2017_promo_store_class = df_2017_promo_store_class.groupby(['class', 'store_nbr'])[promo_2017.columns].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timespan(df, dt, minus, periods, freq='D'):\n",
    "    return df[pd.date_range(dt - timedelta(days=minus), periods=periods, freq=freq)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(df, promo_df, t2017, is_train=True, name_prefix=None):\n",
    "    X = {\n",
    "        \"promo_7_2017\": get_timespan(promo_df, t2017, 7, 7).sum(axis=1).values,\n",
    "        \"promo_14_2017\": get_timespan(promo_df, t2017, 14, 14).sum(axis=1).values,\n",
    "        \"promo_30_2017\": get_timespan(promo_df, t2017, 30, 30).sum(axis=1).values,\n",
    "        \"promo_3_2017_aft\": get_timespan(promo_df, t2017 + timedelta(days=15), 14, 3).sum(axis=1).values,\n",
    "        \"promo_7_2017_aft\": get_timespan(promo_df, t2017 + timedelta(days=15), 14, 7).sum(axis=1).values,\n",
    "        \"promo_14_2017_aft\": get_timespan(promo_df, t2017 + timedelta(days=15), 14, 14).sum(axis=1).values,\n",
    "    }\n",
    "\n",
    "# Removed due to the presence of nan values \n",
    "#     for i in [3, 7, 14, 30]:\n",
    "#         tmp1 = get_timespan(df, t2017, i, i)\n",
    "#         tmp2 = (get_timespan(promo_df, t2017, i, i) > 0) * 1\n",
    "\n",
    "#         X['has_promo_mean_%s' % i] = (tmp1 * tmp2.replace(0, np.nan)).mean(axis=1).values\n",
    "#         X['no_promo_mean_%s' % i] = (tmp1 * (1 - tmp2).replace(0, np.nan)).mean(axis=1).values\n",
    "                \n",
    "        \n",
    "    for i in [3, 7, 14, 30]:\n",
    "        tmp = get_timespan(df, t2017, i, i)\n",
    "        X['diff_%s_mean' % i] = tmp.diff(axis=1).mean(axis=1).values\n",
    "        X['mean_%s' % i] = tmp.mean(axis=1).values\n",
    "        X['median_%s' % i] = tmp.median(axis=1).values\n",
    "        X['min_%s' % i] = tmp.min(axis=1).values\n",
    "        X['max_%s' % i] = tmp.max(axis=1).values\n",
    "        X['std_%s' % i] = tmp.std(axis=1).values\n",
    "\n",
    "    for i in [7, 14, 30]:\n",
    "        tmp = get_timespan(df, t2017, i, i)\n",
    "        X['has_sales_days_in_last_%s' % i] = (tmp > 0).sum(axis=1).values\n",
    "        X['last_has_sales_day_in_last_%s' % i] = i - ((tmp > 0) * np.arange(i)).max(axis=1).values\n",
    "        X['first_has_sales_day_in_last_%s' % i] = ((tmp > 0) * np.arange(i, 0, -1)).max(axis=1).values\n",
    "\n",
    "        tmp = get_timespan(promo_df, t2017, i, i)\n",
    "        X['has_promo_days_in_last_%s' % i] = (tmp > 0).sum(axis=1).values\n",
    "        X['last_has_promo_day_in_last_%s' % i] = i - ((tmp > 0) * np.arange(i)).max(axis=1).values\n",
    "        X['first_has_promo_day_in_last_%s' % i] = ((tmp > 0) * np.arange(i, 0, -1)).max(axis=1).values\n",
    "\n",
    "    tmp = get_timespan(promo_df, t2017 + timedelta(days=15), 14, 14)\n",
    "    X['has_promo_days_in_after_14_days'] = (tmp > 0).sum(axis=1).values\n",
    "    X['last_has_promo_day_in_after_14_days'] = i - ((tmp > 0) * np.arange(14)).max(axis=1).values\n",
    "    X['first_has_promo_day_in_after_14_days'] = ((tmp > 0) * np.arange(14, 0, -1)).max(axis=1).values\n",
    "\n",
    "    for i in range(1, 15):\n",
    "        X['day_%s_2017' % i] = get_timespan(df, t2017, i, 1).values.ravel()\n",
    "\n",
    "    for i in range(7):\n",
    "        X['mean_4_dow{}_2017'.format(i)] = get_timespan(df, t2017, 28-i, 4, freq='7D').mean(axis=1).values\n",
    "        X['mean_20_dow{}_2017'.format(i)] = get_timespan(df, t2017, 140-i, 20, freq='7D').mean(axis=1).values        \n",
    "        \n",
    "    for i in range(-14, 15):\n",
    "        X[\"promo_{}\".format(i)] = promo_df[t2017 + timedelta(days=i)].values.astype(np.uint8)\n",
    "\n",
    "    X = pd.DataFrame(X)\n",
    "\n",
    "    if is_train:\n",
    "        y = df[\n",
    "            pd.date_range(t2017, periods=15)\n",
    "        ].values\n",
    "        return X, y\n",
    "    if name_prefix is not None:\n",
    "        X.columns = ['%s_%s' % (name_prefix, c) for c in X.columns]\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:09<00:00,  2.49s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Preparing dataset...\")\n",
    "t2017 = date(2017, 5, 30)\n",
    "num_days = 4\n",
    "X_l, y_l = [], []\n",
    "for i in tqdm(range(num_days)):\n",
    "    delta = timedelta(days=7 * i)\n",
    "    X_tmp, y_tmp = prepare_dataset(df_2017, promo_2017, t2017 + delta)\n",
    "\n",
    "    X_tmp = pd.concat([X_tmp, items.reset_index(drop=True), stores.reset_index(drop=True)], axis=1)\n",
    "    X_l.append(X_tmp)\n",
    "    y_l.append(y_tmp)\n",
    "\n",
    "X_train = pd.concat(X_l, axis=0)\n",
    "y_train = np.concatenate(y_l, axis=0)\n",
    "\n",
    "del X_l, y_l\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, y_val = prepare_dataset(df_2017, promo_2017, date(2017, 7, 11))\n",
    "\n",
    "# X_val2 = prepare_dataset(df_2017_item, promo_2017_item, date(2017, 7, 26), is_train=False, name_prefix='item')\n",
    "# X_val2.index = df_2017_item.index\n",
    "# X_val2 = X_val2.reindex(df_2017.index.get_level_values(1)).reset_index(drop=True)\n",
    "\n",
    "# X_val3 = prepare_dataset(df_2017_store_class, df_2017_promo_store_class, date(2017, 7, 26), is_train=False, name_prefix='store_class')\n",
    "# X_val3.index = df_2017_store_class.index\n",
    "# X_val3 = X_val3.reindex(df_2017_store_class_index).reset_index(drop=True)\n",
    "\n",
    "X_val = pd.concat([X_val, items.reset_index(drop=True), stores.reset_index(drop=True)], axis=1)\n",
    "\n",
    "X_test, y_test = prepare_dataset(df_2017, promo_2017, date(2017, 8, 1))\n",
    "\n",
    "# X_test2 = prepare_dataset(df_2017_item, promo_2017_item, date(2017, 8, 16), is_train=False, name_prefix='item')\n",
    "# X_test2.index = df_2017_item.index\n",
    "# X_test2 = X_test2.reindex(df_2017.index.get_level_values(1)).reset_index(drop=True)\n",
    "\n",
    "# X_test3 = prepare_dataset(df_2017_store_class, df_2017_promo_store_class, date(2017, 8, 16), is_train=False, name_prefix='store_class')\n",
    "# X_test3.index = df_2017_store_class.index\n",
    "# X_test3 = X_test3.reindex(df_2017_store_class_index).reset_index(drop=True)\n",
    "\n",
    "X_test = pd.concat([X_test, items.reset_index(drop=True), stores.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# del X_test2, X_val2, df_2017_item, promo_2017_item, df_2017_store_class, df_2017_promo_store_class, df_2017_store_class_index\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_1005\n",
      "class_1328\n",
      "class_1334\n"
     ]
    }
   ],
   "source": [
    "for col in X_train.columns:\n",
    "    if X_train[col].nunique() == 1:\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#there are columns with unique values but will leave it here for simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((670060, 539), (670060, 15))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((167515, 539), (167515, 15))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((167515, 539), (167515, 15))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df_2017, promo_2017\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(pd.concat([X_train, X_val, X_test]))\n",
    "X_train[:] = scaler.transform(X_train)\n",
    "X_val[:] = scaler.transform(X_val)\n",
    "X_test[:] = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "X_val = X_val.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((670060, 539), (670060, 15))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((167515, 539), (167515, 15))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((167515, 539), (167515, 15))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Model 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "512 x 512 x 256 x 128 x 64 x 32 x 16 x 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, input_dim=X_train.shape[1]))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())\n",
    "#     model.add(Dropout(.2))\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, input_dim=X_train.shape[1]))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())\n",
    "#     model.add(Dropout(.2))\n",
    "\n",
    "    model.add(Dense(256, input_dim=X_train.shape[1]))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())\n",
    "#     model.add(Dropout(.1))\n",
    "\n",
    "    model.add(Dense(128, input_dim=X_train.shape[1]))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())\n",
    "#     model.add(Dropout(.05))\n",
    "#     model.add(Dropout(0.1))\n",
    "    \n",
    "    model.add(Dense(64))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())\n",
    "#     model.add(Dropout(.05))\n",
    "\n",
    "    model.add(Dense(32))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())\n",
    "#     model.add(Dropout(.05))\n",
    "\n",
    "    model.add(Dense(16))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())\n",
    "#     model.add(Dropout(.05))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Step 1\n",
      "==================================================\n",
      "Train on 670060 samples, validate on 167515 samples\n",
      "Epoch 1/2000\n",
      " - 25s - loss: 0.4781 - mse: 0.4497 - val_loss: 0.4373 - val_mse: 0.4373\n",
      "Epoch 2/2000\n",
      " - 22s - loss: 0.3450 - mse: 0.3256 - val_loss: 0.3397 - val_mse: 0.3397\n",
      "Epoch 3/2000\n",
      " - 21s - loss: 0.3316 - mse: 0.3134 - val_loss: 0.3265 - val_mse: 0.3265\n",
      "Epoch 4/2000\n",
      " - 22s - loss: 0.3236 - mse: 0.3061 - val_loss: 0.3211 - val_mse: 0.3211\n",
      "Epoch 5/2000\n",
      " - 22s - loss: 0.3179 - mse: 0.3008 - val_loss: 0.3223 - val_mse: 0.3223\n",
      "Epoch 6/2000\n",
      " - 22s - loss: 0.3129 - mse: 0.2962 - val_loss: 0.3209 - val_mse: 0.3209\n",
      "Epoch 7/2000\n",
      " - 22s - loss: 0.3095 - mse: 0.2931 - val_loss: 0.3212 - val_mse: 0.3212\n",
      "Epoch 8/2000\n",
      " - 23s - loss: 0.3064 - mse: 0.2901 - val_loss: 0.3224 - val_mse: 0.3224\n",
      "Epoch 9/2000\n",
      " - 22s - loss: 0.3031 - mse: 0.2871 - val_loss: 0.3226 - val_mse: 0.3226\n",
      "Epoch 10/2000\n",
      " - 23s - loss: 0.2995 - mse: 0.2838 - val_loss: 0.3260 - val_mse: 0.3260\n",
      "Epoch 11/2000\n",
      " - 23s - loss: 0.2970 - mse: 0.2814 - val_loss: 0.3235 - val_mse: 0.3235\n",
      "Epoch 12/2000\n",
      " - 22s - loss: 0.2942 - mse: 0.2788 - val_loss: 0.3278 - val_mse: 0.3278\n",
      "Epoch 13/2000\n",
      " - 22s - loss: 0.2914 - mse: 0.2762 - val_loss: 0.3297 - val_mse: 0.3297\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 14/2000\n",
      " - 22s - loss: 0.2746 - mse: 0.2607 - val_loss: 0.3256 - val_mse: 0.3256\n",
      "Epoch 15/2000\n",
      " - 22s - loss: 0.2668 - mse: 0.2535 - val_loss: 0.3265 - val_mse: 0.3265\n",
      "Epoch 16/2000\n",
      " - 22s - loss: 0.2630 - mse: 0.2499 - val_loss: 0.3289 - val_mse: 0.3289\n",
      "==================================================\n",
      "Step 2\n",
      "==================================================\n",
      "Train on 670060 samples, validate on 167515 samples\n",
      "Epoch 1/2000\n",
      " - 24s - loss: 0.5442 - mse: 0.5135 - val_loss: 0.4310 - val_mse: 0.4310\n",
      "Epoch 2/2000\n",
      " - 22s - loss: 0.3546 - mse: 0.3364 - val_loss: 0.3483 - val_mse: 0.3483\n",
      "Epoch 3/2000\n",
      " - 22s - loss: 0.3366 - mse: 0.3199 - val_loss: 0.3316 - val_mse: 0.3316\n",
      "Epoch 4/2000\n",
      " - 23s - loss: 0.3266 - mse: 0.3107 - val_loss: 0.3262 - val_mse: 0.3262\n",
      "Epoch 5/2000\n",
      " - 22s - loss: 0.3197 - mse: 0.3043 - val_loss: 0.3260 - val_mse: 0.3260\n",
      "Epoch 6/2000\n",
      " - 23s - loss: 0.3144 - mse: 0.2993 - val_loss: 0.3269 - val_mse: 0.3269\n",
      "Epoch 7/2000\n",
      " - 22s - loss: 0.3104 - mse: 0.2955 - val_loss: 0.3250 - val_mse: 0.3250\n",
      "Epoch 8/2000\n",
      " - 22s - loss: 0.3066 - mse: 0.2920 - val_loss: 0.3261 - val_mse: 0.3261\n",
      "Epoch 9/2000\n",
      " - 23s - loss: 0.3031 - mse: 0.2887 - val_loss: 0.3260 - val_mse: 0.3260\n",
      "Epoch 10/2000\n",
      " - 23s - loss: 0.3003 - mse: 0.2861 - val_loss: 0.3279 - val_mse: 0.3279\n",
      "Epoch 11/2000\n",
      " - 22s - loss: 0.2972 - mse: 0.2832 - val_loss: 0.3278 - val_mse: 0.3278\n",
      "Epoch 12/2000\n",
      " - 24s - loss: 0.2946 - mse: 0.2807 - val_loss: 0.3300 - val_mse: 0.3300\n",
      "Epoch 13/2000\n",
      " - 22s - loss: 0.2918 - mse: 0.2781 - val_loss: 0.3292 - val_mse: 0.3292\n",
      "Epoch 14/2000\n",
      " - 22s - loss: 0.2895 - mse: 0.2759 - val_loss: 0.3353 - val_mse: 0.3353\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 15/2000\n",
      " - 22s - loss: 0.2716 - mse: 0.2593 - val_loss: 0.3290 - val_mse: 0.3290\n",
      "Epoch 16/2000\n",
      " - 23s - loss: 0.2638 - mse: 0.2520 - val_loss: 0.3309 - val_mse: 0.3309\n",
      "Epoch 17/2000\n",
      " - 22s - loss: 0.2604 - mse: 0.2488 - val_loss: 0.3331 - val_mse: 0.3331\n",
      "==================================================\n",
      "Step 3\n",
      "==================================================\n",
      "Train on 670060 samples, validate on 167515 samples\n",
      "Epoch 1/2000\n",
      " - 24s - loss: 0.4578 - mse: 0.4316 - val_loss: 0.4058 - val_mse: 0.4058\n",
      "Epoch 2/2000\n",
      " - 22s - loss: 0.3662 - mse: 0.3459 - val_loss: 0.3527 - val_mse: 0.3527\n",
      "Epoch 3/2000\n",
      " - 22s - loss: 0.3553 - mse: 0.3358 - val_loss: 0.3465 - val_mse: 0.3465\n",
      "Epoch 4/2000\n",
      " - 21s - loss: 0.3485 - mse: 0.3295 - val_loss: 0.3461 - val_mse: 0.3461\n",
      "Epoch 5/2000\n",
      " - 22s - loss: 0.3431 - mse: 0.3245 - val_loss: 0.3452 - val_mse: 0.3452\n",
      "Epoch 6/2000\n",
      " - 23s - loss: 0.3383 - mse: 0.3200 - val_loss: 0.3458 - val_mse: 0.3458\n",
      "Epoch 7/2000\n",
      " - 23s - loss: 0.3344 - mse: 0.3164 - val_loss: 0.3495 - val_mse: 0.3495\n",
      "Epoch 8/2000\n",
      " - 22s - loss: 0.3309 - mse: 0.3132 - val_loss: 0.3522 - val_mse: 0.3522\n",
      "Epoch 9/2000\n",
      " - 22s - loss: 0.3270 - mse: 0.3096 - val_loss: 0.3479 - val_mse: 0.3479\n",
      "Epoch 10/2000\n",
      " - 22s - loss: 0.3245 - mse: 0.3072 - val_loss: 0.3499 - val_mse: 0.3499\n",
      "Epoch 11/2000\n",
      " - 22s - loss: 0.3209 - mse: 0.3039 - val_loss: 0.3542 - val_mse: 0.3542\n",
      "Epoch 12/2000\n",
      " - 23s - loss: 0.3180 - mse: 0.3012 - val_loss: 0.3584 - val_mse: 0.3584\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 13/2000\n",
      " - 22s - loss: 0.3003 - mse: 0.2848 - val_loss: 0.3521 - val_mse: 0.3521\n",
      "Epoch 14/2000\n",
      " - 22s - loss: 0.2920 - mse: 0.2771 - val_loss: 0.3541 - val_mse: 0.3541\n",
      "Epoch 15/2000\n",
      " - 23s - loss: 0.2878 - mse: 0.2733 - val_loss: 0.3569 - val_mse: 0.3569\n",
      "==================================================\n",
      "Step 4\n",
      "==================================================\n",
      "Train on 670060 samples, validate on 167515 samples\n",
      "Epoch 1/2000\n",
      " - 31s - loss: 0.4961 - mse: 0.4670 - val_loss: 0.4135 - val_mse: 0.4135\n",
      "Epoch 2/2000\n",
      " - 34s - loss: 0.3689 - mse: 0.3497 - val_loss: 0.3623 - val_mse: 0.3623\n",
      "Epoch 3/2000\n",
      " - 27s - loss: 0.3538 - mse: 0.3358 - val_loss: 0.3461 - val_mse: 0.3461\n",
      "Epoch 4/2000\n",
      " - 27s - loss: 0.3451 - mse: 0.3278 - val_loss: 0.3447 - val_mse: 0.3447\n",
      "Epoch 5/2000\n",
      " - 27s - loss: 0.3388 - mse: 0.3219 - val_loss: 0.3479 - val_mse: 0.3479\n",
      "Epoch 6/2000\n",
      " - 27s - loss: 0.3337 - mse: 0.3172 - val_loss: 0.3449 - val_mse: 0.3449\n",
      "Epoch 7/2000\n",
      " - 40s - loss: 0.3296 - mse: 0.3134 - val_loss: 0.3463 - val_mse: 0.3463\n",
      "Epoch 8/2000\n",
      " - 64s - loss: 0.3258 - mse: 0.3098 - val_loss: 0.3474 - val_mse: 0.3474\n",
      "Epoch 9/2000\n",
      " - 27s - loss: 0.3219 - mse: 0.3062 - val_loss: 0.3502 - val_mse: 0.3502\n",
      "Epoch 10/2000\n",
      " - 29s - loss: 0.3184 - mse: 0.3030 - val_loss: 0.3509 - val_mse: 0.3509\n",
      "Epoch 11/2000\n",
      " - 28s - loss: 0.3153 - mse: 0.3000 - val_loss: 0.3530 - val_mse: 0.3530\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 12/2000\n",
      " - 28s - loss: 0.2986 - mse: 0.2845 - val_loss: 0.3470 - val_mse: 0.3470\n",
      "Epoch 13/2000\n",
      " - 51s - loss: 0.2915 - mse: 0.2779 - val_loss: 0.3487 - val_mse: 0.3487\n",
      "Epoch 14/2000\n",
      " - 51s - loss: 0.2881 - mse: 0.2748 - val_loss: 0.3514 - val_mse: 0.3514\n",
      "==================================================\n",
      "Step 5\n",
      "==================================================\n",
      "Train on 670060 samples, validate on 167515 samples\n",
      "Epoch 1/2000\n",
      " - 25s - loss: 0.4921 - mse: 0.4644 - val_loss: 0.3967 - val_mse: 0.3967\n",
      "Epoch 2/2000\n",
      " - 22s - loss: 0.3879 - mse: 0.3670 - val_loss: 0.3670 - val_mse: 0.3670\n",
      "Epoch 3/2000\n",
      " - 22s - loss: 0.3747 - mse: 0.3547 - val_loss: 0.3636 - val_mse: 0.3636\n",
      "Epoch 4/2000\n",
      " - 23s - loss: 0.3666 - mse: 0.3471 - val_loss: 0.3642 - val_mse: 0.3642\n",
      "Epoch 5/2000\n",
      " - 22s - loss: 0.3597 - mse: 0.3407 - val_loss: 0.3627 - val_mse: 0.3627\n",
      "Epoch 6/2000\n",
      " - 24s - loss: 0.3543 - mse: 0.3358 - val_loss: 0.3635 - val_mse: 0.3635\n",
      "Epoch 7/2000\n",
      " - 25s - loss: 0.3497 - mse: 0.3315 - val_loss: 0.3671 - val_mse: 0.3671\n",
      "Epoch 8/2000\n",
      " - 24s - loss: 0.3451 - mse: 0.3272 - val_loss: 0.3717 - val_mse: 0.3717\n",
      "Epoch 9/2000\n",
      " - 24s - loss: 0.3413 - mse: 0.3237 - val_loss: 0.3776 - val_mse: 0.3776\n",
      "Epoch 10/2000\n",
      " - 30s - loss: 0.3377 - mse: 0.3203 - val_loss: 0.3729 - val_mse: 0.3729\n",
      "Epoch 11/2000\n",
      " - 30s - loss: 0.3332 - mse: 0.3161 - val_loss: 0.3752 - val_mse: 0.3752\n",
      "Epoch 12/2000\n",
      " - 23s - loss: 0.3292 - mse: 0.3124 - val_loss: 0.3782 - val_mse: 0.3782\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 13/2000\n",
      " - 21s - loss: 0.3088 - mse: 0.2934 - val_loss: 0.3742 - val_mse: 0.3742\n",
      "Epoch 14/2000\n",
      " - 24s - loss: 0.2992 - mse: 0.2845 - val_loss: 0.3773 - val_mse: 0.3773\n",
      "Epoch 15/2000\n",
      " - 23s - loss: 0.2945 - mse: 0.2802 - val_loss: 0.3806 - val_mse: 0.3806\n",
      "==================================================\n",
      "Step 6\n",
      "==================================================\n",
      "Train on 670060 samples, validate on 167515 samples\n",
      "Epoch 1/2000\n",
      " - 31s - loss: 0.5174 - mse: 0.4879 - val_loss: 0.4155 - val_mse: 0.4155\n",
      "Epoch 2/2000\n",
      " - 73s - loss: 0.4010 - mse: 0.3793 - val_loss: 0.3895 - val_mse: 0.3895\n",
      "Epoch 3/2000\n",
      " - 29s - loss: 0.3850 - mse: 0.3645 - val_loss: 0.3773 - val_mse: 0.3773\n",
      "Epoch 4/2000\n",
      " - 28s - loss: 0.3750 - mse: 0.3552 - val_loss: 0.3763 - val_mse: 0.3763\n",
      "Epoch 5/2000\n",
      " - 32s - loss: 0.3672 - mse: 0.3480 - val_loss: 0.3792 - val_mse: 0.3792\n",
      "Epoch 6/2000\n",
      " - 30s - loss: 0.3612 - mse: 0.3424 - val_loss: 0.3782 - val_mse: 0.3782\n",
      "Epoch 7/2000\n",
      " - 46s - loss: 0.3562 - mse: 0.3378 - val_loss: 0.3785 - val_mse: 0.3785\n",
      "Epoch 8/2000\n",
      " - 60s - loss: 0.3517 - mse: 0.3335 - val_loss: 0.3868 - val_mse: 0.3868\n",
      "Epoch 9/2000\n",
      " - 29s - loss: 0.3476 - mse: 0.3298 - val_loss: 0.3837 - val_mse: 0.3837\n",
      "Epoch 10/2000\n",
      " - 29s - loss: 0.3431 - mse: 0.3257 - val_loss: 0.3842 - val_mse: 0.3842\n",
      "Epoch 11/2000\n",
      " - 44s - loss: 0.3388 - mse: 0.3216 - val_loss: 0.3898 - val_mse: 0.3898\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 12/2000\n",
      " - 35s - loss: 0.3201 - mse: 0.3042 - val_loss: 0.3858 - val_mse: 0.3858\n",
      "Epoch 13/2000\n",
      " - 29s - loss: 0.3112 - mse: 0.2960 - val_loss: 0.3883 - val_mse: 0.3883\n",
      "Epoch 14/2000\n",
      " - 37s - loss: 0.3071 - mse: 0.2921 - val_loss: 0.3911 - val_mse: 0.3911\n",
      "==================================================\n",
      "Step 7\n",
      "==================================================\n",
      "Train on 670060 samples, validate on 167515 samples\n",
      "Epoch 1/2000\n",
      " - 29s - loss: 0.5029 - mse: 0.4732 - val_loss: 0.4181 - val_mse: 0.4181\n",
      "Epoch 2/2000\n",
      " - 35s - loss: 0.3880 - mse: 0.3658 - val_loss: 0.3805 - val_mse: 0.3805\n",
      "Epoch 3/2000\n",
      " - 34s - loss: 0.3743 - mse: 0.3531 - val_loss: 0.3714 - val_mse: 0.3714\n",
      "Epoch 4/2000\n",
      " - 28s - loss: 0.3669 - mse: 0.3463 - val_loss: 0.3705 - val_mse: 0.3705\n",
      "Epoch 5/2000\n",
      " - 27s - loss: 0.3610 - mse: 0.3408 - val_loss: 0.3735 - val_mse: 0.3735\n",
      "Epoch 6/2000\n",
      " - 30s - loss: 0.3557 - mse: 0.3359 - val_loss: 0.3730 - val_mse: 0.3730\n",
      "Epoch 7/2000\n",
      " - 28s - loss: 0.3514 - mse: 0.3319 - val_loss: 0.3738 - val_mse: 0.3738\n",
      "Epoch 8/2000\n",
      " - 28s - loss: 0.3477 - mse: 0.3285 - val_loss: 0.3738 - val_mse: 0.3738\n",
      "Epoch 9/2000\n",
      " - 32s - loss: 0.3432 - mse: 0.3243 - val_loss: 0.3749 - val_mse: 0.3749\n",
      "Epoch 10/2000\n",
      " - 36s - loss: 0.3392 - mse: 0.3206 - val_loss: 0.3785 - val_mse: 0.3785\n",
      "Epoch 11/2000\n",
      " - 29s - loss: 0.3360 - mse: 0.3177 - val_loss: 0.3783 - val_mse: 0.3783\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 12/2000\n",
      " - 27s - loss: 0.3169 - mse: 0.3000 - val_loss: 0.3795 - val_mse: 0.3795\n",
      "Epoch 13/2000\n",
      " - 35s - loss: 0.3083 - mse: 0.2921 - val_loss: 0.3814 - val_mse: 0.3814\n",
      "Epoch 14/2000\n",
      " - 27s - loss: 0.3042 - mse: 0.2883 - val_loss: 0.3838 - val_mse: 0.3838\n",
      "==================================================\n",
      "Step 8\n",
      "==================================================\n",
      "Train on 670060 samples, validate on 167515 samples\n",
      "Epoch 1/2000\n",
      " - 29s - loss: 0.4804 - mse: 0.4527 - val_loss: 0.3939 - val_mse: 0.3939\n",
      "Epoch 2/2000\n",
      " - 24s - loss: 0.3760 - mse: 0.3555 - val_loss: 0.3647 - val_mse: 0.3647\n",
      "Epoch 3/2000\n",
      " - 23s - loss: 0.3629 - mse: 0.3435 - val_loss: 0.3594 - val_mse: 0.3594\n",
      "Epoch 4/2000\n",
      " - 23s - loss: 0.3545 - mse: 0.3358 - val_loss: 0.3592 - val_mse: 0.3592\n",
      "Epoch 5/2000\n",
      " - 24s - loss: 0.3485 - mse: 0.3303 - val_loss: 0.3579 - val_mse: 0.3579\n",
      "Epoch 6/2000\n",
      " - 24s - loss: 0.3435 - mse: 0.3256 - val_loss: 0.3604 - val_mse: 0.3604\n",
      "Epoch 7/2000\n",
      " - 23s - loss: 0.3391 - mse: 0.3216 - val_loss: 0.3602 - val_mse: 0.3602\n",
      "Epoch 8/2000\n",
      " - 29s - loss: 0.3357 - mse: 0.3184 - val_loss: 0.3633 - val_mse: 0.3633\n",
      "Epoch 9/2000\n",
      " - 24s - loss: 0.3320 - mse: 0.3149 - val_loss: 0.3648 - val_mse: 0.3648\n",
      "Epoch 10/2000\n",
      " - 25s - loss: 0.3286 - mse: 0.3117 - val_loss: 0.3652 - val_mse: 0.3652\n",
      "Epoch 11/2000\n",
      " - 25s - loss: 0.3252 - mse: 0.3086 - val_loss: 0.3689 - val_mse: 0.3689\n",
      "Epoch 12/2000\n",
      " - 23s - loss: 0.3220 - mse: 0.3056 - val_loss: 0.3720 - val_mse: 0.3720\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 13/2000\n",
      " - 22s - loss: 0.3038 - mse: 0.2887 - val_loss: 0.3692 - val_mse: 0.3692\n",
      "Epoch 14/2000\n",
      " - 24s - loss: 0.2953 - mse: 0.2809 - val_loss: 0.3716 - val_mse: 0.3716\n",
      "Epoch 15/2000\n",
      " - 25s - loss: 0.2914 - mse: 0.2772 - val_loss: 0.3734 - val_mse: 0.3734\n",
      "==================================================\n",
      "Step 9\n",
      "==================================================\n",
      "Train on 670060 samples, validate on 167515 samples\n",
      "Epoch 1/2000\n",
      " - 27s - loss: 0.4921 - mse: 0.4649 - val_loss: 0.4046 - val_mse: 0.4046\n",
      "Epoch 2/2000\n",
      " - 59s - loss: 0.3640 - mse: 0.3459 - val_loss: 0.3605 - val_mse: 0.3605\n",
      "Epoch 3/2000\n",
      " - 30s - loss: 0.3472 - mse: 0.3306 - val_loss: 0.3536 - val_mse: 0.3536\n",
      "Epoch 4/2000\n",
      " - 31s - loss: 0.3386 - mse: 0.3227 - val_loss: 0.3515 - val_mse: 0.3515\n",
      "Epoch 5/2000\n",
      " - 24s - loss: 0.3326 - mse: 0.3170 - val_loss: 0.3506 - val_mse: 0.3506\n",
      "Epoch 6/2000\n",
      " - 23s - loss: 0.3276 - mse: 0.3124 - val_loss: 0.3530 - val_mse: 0.3530\n",
      "Epoch 7/2000\n",
      " - 23s - loss: 0.3233 - mse: 0.3084 - val_loss: 0.3551 - val_mse: 0.3551\n",
      "Epoch 8/2000\n",
      " - 40s - loss: 0.3201 - mse: 0.3054 - val_loss: 0.3542 - val_mse: 0.3542\n",
      "Epoch 9/2000\n",
      " - 56s - loss: 0.3164 - mse: 0.3018 - val_loss: 0.3560 - val_mse: 0.3560\n",
      "Epoch 10/2000\n",
      " - 31s - loss: 0.3130 - mse: 0.2987 - val_loss: 0.3594 - val_mse: 0.3594\n",
      "Epoch 11/2000\n",
      " - 27s - loss: 0.3100 - mse: 0.2958 - val_loss: 0.3600 - val_mse: 0.3600\n",
      "Epoch 12/2000\n",
      " - 22s - loss: 0.3066 - mse: 0.2926 - val_loss: 0.3626 - val_mse: 0.3626\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 13/2000\n",
      " - 22s - loss: 0.2893 - mse: 0.2765 - val_loss: 0.3588 - val_mse: 0.3588\n",
      "Epoch 14/2000\n",
      " - 22s - loss: 0.2812 - mse: 0.2689 - val_loss: 0.3618 - val_mse: 0.3618\n",
      "Epoch 15/2000\n",
      " - 56s - loss: 0.2774 - mse: 0.2654 - val_loss: 0.3635 - val_mse: 0.3635\n",
      "==================================================\n",
      "Step 10\n",
      "==================================================\n",
      "Train on 670060 samples, validate on 167515 samples\n",
      "Epoch 1/2000\n",
      " - 21s - loss: 0.6232 - mse: 0.5886 - val_loss: 0.4139 - val_mse: 0.4139\n",
      "Epoch 2/2000\n",
      " - 19s - loss: 0.3783 - mse: 0.3573 - val_loss: 0.3808 - val_mse: 0.3808\n",
      "Epoch 3/2000\n",
      " - 20s - loss: 0.3617 - mse: 0.3418 - val_loss: 0.3715 - val_mse: 0.3715\n",
      "Epoch 4/2000\n",
      " - 19s - loss: 0.3526 - mse: 0.3334 - val_loss: 0.3716 - val_mse: 0.3716\n",
      "Epoch 5/2000\n",
      " - 19s - loss: 0.3453 - mse: 0.3267 - val_loss: 0.3733 - val_mse: 0.3733\n",
      "Epoch 6/2000\n",
      " - 19s - loss: 0.3402 - mse: 0.3219 - val_loss: 0.3767 - val_mse: 0.3767\n",
      "Epoch 7/2000\n",
      " - 19s - loss: 0.3355 - mse: 0.3176 - val_loss: 0.3769 - val_mse: 0.3769\n",
      "Epoch 8/2000\n",
      " - 19s - loss: 0.3319 - mse: 0.3142 - val_loss: 0.3755 - val_mse: 0.3755\n",
      "Epoch 9/2000\n",
      " - 19s - loss: 0.3282 - mse: 0.3107 - val_loss: 0.3826 - val_mse: 0.3826\n",
      "Epoch 10/2000\n",
      " - 19s - loss: 0.3247 - mse: 0.3075 - val_loss: 0.3795 - val_mse: 0.3795\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 11/2000\n",
      " - 23s - loss: 0.3084 - mse: 0.2923 - val_loss: 0.3792 - val_mse: 0.3792\n",
      "Epoch 12/2000\n",
      " - 25s - loss: 0.3025 - mse: 0.2869 - val_loss: 0.3820 - val_mse: 0.3820\n",
      "Epoch 13/2000\n",
      " - 19s - loss: 0.2998 - mse: 0.2844 - val_loss: 0.3810 - val_mse: 0.3810\n",
      "==================================================\n",
      "Step 11\n",
      "==================================================\n",
      "Train on 670060 samples, validate on 167515 samples\n",
      "Epoch 1/2000\n",
      " - 21s - loss: 0.5229 - mse: 0.4937 - val_loss: 0.4268 - val_mse: 0.4268\n",
      "Epoch 2/2000\n",
      " - 20s - loss: 0.3782 - mse: 0.3586 - val_loss: 0.3811 - val_mse: 0.3811\n",
      "Epoch 3/2000\n",
      " - 19s - loss: 0.3609 - mse: 0.3427 - val_loss: 0.3714 - val_mse: 0.3714\n",
      "Epoch 4/2000\n",
      " - 19s - loss: 0.3514 - mse: 0.3340 - val_loss: 0.3664 - val_mse: 0.3664\n",
      "Epoch 5/2000\n",
      " - 19s - loss: 0.3449 - mse: 0.3279 - val_loss: 0.3661 - val_mse: 0.3661\n",
      "Epoch 6/2000\n",
      " - 19s - loss: 0.3388 - mse: 0.3222 - val_loss: 0.3663 - val_mse: 0.3663\n",
      "Epoch 7/2000\n",
      " - 19s - loss: 0.3344 - mse: 0.3182 - val_loss: 0.3702 - val_mse: 0.3702\n",
      "Epoch 8/2000\n",
      " - 19s - loss: 0.3303 - mse: 0.3144 - val_loss: 0.3693 - val_mse: 0.3693\n",
      "Epoch 9/2000\n",
      " - 25s - loss: 0.3261 - mse: 0.3105 - val_loss: 0.3759 - val_mse: 0.3759\n",
      "Epoch 10/2000\n",
      " - 19s - loss: 0.3232 - mse: 0.3077 - val_loss: 0.3757 - val_mse: 0.3757\n",
      "Epoch 11/2000\n",
      " - 19s - loss: 0.3195 - mse: 0.3042 - val_loss: 0.3778 - val_mse: 0.3778\n",
      "Epoch 12/2000\n",
      " - 20s - loss: 0.3166 - mse: 0.3015 - val_loss: 0.3765 - val_mse: 0.3765\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 13/2000\n",
      " - 20s - loss: 0.2975 - mse: 0.2838 - val_loss: 0.3754 - val_mse: 0.3754\n",
      "Epoch 14/2000\n",
      " - 19s - loss: 0.2893 - mse: 0.2761 - val_loss: 0.3769 - val_mse: 0.3769\n",
      "Epoch 15/2000\n",
      " - 21s - loss: 0.2856 - mse: 0.2726 - val_loss: 0.3796 - val_mse: 0.3796\n",
      "==================================================\n",
      "Step 12\n",
      "==================================================\n",
      "Train on 670060 samples, validate on 167515 samples\n",
      "Epoch 1/2000\n",
      " - 23s - loss: 0.5678 - mse: 0.5369 - val_loss: 0.4407 - val_mse: 0.4407\n",
      "Epoch 2/2000\n",
      " - 20s - loss: 0.4151 - mse: 0.3930 - val_loss: 0.4106 - val_mse: 0.4106\n",
      "Epoch 3/2000\n",
      " - 28s - loss: 0.3980 - mse: 0.3771 - val_loss: 0.4032 - val_mse: 0.4032\n",
      "Epoch 4/2000\n",
      " - 57s - loss: 0.3872 - mse: 0.3671 - val_loss: 0.4057 - val_mse: 0.4057\n",
      "Epoch 5/2000\n",
      " - 23s - loss: 0.3791 - mse: 0.3595 - val_loss: 0.4025 - val_mse: 0.4025\n",
      "Epoch 6/2000\n",
      " - 21s - loss: 0.3727 - mse: 0.3536 - val_loss: 0.4010 - val_mse: 0.4010\n",
      "Epoch 7/2000\n",
      " - 23s - loss: 0.3669 - mse: 0.3482 - val_loss: 0.4066 - val_mse: 0.4066\n",
      "Epoch 8/2000\n",
      " - 22s - loss: 0.3624 - mse: 0.3439 - val_loss: 0.4030 - val_mse: 0.4030\n",
      "Epoch 9/2000\n",
      " - 21s - loss: 0.3580 - mse: 0.3399 - val_loss: 0.4097 - val_mse: 0.4097\n",
      "Epoch 10/2000\n",
      " - 22s - loss: 0.3538 - mse: 0.3360 - val_loss: 0.4124 - val_mse: 0.4124\n",
      "Epoch 11/2000\n",
      " - 21s - loss: 0.3502 - mse: 0.3326 - val_loss: 0.4097 - val_mse: 0.4097\n",
      "Epoch 12/2000\n",
      " - 21s - loss: 0.3458 - mse: 0.3285 - val_loss: 0.4229 - val_mse: 0.4229\n",
      "Epoch 13/2000\n",
      " - 22s - loss: 0.3424 - mse: 0.3253 - val_loss: 0.4231 - val_mse: 0.4231\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 14/2000\n",
      " - 26s - loss: 0.3207 - mse: 0.3051 - val_loss: 0.4093 - val_mse: 0.4093\n",
      "Epoch 15/2000\n",
      " - 22s - loss: 0.3112 - mse: 0.2964 - val_loss: 0.4133 - val_mse: 0.4133\n",
      "Epoch 16/2000\n",
      " - 22s - loss: 0.3067 - mse: 0.2922 - val_loss: 0.4162 - val_mse: 0.4162\n",
      "==================================================\n",
      "Step 13\n",
      "==================================================\n",
      "Train on 670060 samples, validate on 167515 samples\n",
      "Epoch 1/2000\n",
      " - 40s - loss: 0.5070 - mse: 0.4790 - val_loss: 0.4568 - val_mse: 0.4568\n",
      "Epoch 2/2000\n",
      " - 25s - loss: 0.4163 - mse: 0.3942 - val_loss: 0.4139 - val_mse: 0.4139\n",
      "Epoch 3/2000\n",
      " - 25s - loss: 0.3998 - mse: 0.3789 - val_loss: 0.4127 - val_mse: 0.4127\n",
      "Epoch 4/2000\n",
      " - 24s - loss: 0.3899 - mse: 0.3697 - val_loss: 0.4080 - val_mse: 0.4080\n",
      "Epoch 5/2000\n",
      " - 71s - loss: 0.3816 - mse: 0.3620 - val_loss: 0.4134 - val_mse: 0.4134\n",
      "Epoch 6/2000\n",
      " - 36s - loss: 0.3750 - mse: 0.3559 - val_loss: 0.4081 - val_mse: 0.4081\n",
      "Epoch 7/2000\n",
      " - 37s - loss: 0.3692 - mse: 0.3505 - val_loss: 0.4137 - val_mse: 0.4137\n",
      "Epoch 8/2000\n",
      " - 24s - loss: 0.3648 - mse: 0.3463 - val_loss: 0.4222 - val_mse: 0.4222\n",
      "Epoch 9/2000\n",
      " - 24s - loss: 0.3596 - mse: 0.3415 - val_loss: 0.4198 - val_mse: 0.4198\n",
      "Epoch 10/2000\n",
      " - 24s - loss: 0.3552 - mse: 0.3375 - val_loss: 0.4238 - val_mse: 0.4238\n",
      "Epoch 11/2000\n",
      " - 67s - loss: 0.3508 - mse: 0.3333 - val_loss: 0.4388 - val_mse: 0.4388\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 12/2000\n",
      " - 38s - loss: 0.3291 - mse: 0.3132 - val_loss: 0.4210 - val_mse: 0.4210\n",
      "Epoch 13/2000\n",
      " - 36s - loss: 0.3192 - mse: 0.3040 - val_loss: 0.4236 - val_mse: 0.4236\n",
      "Epoch 14/2000\n",
      " - 25s - loss: 0.3142 - mse: 0.2994 - val_loss: 0.4282 - val_mse: 0.4282\n",
      "==================================================\n",
      "Step 14\n",
      "==================================================\n",
      "Train on 670060 samples, validate on 167515 samples\n",
      "Epoch 1/2000\n",
      " - 92s - loss: 0.5446 - mse: 0.5128 - val_loss: 0.4581 - val_mse: 0.4581\n",
      "Epoch 2/2000\n",
      " - 44s - loss: 0.4046 - mse: 0.3819 - val_loss: 0.4109 - val_mse: 0.4109\n",
      "Epoch 3/2000\n",
      " - 30s - loss: 0.3898 - mse: 0.3682 - val_loss: 0.4076 - val_mse: 0.4076\n",
      "Epoch 4/2000\n",
      " - 29s - loss: 0.3803 - mse: 0.3594 - val_loss: 0.4055 - val_mse: 0.4055\n",
      "Epoch 5/2000\n",
      " - 28s - loss: 0.3738 - mse: 0.3534 - val_loss: 0.4041 - val_mse: 0.4041\n",
      "Epoch 6/2000\n",
      " - 27s - loss: 0.3677 - mse: 0.3477 - val_loss: 0.4062 - val_mse: 0.4062\n",
      "Epoch 7/2000\n",
      " - 27s - loss: 0.3627 - mse: 0.3431 - val_loss: 0.4073 - val_mse: 0.4073\n",
      "Epoch 8/2000\n",
      " - 104s - loss: 0.3583 - mse: 0.3390 - val_loss: 0.4088 - val_mse: 0.4088\n",
      "Epoch 9/2000\n",
      " - 29s - loss: 0.3545 - mse: 0.3355 - val_loss: 0.4152 - val_mse: 0.4152\n",
      "Epoch 10/2000\n",
      " - 26s - loss: 0.3508 - mse: 0.3320 - val_loss: 0.4147 - val_mse: 0.4147\n",
      "Epoch 11/2000\n",
      " - 26s - loss: 0.3463 - mse: 0.3278 - val_loss: 0.4192 - val_mse: 0.4192\n",
      "Epoch 12/2000\n",
      " - 26s - loss: 0.3429 - mse: 0.3246 - val_loss: 0.4218 - val_mse: 0.4218\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 13/2000\n",
      " - 34s - loss: 0.3222 - mse: 0.3056 - val_loss: 0.4180 - val_mse: 0.4180\n",
      "Epoch 14/2000\n",
      " - 41s - loss: 0.3131 - mse: 0.2971 - val_loss: 0.4197 - val_mse: 0.4197\n",
      "Epoch 15/2000\n",
      " - 86s - loss: 0.3089 - mse: 0.2932 - val_loss: 0.4215 - val_mse: 0.4215\n",
      "==================================================\n",
      "Step 15\n",
      "==================================================\n",
      "Train on 670060 samples, validate on 167515 samples\n",
      "Epoch 1/2000\n",
      " - 119s - loss: 0.5988 - mse: 0.5643 - val_loss: 0.4643 - val_mse: 0.4643\n",
      "Epoch 2/2000\n",
      " - 122s - loss: 0.4008 - mse: 0.3787 - val_loss: 0.4138 - val_mse: 0.4138\n",
      "Epoch 3/2000\n",
      " - 136s - loss: 0.3820 - mse: 0.3613 - val_loss: 0.4009 - val_mse: 0.4009\n",
      "Epoch 4/2000\n",
      " - 128s - loss: 0.3715 - mse: 0.3516 - val_loss: 0.3966 - val_mse: 0.3966\n",
      "Epoch 5/2000\n",
      " - 115s - loss: 0.3643 - mse: 0.3449 - val_loss: 0.3965 - val_mse: 0.3965\n",
      "Epoch 6/2000\n",
      " - 95s - loss: 0.3585 - mse: 0.3395 - val_loss: 0.4023 - val_mse: 0.4023\n",
      "Epoch 7/2000\n",
      " - 114s - loss: 0.3536 - mse: 0.3350 - val_loss: 0.4021 - val_mse: 0.4021\n",
      "Epoch 8/2000\n",
      " - 116s - loss: 0.3494 - mse: 0.3310 - val_loss: 0.4018 - val_mse: 0.4018\n",
      "Epoch 9/2000\n",
      " - 112s - loss: 0.3450 - mse: 0.3268 - val_loss: 0.4066 - val_mse: 0.4066\n",
      "Epoch 10/2000\n",
      " - 117s - loss: 0.3417 - mse: 0.3238 - val_loss: 0.4055 - val_mse: 0.4055\n",
      "Epoch 11/2000\n",
      " - 115s - loss: 0.3374 - mse: 0.3198 - val_loss: 0.4135 - val_mse: 0.4135\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 12/2000\n",
      " - 126s - loss: 0.3187 - mse: 0.3024 - val_loss: 0.4060 - val_mse: 0.4060\n",
      "Epoch 13/2000\n",
      " - 114s - loss: 0.3105 - mse: 0.2949 - val_loss: 0.4078 - val_mse: 0.4078\n",
      "Epoch 14/2000\n",
      " - 106s - loss: 0.3071 - mse: 0.2917 - val_loss: 0.4094 - val_mse: 0.4094\n",
      "Epoch 15/2000\n",
      " - 124s - loss: 0.3045 - mse: 0.2892 - val_loss: 0.4121 - val_mse: 0.4121\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 2000\n",
    "\n",
    "val_pred = []\n",
    "test_pred = []\n",
    "# wtpath = 'weights.hdf5'  # To save best epoch. But need Keras bug to be fixed first.\n",
    "sample_weights=np.array( pd.concat([items[\"perishable\"]] * num_days) * 0.25 + 1 )\n",
    "for i in range(15):\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Step %d\" % (i+1))\n",
    "    print(\"=\" * 50)\n",
    "    y = y_train[:, i]\n",
    "    y_mean = y.mean()\n",
    "    xv = X_val\n",
    "    yv = y_val[:, i]\n",
    "    model = build_model()\n",
    "\n",
    "    opt = optimizers.Adam(lr=0.001)\n",
    "#     opt = optimizers.RMSprop(learning_rate=0.001, rho=0.9)\n",
    "    model.compile(loss='mse', optimizer=opt, metrics=['mse'])\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=10, verbose=0),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=7, verbose=1, min_delta=1e-4, mode='min')\n",
    "        ]\n",
    "    \n",
    "    #smaller batch size runs faster\n",
    "    #batch_size = 65536\n",
    "    batch_size = 8192\n",
    "\n",
    "    model.fit(X_train, y - y_mean, batch_size = batch_size, epochs = N_EPOCHS, verbose=2,\n",
    "               sample_weight=sample_weights, validation_data=(xv,yv-y_mean), callbacks=callbacks )\n",
    "    val_pred.append(model.predict(X_val)+y_mean)\n",
    "    test_pred.append(model.predict(X_test)+y_mean)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nwrmsle = 0.6169081629472548\n"
     ]
    }
   ],
   "source": [
    "weight = items[\"perishable\"] * 0.25 + 1\n",
    "val_err = (y_val - np.array(val_pred).squeeze(axis=2).transpose())**2\n",
    "val_err = val_err.sum(axis=1) * weight\n",
    "#change to 15 days\n",
    "val_err = np.sqrt(val_err.sum() / weight.sum() / 15)\n",
    "print('nwrmsle = {}'.format(val_err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nwrmsle = 0.6301074060228535\n"
     ]
    }
   ],
   "source": [
    "test_err = (y_test - np.array(test_pred).squeeze(axis=2).transpose())**2\n",
    "test_err = test_err.sum(axis=1) * weight\n",
    "#change to 15 days\n",
    "test_err = np.sqrt(test_err.sum() / weight.sum() / 15)\n",
    "print('nwrmsle = {}'.format(test_err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2017_index = pd.read_csv('../derived_datasets/df_2017_index.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2017_index = df_2017_index.set_index([0,1]).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_test = pd.DataFrame(np.array(test_pred).squeeze(axis=2).transpose(), \n",
    "                            index = df_2017_index, columns = pd.date_range('2017-08-01',periods=15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_test.to_csv('../derived_datasets/nn_test_pred_model_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
