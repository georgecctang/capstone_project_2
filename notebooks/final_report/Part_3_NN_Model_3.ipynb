{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference Dates\n",
    "\n",
    "Num Training Weeks = 4  \n",
    "Num Test/Val Days = 15\n",
    "\n",
    "- Train: 5/30/2017 (Tues), 6/6/2017,6/13/2017,6/20/2017  \n",
    "- Val: 7/11/2017 (Tues) - 7/25/2017 (Wed)  \n",
    "- Test: 8/1/2017 (Tues)  - 8/15/2017 (Wed)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.41.0)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (0.25.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.17.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.6.1->pandas) (1.11.0)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.22)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (0.14.1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.17.2)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.3.1)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.17.2)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (5.2)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.8)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/lib/python3/dist-packages (from keras) (1.11.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras) (1.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm\n",
    "!pip install  pandas\n",
    "!pip install sklearn\n",
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import callbacks\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\n",
    "    '../input/train.csv', usecols=[1, 2, 3, 4, 5],\n",
    "    dtype={'onpromotion': bool},\n",
    "    converters={'unit_sales': lambda u: np.log1p(\n",
    "        float(u)) if float(u) > 0 else 0},\n",
    "    parse_dates=[\"date\"],\n",
    "    skiprows=range(1, 66458909)  # 2016-01-01\n",
    ")\n",
    "\n",
    "df_test = pd.read_csv(\n",
    "    \"../input/test.csv\", usecols=[0, 1, 2, 3, 4],\n",
    "    dtype={'onpromotion': bool},\n",
    "    parse_dates=[\"date\"]  # , date_parser=parser\n",
    ").set_index(\n",
    "    ['store_nbr', 'item_nbr', 'date']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = pd.read_csv(\n",
    "    \"../input/items.csv\",\n",
    ").set_index(\"item_nbr\")\n",
    "\n",
    "stores = pd.read_csv(\n",
    "    \"../input/stores.csv\",\n",
    ").set_index(\"store_nbr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family</th>\n",
       "      <th>class</th>\n",
       "      <th>perishable</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_nbr</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96995</th>\n",
       "      <td>GROCERY I</td>\n",
       "      <td>1093</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99197</th>\n",
       "      <td>GROCERY I</td>\n",
       "      <td>1067</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103501</th>\n",
       "      <td>CLEANING</td>\n",
       "      <td>3008</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103520</th>\n",
       "      <td>GROCERY I</td>\n",
       "      <td>1028</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103665</th>\n",
       "      <td>BREAD/BAKERY</td>\n",
       "      <td>2712</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                family  class  perishable\n",
       "item_nbr                                 \n",
       "96995        GROCERY I   1093           0\n",
       "99197        GROCERY I   1067           0\n",
       "103501        CLEANING   3008           0\n",
       "103520       GROCERY I   1028           0\n",
       "103665    BREAD/BAKERY   2712           1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>type</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_nbr</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Santo Domingo</td>\n",
       "      <td>Santo Domingo de los Tsachilas</td>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    city                           state type  cluster\n",
       "store_nbr                                                             \n",
       "1                  Quito                       Pichincha    D       13\n",
       "2                  Quito                       Pichincha    D       13\n",
       "3                  Quito                       Pichincha    D        8\n",
       "4                  Quito                       Pichincha    D        9\n",
       "5          Santo Domingo  Santo Domingo de los Tsachilas    D        4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2017 = df_train.loc[df_train.date>=pd.datetime(2017,1,1)]\n",
    "del df_train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>unit_sales</th>\n",
       "      <th>onpromotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35229871</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>25</td>\n",
       "      <td>99197</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35229872</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>25</td>\n",
       "      <td>103665</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35229873</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>25</td>\n",
       "      <td>105574</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35229874</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>25</td>\n",
       "      <td>105857</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35229875</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>25</td>\n",
       "      <td>106716</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               date  store_nbr  item_nbr  unit_sales  onpromotion\n",
       "35229871 2017-01-01         25     99197    0.693147        False\n",
       "35229872 2017-01-01         25    103665    2.079442        False\n",
       "35229873 2017-01-01         25    105574    0.693147        False\n",
       "35229874 2017-01-01         25    105857    1.609438        False\n",
       "35229875 2017-01-01         25    106716    1.098612        False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2017.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "promo_2017_train = df_2017.set_index(\n",
    "    [\"store_nbr\", \"item_nbr\", \"date\"])[[\"onpromotion\"]].unstack(\n",
    "        level=-1).fillna(False)\n",
    "promo_2017_train.columns = promo_2017_train.columns.get_level_values(1)\n",
    "promo_2017_test = df_test[[\"onpromotion\"]].unstack(level=-1).fillna(False)\n",
    "promo_2017_test.columns = promo_2017_test.columns.get_level_values(1)\n",
    "promo_2017_test = promo_2017_test.reindex(promo_2017_train.index).fillna(False)\n",
    "promo_2017 = pd.concat([promo_2017_train, promo_2017_test], axis=1)\n",
    "del promo_2017_test, promo_2017_train, df_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>2017-01-01</th>\n",
       "      <th>2017-01-02</th>\n",
       "      <th>2017-01-03</th>\n",
       "      <th>2017-01-04</th>\n",
       "      <th>2017-01-05</th>\n",
       "      <th>2017-01-06</th>\n",
       "      <th>2017-01-07</th>\n",
       "      <th>2017-01-08</th>\n",
       "      <th>2017-01-09</th>\n",
       "      <th>2017-01-10</th>\n",
       "      <th>...</th>\n",
       "      <th>2017-08-22</th>\n",
       "      <th>2017-08-23</th>\n",
       "      <th>2017-08-24</th>\n",
       "      <th>2017-08-25</th>\n",
       "      <th>2017-08-26</th>\n",
       "      <th>2017-08-27</th>\n",
       "      <th>2017-08-28</th>\n",
       "      <th>2017-08-29</th>\n",
       "      <th>2017-08-30</th>\n",
       "      <th>2017-08-31</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>96995</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99197</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103520</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103665</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105574</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 243 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "date                2017-01-01  2017-01-02  2017-01-03  2017-01-04  \\\n",
       "store_nbr item_nbr                                                   \n",
       "1         96995          False       False       False       False   \n",
       "          99197          False       False       False       False   \n",
       "          103520         False       False       False       False   \n",
       "          103665         False       False       False       False   \n",
       "          105574         False       False        True       False   \n",
       "\n",
       "date                2017-01-05  2017-01-06  2017-01-07  2017-01-08  \\\n",
       "store_nbr item_nbr                                                   \n",
       "1         96995          False       False       False       False   \n",
       "          99197          False       False       False       False   \n",
       "          103520         False       False       False       False   \n",
       "          103665         False       False       False       False   \n",
       "          105574         False        True       False       False   \n",
       "\n",
       "date                2017-01-09  2017-01-10  ...  2017-08-22  2017-08-23  \\\n",
       "store_nbr item_nbr                          ...                           \n",
       "1         96995          False       False  ...       False       False   \n",
       "          99197          False       False  ...       False       False   \n",
       "          103520         False       False  ...       False       False   \n",
       "          103665         False       False  ...       False       False   \n",
       "          105574         False       False  ...       False       False   \n",
       "\n",
       "date                2017-08-24  2017-08-25  2017-08-26  2017-08-27  \\\n",
       "store_nbr item_nbr                                                   \n",
       "1         96995          False       False       False       False   \n",
       "          99197          False       False       False       False   \n",
       "          103520         False       False       False       False   \n",
       "          103665         False       False       False       False   \n",
       "          105574         False       False       False       False   \n",
       "\n",
       "date                2017-08-28  2017-08-29  2017-08-30  2017-08-31  \n",
       "store_nbr item_nbr                                                  \n",
       "1         96995          False       False       False       False  \n",
       "          99197          False       False       False       False  \n",
       "          103520         False       False       False       False  \n",
       "          103665         False       False       False       False  \n",
       "          105574         False       False       False       False  \n",
       "\n",
       "[5 rows x 243 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "promo_2017.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2017 = df_2017.set_index(\n",
    "    [\"store_nbr\", \"item_nbr\", \"date\"])[[\"unit_sales\"]].unstack(\n",
    "        level=-1).fillna(0)\n",
    "df_2017.columns = df_2017.columns.get_level_values(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>2017-01-01</th>\n",
       "      <th>2017-01-02</th>\n",
       "      <th>2017-01-03</th>\n",
       "      <th>2017-01-04</th>\n",
       "      <th>2017-01-05</th>\n",
       "      <th>2017-01-06</th>\n",
       "      <th>2017-01-07</th>\n",
       "      <th>2017-01-08</th>\n",
       "      <th>2017-01-09</th>\n",
       "      <th>2017-01-10</th>\n",
       "      <th>...</th>\n",
       "      <th>2017-08-06</th>\n",
       "      <th>2017-08-07</th>\n",
       "      <th>2017-08-08</th>\n",
       "      <th>2017-08-09</th>\n",
       "      <th>2017-08-10</th>\n",
       "      <th>2017-08-11</th>\n",
       "      <th>2017-08-12</th>\n",
       "      <th>2017-08-13</th>\n",
       "      <th>2017-08-14</th>\n",
       "      <th>2017-08-15</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>96995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99197</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103520</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103665</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>...</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105574</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.609438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 227 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "date                2017-01-01  2017-01-02  2017-01-03  2017-01-04  \\\n",
       "store_nbr item_nbr                                                   \n",
       "1         96995            0.0    0.000000    0.000000    0.000000   \n",
       "          99197            0.0    0.000000    1.386294    0.693147   \n",
       "          103520           0.0    0.693147    1.098612    0.000000   \n",
       "          103665           0.0    0.000000    0.000000    1.386294   \n",
       "          105574           0.0    0.000000    1.791759    2.564949   \n",
       "\n",
       "date                2017-01-05  2017-01-06  2017-01-07  2017-01-08  \\\n",
       "store_nbr item_nbr                                                   \n",
       "1         96995       0.000000    0.000000    0.000000    0.000000   \n",
       "          99197       0.693147    0.693147    1.098612    0.000000   \n",
       "          103520      1.098612    1.386294    0.693147    0.000000   \n",
       "          103665      1.098612    1.098612    0.693147    1.098612   \n",
       "          105574      2.302585    1.945910    1.609438    1.098612   \n",
       "\n",
       "date                2017-01-09  2017-01-10  ...  2017-08-06  2017-08-07  \\\n",
       "store_nbr item_nbr                          ...                           \n",
       "1         96995       0.000000    0.000000  ...    1.098612    1.098612   \n",
       "          99197       0.000000    0.693147  ...    0.000000    1.098612   \n",
       "          103520      0.693147    0.693147  ...    0.000000    0.000000   \n",
       "          103665      0.000000    2.079442  ...    0.693147    1.098612   \n",
       "          105574      1.386294    2.302585  ...    0.000000    1.791759   \n",
       "\n",
       "date                2017-08-08  2017-08-09  2017-08-10  2017-08-11  \\\n",
       "store_nbr item_nbr                                                   \n",
       "1         96995       0.000000    0.000000    0.693147    0.000000   \n",
       "          99197       0.000000    1.098612    0.000000    0.000000   \n",
       "          103520      1.386294    0.000000    1.386294    0.693147   \n",
       "          103665      0.000000    2.079442    2.302585    1.098612   \n",
       "          105574      2.079442    1.945910    2.397895    1.791759   \n",
       "\n",
       "date                2017-08-12  2017-08-13  2017-08-14  2017-08-15  \n",
       "store_nbr item_nbr                                                  \n",
       "1         96995       0.000000    0.000000    0.000000    0.000000  \n",
       "          99197       0.000000    0.000000    0.000000    0.000000  \n",
       "          103520      0.693147    0.693147    0.000000    0.000000  \n",
       "          103665      0.000000    0.000000    0.693147    0.693147  \n",
       "          105574      1.791759    0.000000    1.386294    1.609438  \n",
       "\n",
       "[5 rows x 227 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2017.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "items['class'] = items['class'].astype('category')\n",
    "items = pd.get_dummies(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>perishable</th>\n",
       "      <th>family_AUTOMOTIVE</th>\n",
       "      <th>family_BABY CARE</th>\n",
       "      <th>family_BEAUTY</th>\n",
       "      <th>family_BEVERAGES</th>\n",
       "      <th>family_BOOKS</th>\n",
       "      <th>family_BREAD/BAKERY</th>\n",
       "      <th>family_CELEBRATION</th>\n",
       "      <th>family_CLEANING</th>\n",
       "      <th>family_DAIRY</th>\n",
       "      <th>...</th>\n",
       "      <th>class_6920</th>\n",
       "      <th>class_6922</th>\n",
       "      <th>class_6924</th>\n",
       "      <th>class_6936</th>\n",
       "      <th>class_6954</th>\n",
       "      <th>class_6960</th>\n",
       "      <th>class_7002</th>\n",
       "      <th>class_7016</th>\n",
       "      <th>class_7034</th>\n",
       "      <th>class_7780</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_nbr</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99197</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103501</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103520</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103665</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          perishable  family_AUTOMOTIVE  family_BABY CARE  family_BEAUTY  \\\n",
       "item_nbr                                                                   \n",
       "96995              0                  0                 0              0   \n",
       "99197              0                  0                 0              0   \n",
       "103501             0                  0                 0              0   \n",
       "103520             0                  0                 0              0   \n",
       "103665             1                  0                 0              0   \n",
       "\n",
       "          family_BEVERAGES  family_BOOKS  family_BREAD/BAKERY  \\\n",
       "item_nbr                                                        \n",
       "96995                    0             0                    0   \n",
       "99197                    0             0                    0   \n",
       "103501                   0             0                    0   \n",
       "103520                   0             0                    0   \n",
       "103665                   0             0                    1   \n",
       "\n",
       "          family_CELEBRATION  family_CLEANING  family_DAIRY  ...  class_6920  \\\n",
       "item_nbr                                                     ...               \n",
       "96995                      0                0             0  ...           0   \n",
       "99197                      0                0             0  ...           0   \n",
       "103501                     0                1             0  ...           0   \n",
       "103520                     0                0             0  ...           0   \n",
       "103665                     0                0             0  ...           0   \n",
       "\n",
       "          class_6922  class_6924  class_6936  class_6954  class_6960  \\\n",
       "item_nbr                                                               \n",
       "96995              0           0           0           0           0   \n",
       "99197              0           0           0           0           0   \n",
       "103501             0           0           0           0           0   \n",
       "103520             0           0           0           0           0   \n",
       "103665             0           0           0           0           0   \n",
       "\n",
       "          class_7002  class_7016  class_7034  class_7780  \n",
       "item_nbr                                                  \n",
       "96995              0           0           0           0  \n",
       "99197              0           0           0           0  \n",
       "103501             0           0           0           0  \n",
       "103520             0           0           0           0  \n",
       "103665             0           0           0           0  \n",
       "\n",
       "[5 rows x 371 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = items.reindex(df_2017.index.get_level_values(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(167515, 371)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>type</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_nbr</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Santo Domingo</td>\n",
       "      <td>Santo Domingo de los Tsachilas</td>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    city                           state type  cluster\n",
       "store_nbr                                                             \n",
       "1                  Quito                       Pichincha    D       13\n",
       "2                  Quito                       Pichincha    D       13\n",
       "3                  Quito                       Pichincha    D        8\n",
       "4                  Quito                       Pichincha    D        9\n",
       "5          Santo Domingo  Santo Domingo de los Tsachilas    D        4"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores['cluster'] = stores.cluster.astype('category')\n",
    "stores = pd.get_dummies(stores)\n",
    "stores = stores.reindex(df_2017.index.get_level_values(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_Ambato</th>\n",
       "      <th>city_Babahoyo</th>\n",
       "      <th>city_Cayambe</th>\n",
       "      <th>city_Cuenca</th>\n",
       "      <th>city_Daule</th>\n",
       "      <th>city_El Carmen</th>\n",
       "      <th>city_Esmeraldas</th>\n",
       "      <th>city_Guaranda</th>\n",
       "      <th>city_Guayaquil</th>\n",
       "      <th>city_Ibarra</th>\n",
       "      <th>...</th>\n",
       "      <th>cluster_8</th>\n",
       "      <th>cluster_9</th>\n",
       "      <th>cluster_10</th>\n",
       "      <th>cluster_11</th>\n",
       "      <th>cluster_12</th>\n",
       "      <th>cluster_13</th>\n",
       "      <th>cluster_14</th>\n",
       "      <th>cluster_15</th>\n",
       "      <th>cluster_16</th>\n",
       "      <th>cluster_17</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_nbr</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           city_Ambato  city_Babahoyo  city_Cayambe  city_Cuenca  city_Daule  \\\n",
       "store_nbr                                                                      \n",
       "1                    0              0             0            0           0   \n",
       "1                    0              0             0            0           0   \n",
       "1                    0              0             0            0           0   \n",
       "1                    0              0             0            0           0   \n",
       "1                    0              0             0            0           0   \n",
       "\n",
       "           city_El Carmen  city_Esmeraldas  city_Guaranda  city_Guayaquil  \\\n",
       "store_nbr                                                                   \n",
       "1                       0                0              0               0   \n",
       "1                       0                0              0               0   \n",
       "1                       0                0              0               0   \n",
       "1                       0                0              0               0   \n",
       "1                       0                0              0               0   \n",
       "\n",
       "           city_Ibarra  ...  cluster_8  cluster_9  cluster_10  cluster_11  \\\n",
       "store_nbr               ...                                                 \n",
       "1                    0  ...          0          0           0           0   \n",
       "1                    0  ...          0          0           0           0   \n",
       "1                    0  ...          0          0           0           0   \n",
       "1                    0  ...          0          0           0           0   \n",
       "1                    0  ...          0          0           0           0   \n",
       "\n",
       "           cluster_12  cluster_13  cluster_14  cluster_15  cluster_16  \\\n",
       "store_nbr                                                               \n",
       "1                   0           1           0           0           0   \n",
       "1                   0           1           0           0           0   \n",
       "1                   0           1           0           0           0   \n",
       "1                   0           1           0           0           0   \n",
       "1                   0           1           0           0           0   \n",
       "\n",
       "           cluster_17  \n",
       "store_nbr              \n",
       "1                   0  \n",
       "1                   0  \n",
       "1                   0  \n",
       "1                   0  \n",
       "1                   0  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(167515, 60)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sum of sales for each item across all stores for each day\n",
    "#df_2017_item = df_2017.groupby('item_nbr')[df_2017.columns].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sum of promotion for each item across all stores for each day\n",
    "#promo_2017_item = promo_2017.groupby('item_nbr')[promo_2017.columns].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum of sales in each class (multiple items) for each store for each day \n",
    "# df_2017_store_class = df_2017.reset_index()\n",
    "# df_2017_store_class['class'] = items['class'].values\n",
    "# df_2017_store_class_index = df_2017_store_class[['class', 'store_nbr']]\n",
    "# df_2017_store_class = df_2017_store_class.groupby(['class', 'store_nbr'])[df_2017.columns].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_2017_store_class_index.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_2017_store_class.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_2017_store_class.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum of promotions in each class (multiple items) for each store for each day \n",
    "\n",
    "# df_2017_promo_store_class = promo_2017.reset_index()\n",
    "# df_2017_promo_store_class['class'] = items['class'].values\n",
    "# df_2017_promo_store_class_index = df_2017_promo_store_class[['class', 'store_nbr']]\n",
    "# df_2017_promo_store_class = df_2017_promo_store_class.groupby(['class', 'store_nbr'])[promo_2017.columns].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timespan(df, dt, minus, periods, freq='D'):\n",
    "    return df[pd.date_range(dt - timedelta(days=minus), periods=periods, freq=freq)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(df, promo_df, t2017, is_train=True, name_prefix=None):\n",
    "    X = {\n",
    "        \"promo_7_2017\": get_timespan(promo_df, t2017, 7, 7).sum(axis=1).values,\n",
    "        \"promo_14_2017\": get_timespan(promo_df, t2017, 14, 14).sum(axis=1).values,\n",
    "        \"promo_30_2017\": get_timespan(promo_df, t2017, 30, 30).sum(axis=1).values,\n",
    "        \"promo_3_2017_aft\": get_timespan(promo_df, t2017 + timedelta(days=15), 14, 3).sum(axis=1).values,\n",
    "        \"promo_7_2017_aft\": get_timespan(promo_df, t2017 + timedelta(days=15), 14, 7).sum(axis=1).values,\n",
    "        \"promo_14_2017_aft\": get_timespan(promo_df, t2017 + timedelta(days=15), 14, 14).sum(axis=1).values,\n",
    "    }\n",
    "\n",
    "# Removed due to the presence of nan values \n",
    "#     for i in [3, 7, 14, 30]:\n",
    "#         tmp1 = get_timespan(df, t2017, i, i)\n",
    "#         tmp2 = (get_timespan(promo_df, t2017, i, i) > 0) * 1\n",
    "\n",
    "#         X['has_promo_mean_%s' % i] = (tmp1 * tmp2.replace(0, np.nan)).mean(axis=1).values\n",
    "#         X['no_promo_mean_%s' % i] = (tmp1 * (1 - tmp2).replace(0, np.nan)).mean(axis=1).values\n",
    "                \n",
    "        \n",
    "    for i in [3, 7, 14, 30]:\n",
    "        tmp = get_timespan(df, t2017, i, i)\n",
    "        X['diff_%s_mean' % i] = tmp.diff(axis=1).mean(axis=1).values\n",
    "        X['mean_%s' % i] = tmp.mean(axis=1).values\n",
    "        X['median_%s' % i] = tmp.median(axis=1).values\n",
    "        X['min_%s' % i] = tmp.min(axis=1).values\n",
    "        X['max_%s' % i] = tmp.max(axis=1).values\n",
    "        X['std_%s' % i] = tmp.std(axis=1).values\n",
    "\n",
    "    for i in [7, 14, 30]:\n",
    "        tmp = get_timespan(df, t2017, i, i)\n",
    "        X['has_sales_days_in_last_%s' % i] = (tmp > 0).sum(axis=1).values\n",
    "        X['last_has_sales_day_in_last_%s' % i] = i - ((tmp > 0) * np.arange(i)).max(axis=1).values\n",
    "        X['first_has_sales_day_in_last_%s' % i] = ((tmp > 0) * np.arange(i, 0, -1)).max(axis=1).values\n",
    "\n",
    "        tmp = get_timespan(promo_df, t2017, i, i)\n",
    "        X['has_promo_days_in_last_%s' % i] = (tmp > 0).sum(axis=1).values\n",
    "        X['last_has_promo_day_in_last_%s' % i] = i - ((tmp > 0) * np.arange(i)).max(axis=1).values\n",
    "        X['first_has_promo_day_in_last_%s' % i] = ((tmp > 0) * np.arange(i, 0, -1)).max(axis=1).values\n",
    "\n",
    "    tmp = get_timespan(promo_df, t2017 + timedelta(days=15), 14, 14)\n",
    "    X['has_promo_days_in_after_14_days'] = (tmp > 0).sum(axis=1).values\n",
    "    X['last_has_promo_day_in_after_14_days'] = i - ((tmp > 0) * np.arange(14)).max(axis=1).values\n",
    "    X['first_has_promo_day_in_after_14_days'] = ((tmp > 0) * np.arange(14, 0, -1)).max(axis=1).values\n",
    "\n",
    "    for i in range(1, 15):\n",
    "        X['day_%s_2017' % i] = get_timespan(df, t2017, i, 1).values.ravel()\n",
    "\n",
    "    for i in range(7):\n",
    "        X['mean_4_dow{}_2017'.format(i)] = get_timespan(df, t2017, 28-i, 4, freq='7D').mean(axis=1).values\n",
    "        X['mean_20_dow{}_2017'.format(i)] = get_timespan(df, t2017, 140-i, 20, freq='7D').mean(axis=1).values        \n",
    "        \n",
    "    for i in range(-14, 15):\n",
    "        X[\"promo_{}\".format(i)] = promo_df[t2017 + timedelta(days=i)].values.astype(np.uint8)\n",
    "\n",
    "    X = pd.DataFrame(X)\n",
    "\n",
    "    if is_train:\n",
    "        y = df[\n",
    "            pd.date_range(t2017, periods=15)\n",
    "        ].values\n",
    "        return X, y\n",
    "    if name_prefix is not None:\n",
    "        X.columns = ['%s_%s' % (name_prefix, c) for c in X.columns]\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:09<00:00,  2.28s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Preparing dataset...\")\n",
    "t2017 = date(2017, 5, 30)\n",
    "num_days = 4\n",
    "X_l, y_l = [], []\n",
    "for i in tqdm(range(num_days)):\n",
    "    delta = timedelta(days=7 * i)\n",
    "    X_tmp, y_tmp = prepare_dataset(df_2017, promo_2017, t2017 + delta)\n",
    "\n",
    "    X_tmp = pd.concat([X_tmp, items.reset_index(drop=True), stores.reset_index(drop=True)], axis=1)\n",
    "    X_l.append(X_tmp)\n",
    "    y_l.append(y_tmp)\n",
    "\n",
    "X_train = pd.concat(X_l, axis=0)\n",
    "y_train = np.concatenate(y_l, axis=0)\n",
    "\n",
    "del X_l, y_l\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, y_val = prepare_dataset(df_2017, promo_2017, date(2017, 7, 11))\n",
    "\n",
    "# X_val2 = prepare_dataset(df_2017_item, promo_2017_item, date(2017, 7, 26), is_train=False, name_prefix='item')\n",
    "# X_val2.index = df_2017_item.index\n",
    "# X_val2 = X_val2.reindex(df_2017.index.get_level_values(1)).reset_index(drop=True)\n",
    "\n",
    "# X_val3 = prepare_dataset(df_2017_store_class, df_2017_promo_store_class, date(2017, 7, 26), is_train=False, name_prefix='store_class')\n",
    "# X_val3.index = df_2017_store_class.index\n",
    "# X_val3 = X_val3.reindex(df_2017_store_class_index).reset_index(drop=True)\n",
    "\n",
    "X_val = pd.concat([X_val, items.reset_index(drop=True), stores.reset_index(drop=True)], axis=1)\n",
    "\n",
    "X_test, y_test = prepare_dataset(df_2017, promo_2017, date(2017, 8, 1))\n",
    "\n",
    "# X_test2 = prepare_dataset(df_2017_item, promo_2017_item, date(2017, 8, 16), is_train=False, name_prefix='item')\n",
    "# X_test2.index = df_2017_item.index\n",
    "# X_test2 = X_test2.reindex(df_2017.index.get_level_values(1)).reset_index(drop=True)\n",
    "\n",
    "# X_test3 = prepare_dataset(df_2017_store_class, df_2017_promo_store_class, date(2017, 8, 16), is_train=False, name_prefix='store_class')\n",
    "# X_test3.index = df_2017_store_class.index\n",
    "# X_test3 = X_test3.reindex(df_2017_store_class_index).reset_index(drop=True)\n",
    "\n",
    "X_test = pd.concat([X_test, items.reset_index(drop=True), stores.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# del X_test2, X_val2, df_2017_item, promo_2017_item, df_2017_store_class, df_2017_promo_store_class, df_2017_store_class_index\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_1005\n",
      "class_1328\n",
      "class_1334\n"
     ]
    }
   ],
   "source": [
    "for col in X_train.columns:\n",
    "    if X_train[col].nunique() == 1:\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#there are columns with unique values but will leave it here for simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((670060, 539), (670060, 15))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((167515, 539), (167515, 15))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((167515, 539), (167515, 15))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df_2017, promo_2017\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(pd.concat([X_train, X_val, X_test]))\n",
    "X_train[:] = scaler.transform(X_train)\n",
    "X_val[:] = scaler.transform(X_val)\n",
    "X_test[:] = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "X_val = X_val.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((670060, 539), (670060, 15))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((167515, 539), (167515, 15))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((167515, 539), (167515, 15))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Model 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "256 x 128 x 64 x 32 x 16 x 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(256, input_dim=X_train.shape[1]))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())\n",
    "#     model.add(Dropout(.1))\n",
    "\n",
    "    model.add(Dense(128, input_dim=X_train.shape[1]))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())\n",
    "#     model.add(Dropout(.05))\n",
    "#     model.add(Dropout(0.1))\n",
    "    \n",
    "    model.add(Dense(64))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())\n",
    "#     model.add(Dropout(.05))\n",
    "\n",
    "    model.add(Dense(32))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())\n",
    "#     model.add(Dropout(.05))\n",
    "\n",
    "    model.add(Dense(16))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())\n",
    "#     model.add(Dropout(.05))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Step 1\n",
      "==================================================\n",
      "Train on 670060 samples, validate on 167515 samples\n",
      "Epoch 1/2000\n",
      " - 20s - loss: 0.4925 - mse: 0.4638 - val_loss: 0.3851 - val_mse: 0.3851\n",
      "Epoch 2/2000\n",
      " - 18s - loss: 0.3548 - mse: 0.3347 - val_loss: 0.3368 - val_mse: 0.3368\n",
      "Epoch 3/2000\n",
      " - 18s - loss: 0.3387 - mse: 0.3199 - val_loss: 0.3299 - val_mse: 0.3299\n",
      "Epoch 4/2000\n",
      " - 18s - loss: 0.3302 - mse: 0.3121 - val_loss: 0.3228 - val_mse: 0.3228\n",
      "Epoch 5/2000\n",
      " - 18s - loss: 0.3247 - mse: 0.3071 - val_loss: 0.3210 - val_mse: 0.3210\n",
      "Epoch 6/2000\n",
      " - 18s - loss: 0.3207 - mse: 0.3033 - val_loss: 0.3186 - val_mse: 0.3186\n",
      "Epoch 7/2000\n",
      " - 18s - loss: 0.3175 - mse: 0.3004 - val_loss: 0.3190 - val_mse: 0.3190\n",
      "Epoch 8/2000\n",
      " - 18s - loss: 0.3145 - mse: 0.2977 - val_loss: 0.3191 - val_mse: 0.3191\n",
      "Epoch 9/2000\n",
      " - 18s - loss: 0.3122 - mse: 0.2955 - val_loss: 0.3201 - val_mse: 0.3201\n",
      "Epoch 10/2000\n",
      " - 18s - loss: 0.3099 - mse: 0.2934 - val_loss: 0.3210 - val_mse: 0.3210\n",
      "Epoch 11/2000\n",
      " - 18s - loss: 0.3075 - mse: 0.2912 - val_loss: 0.3210 - val_mse: 0.3210\n",
      "Epoch 12/2000\n",
      " - 18s - loss: 0.3057 - mse: 0.2895 - val_loss: 0.3237 - val_mse: 0.3237\n",
      "Epoch 13/2000\n",
      " - 18s - loss: 0.3037 - mse: 0.2876 - val_loss: 0.3216 - val_mse: 0.3216\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 14/2000\n",
      " - 18s - loss: 0.2940 - mse: 0.2787 - val_loss: 0.3192 - val_mse: 0.3192\n",
      "Epoch 15/2000\n",
      " - 18s - loss: 0.2904 - mse: 0.2754 - val_loss: 0.3198 - val_mse: 0.3198\n",
      "Epoch 16/2000\n",
      " - 18s - loss: 0.2890 - mse: 0.2741 - val_loss: 0.3210 - val_mse: 0.3210\n",
      "==================================================\n",
      "Step 2\n",
      "==================================================\n",
      "Train on 670060 samples, validate on 167515 samples\n",
      "Epoch 1/2000\n",
      " - 19s - loss: 0.4974 - mse: 0.4690 - val_loss: 0.3878 - val_mse: 0.3878\n",
      "Epoch 2/2000\n",
      " - 18s - loss: 0.3550 - mse: 0.3366 - val_loss: 0.3336 - val_mse: 0.3336\n",
      "Epoch 3/2000\n",
      " - 18s - loss: 0.3380 - mse: 0.3212 - val_loss: 0.3232 - val_mse: 0.3232\n",
      "Epoch 4/2000\n",
      " - 18s - loss: 0.3295 - mse: 0.3134 - val_loss: 0.3208 - val_mse: 0.3208\n",
      "Epoch 5/2000\n",
      " - 18s - loss: 0.3241 - mse: 0.3084 - val_loss: 0.3179 - val_mse: 0.3179\n",
      "Epoch 6/2000\n",
      " - 18s - loss: 0.3198 - mse: 0.3045 - val_loss: 0.3173 - val_mse: 0.3173\n",
      "Epoch 7/2000\n",
      " - 19s - loss: 0.3166 - mse: 0.3014 - val_loss: 0.3154 - val_mse: 0.3154\n",
      "Epoch 8/2000\n",
      " - 18s - loss: 0.3136 - mse: 0.2986 - val_loss: 0.3188 - val_mse: 0.3188\n",
      "Epoch 9/2000\n",
      " - 18s - loss: 0.3113 - mse: 0.2965 - val_loss: 0.3179 - val_mse: 0.3179\n",
      "Epoch 10/2000\n",
      " - 18s - loss: 0.3090 - mse: 0.2943 - val_loss: 0.3183 - val_mse: 0.3183\n",
      "Epoch 11/2000\n",
      " - 18s - loss: 0.3070 - mse: 0.2924 - val_loss: 0.3183 - val_mse: 0.3183\n",
      "Epoch 12/2000\n",
      " - 18s - loss: 0.3054 - mse: 0.2910 - val_loss: 0.3197 - val_mse: 0.3197\n",
      "Epoch 13/2000\n",
      " - 18s - loss: 0.3031 - mse: 0.2889 - val_loss: 0.3201 - val_mse: 0.3201\n",
      "Epoch 14/2000\n",
      " - 18s - loss: 0.3016 - mse: 0.2874 - val_loss: 0.3220 - val_mse: 0.3220\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 15/2000\n",
      " - 18s - loss: 0.2920 - mse: 0.2786 - val_loss: 0.3182 - val_mse: 0.3182\n",
      "Epoch 16/2000\n",
      " - 18s - loss: 0.2885 - mse: 0.2753 - val_loss: 0.3196 - val_mse: 0.3196\n",
      "Epoch 17/2000\n",
      " - 18s - loss: 0.2872 - mse: 0.2741 - val_loss: 0.3198 - val_mse: 0.3198\n",
      "==================================================\n",
      "Step 3\n",
      "==================================================\n",
      "Train on 670060 samples, validate on 167515 samples\n",
      "Epoch 1/2000\n",
      " - 20s - loss: 0.5387 - mse: 0.5084 - val_loss: 0.4517 - val_mse: 0.4517\n",
      "Epoch 2/2000\n",
      " - 18s - loss: 0.3814 - mse: 0.3603 - val_loss: 0.3744 - val_mse: 0.3744\n",
      "Epoch 3/2000\n",
      " - 18s - loss: 0.3666 - mse: 0.3465 - val_loss: 0.3557 - val_mse: 0.3557\n",
      "Epoch 4/2000\n",
      " - 18s - loss: 0.3578 - mse: 0.3383 - val_loss: 0.3503 - val_mse: 0.3503\n",
      "Epoch 5/2000\n",
      " - 18s - loss: 0.3518 - mse: 0.3327 - val_loss: 0.3485 - val_mse: 0.3485\n",
      "Epoch 6/2000\n",
      " - 18s - loss: 0.3476 - mse: 0.3288 - val_loss: 0.3494 - val_mse: 0.3494\n",
      "Epoch 7/2000\n",
      " - 18s - loss: 0.3433 - mse: 0.3248 - val_loss: 0.3496 - val_mse: 0.3496\n",
      "Epoch 8/2000\n",
      " - 18s - loss: 0.3401 - mse: 0.3218 - val_loss: 0.3489 - val_mse: 0.3489\n",
      "Epoch 9/2000\n",
      " - 18s - loss: 0.3373 - mse: 0.3192 - val_loss: 0.3505 - val_mse: 0.3505\n",
      "Epoch 10/2000\n",
      " - 18s - loss: 0.3350 - mse: 0.3171 - val_loss: 0.3505 - val_mse: 0.3505\n",
      "Epoch 11/2000\n",
      " - 18s - loss: 0.3329 - mse: 0.3151 - val_loss: 0.3496 - val_mse: 0.3496\n",
      "Epoch 12/2000\n",
      " - 18s - loss: 0.3304 - mse: 0.3127 - val_loss: 0.3513 - val_mse: 0.3513\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 13/2000\n",
      " - 18s - loss: 0.3198 - mse: 0.3029 - val_loss: 0.3485 - val_mse: 0.3485\n",
      "Epoch 14/2000\n",
      " - 18s - loss: 0.3162 - mse: 0.2996 - val_loss: 0.3498 - val_mse: 0.3498\n",
      "Epoch 15/2000\n",
      " - 18s - loss: 0.3148 - mse: 0.2983 - val_loss: 0.3510 - val_mse: 0.3510\n",
      "Epoch 16/2000\n",
      " - 18s - loss: 0.3137 - mse: 0.2973 - val_loss: 0.3514 - val_mse: 0.3514\n",
      "Epoch 17/2000\n",
      " - 18s - loss: 0.3128 - mse: 0.2965 - val_loss: 0.3532 - val_mse: 0.3532\n",
      "Epoch 18/2000\n",
      " - 18s - loss: 0.3119 - mse: 0.2957 - val_loss: 0.3537 - val_mse: 0.3537\n",
      "Epoch 19/2000\n",
      " - 18s - loss: 0.3111 - mse: 0.2949 - val_loss: 0.3546 - val_mse: 0.3546\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 20/2000\n",
      " - 18s - loss: 0.3087 - mse: 0.2927 - val_loss: 0.3553 - val_mse: 0.3553\n",
      "Epoch 21/2000\n",
      " - 18s - loss: 0.3085 - mse: 0.2925 - val_loss: 0.3557 - val_mse: 0.3557\n",
      "Epoch 22/2000\n",
      " - 18s - loss: 0.3085 - mse: 0.2925 - val_loss: 0.3559 - val_mse: 0.3559\n",
      "Epoch 23/2000\n",
      " - 18s - loss: 0.3084 - mse: 0.2924 - val_loss: 0.3561 - val_mse: 0.3561\n",
      "==================================================\n",
      "Step 4\n",
      "==================================================\n",
      "Train on 670060 samples, validate on 167515 samples\n",
      "Epoch 1/2000\n",
      " - 19s - loss: 0.5024 - mse: 0.4735 - val_loss: 0.4848 - val_mse: 0.4848\n",
      "Epoch 2/2000\n",
      " - 18s - loss: 0.3747 - mse: 0.3551 - val_loss: 0.3765 - val_mse: 0.3765\n",
      "Epoch 3/2000\n",
      " - 18s - loss: 0.3592 - mse: 0.3410 - val_loss: 0.3600 - val_mse: 0.3600\n",
      "Epoch 4/2000\n",
      " - 18s - loss: 0.3512 - mse: 0.3335 - val_loss: 0.3539 - val_mse: 0.3539\n",
      "Epoch 5/2000\n",
      " - 18s - loss: 0.3455 - mse: 0.3283 - val_loss: 0.3465 - val_mse: 0.3465\n",
      "Epoch 6/2000\n",
      " - 18s - loss: 0.3409 - mse: 0.3240 - val_loss: 0.3469 - val_mse: 0.3469\n",
      "Epoch 7/2000\n",
      " - 18s - loss: 0.3377 - mse: 0.3209 - val_loss: 0.3483 - val_mse: 0.3483\n",
      "Epoch 8/2000\n",
      " - 18s - loss: 0.3345 - mse: 0.3180 - val_loss: 0.3490 - val_mse: 0.3490\n",
      "Epoch 9/2000\n",
      " - 18s - loss: 0.3314 - mse: 0.3151 - val_loss: 0.3488 - val_mse: 0.3488\n",
      "Epoch 10/2000\n",
      " - 18s - loss: 0.3291 - mse: 0.3129 - val_loss: 0.3510 - val_mse: 0.3510\n",
      "Epoch 11/2000\n",
      " - 18s - loss: 0.3267 - mse: 0.3107 - val_loss: 0.3490 - val_mse: 0.3490\n",
      "Epoch 12/2000\n",
      " - 18s - loss: 0.3243 - mse: 0.3085 - val_loss: 0.3469 - val_mse: 0.3469\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 13/2000\n",
      " - 18s - loss: 0.3135 - mse: 0.2985 - val_loss: 0.3457 - val_mse: 0.3457\n",
      "Epoch 14/2000\n",
      " - 18s - loss: 0.3095 - mse: 0.2948 - val_loss: 0.3473 - val_mse: 0.3473\n",
      "Epoch 15/2000\n",
      " - 18s - loss: 0.3081 - mse: 0.2934 - val_loss: 0.3477 - val_mse: 0.3477\n",
      "Epoch 16/2000\n",
      " - 18s - loss: 0.3070 - mse: 0.2924 - val_loss: 0.3490 - val_mse: 0.3490\n",
      "Epoch 17/2000\n",
      " - 18s - loss: 0.3060 - mse: 0.2915 - val_loss: 0.3503 - val_mse: 0.3503\n",
      "Epoch 18/2000\n",
      " - 18s - loss: 0.3051 - mse: 0.2907 - val_loss: 0.3507 - val_mse: 0.3507\n",
      "Epoch 19/2000\n",
      " - 18s - loss: 0.3043 - mse: 0.2900 - val_loss: 0.3522 - val_mse: 0.3522\n",
      "Epoch 20/2000\n",
      " - 18s - loss: 0.3035 - mse: 0.2892 - val_loss: 0.3523 - val_mse: 0.3523\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 21/2000\n",
      " - 18s - loss: 0.3011 - mse: 0.2870 - val_loss: 0.3535 - val_mse: 0.3535\n",
      "Epoch 22/2000\n",
      " - 18s - loss: 0.3007 - mse: 0.2866 - val_loss: 0.3541 - val_mse: 0.3541\n",
      "Epoch 23/2000\n",
      " - 19s - loss: 0.3008 - mse: 0.2867 - val_loss: 0.3545 - val_mse: 0.3545\n",
      "==================================================\n",
      "Step 5\n",
      "==================================================\n",
      "Train on 670060 samples, validate on 167515 samples\n",
      "Epoch 1/2000\n",
      " - 37s - loss: 0.5008 - mse: 0.4724 - val_loss: 0.4761 - val_mse: 0.4761\n",
      "Epoch 2/2000\n",
      " - 20s - loss: 0.3953 - mse: 0.3739 - val_loss: 0.3862 - val_mse: 0.3862\n",
      "Epoch 3/2000\n",
      " - 20s - loss: 0.3821 - mse: 0.3616 - val_loss: 0.3696 - val_mse: 0.3696\n",
      "Epoch 4/2000\n",
      " - 21s - loss: 0.3740 - mse: 0.3540 - val_loss: 0.3683 - val_mse: 0.3683\n",
      "Epoch 5/2000\n",
      " - 25s - loss: 0.3680 - mse: 0.3485 - val_loss: 0.3634 - val_mse: 0.3634\n",
      "Epoch 6/2000\n",
      " - 24s - loss: 0.3638 - mse: 0.3445 - val_loss: 0.3629 - val_mse: 0.3629\n",
      "Epoch 7/2000\n",
      " - 26s - loss: 0.3592 - mse: 0.3403 - val_loss: 0.3631 - val_mse: 0.3631\n",
      "Epoch 8/2000\n",
      " - 24s - loss: 0.3559 - mse: 0.3372 - val_loss: 0.3645 - val_mse: 0.3645\n",
      "Epoch 9/2000\n",
      " - 24s - loss: 0.3529 - mse: 0.3344 - val_loss: 0.3667 - val_mse: 0.3667\n",
      "Epoch 10/2000\n",
      " - 28s - loss: 0.3503 - mse: 0.3320 - val_loss: 0.3712 - val_mse: 0.3712\n",
      "Epoch 11/2000\n",
      " - 27s - loss: 0.3477 - mse: 0.3297 - val_loss: 0.3692 - val_mse: 0.3692\n",
      "Epoch 12/2000\n",
      " - 28s - loss: 0.3450 - mse: 0.3271 - val_loss: 0.3722 - val_mse: 0.3722\n",
      "Epoch 13/2000\n",
      " - 27s - loss: 0.3422 - mse: 0.3246 - val_loss: 0.3723 - val_mse: 0.3723\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 14/2000\n",
      " - 27s - loss: 0.3304 - mse: 0.3136 - val_loss: 0.3681 - val_mse: 0.3681\n",
      "Epoch 15/2000\n",
      " - 24s - loss: 0.3260 - mse: 0.3095 - val_loss: 0.3697 - val_mse: 0.3697\n",
      "Epoch 16/2000\n",
      " - 25s - loss: 0.3243 - mse: 0.3079 - val_loss: 0.3720 - val_mse: 0.3720\n",
      "==================================================\n",
      "Step 6\n",
      "==================================================\n",
      "Train on 670060 samples, validate on 167515 samples\n",
      "Epoch 1/2000\n",
      " - 37s - loss: 0.5251 - mse: 0.4955 - val_loss: 0.4381 - val_mse: 0.4381\n",
      "Epoch 2/2000\n",
      " - 74s - loss: 0.4072 - mse: 0.3852 - val_loss: 0.3910 - val_mse: 0.3910\n",
      "Epoch 3/2000\n",
      " - 45s - loss: 0.3920 - mse: 0.3711 - val_loss: 0.3831 - val_mse: 0.3831\n",
      "Epoch 4/2000\n",
      " - 35s - loss: 0.3830 - mse: 0.3627 - val_loss: 0.3776 - val_mse: 0.3776\n",
      "Epoch 5/2000\n",
      " - 29s - loss: 0.3767 - mse: 0.3569 - val_loss: 0.3734 - val_mse: 0.3734\n",
      "Epoch 6/2000\n",
      " - 30s - loss: 0.3714 - mse: 0.3520 - val_loss: 0.3744 - val_mse: 0.3744\n",
      "Epoch 7/2000\n",
      " - 73s - loss: 0.3671 - mse: 0.3479 - val_loss: 0.3729 - val_mse: 0.3729\n",
      "Epoch 8/2000\n",
      " - 45s - loss: 0.3634 - mse: 0.3445 - val_loss: 0.3725 - val_mse: 0.3725\n",
      "Epoch 9/2000\n",
      " - 28s - loss: 0.3604 - mse: 0.3417 - val_loss: 0.3737 - val_mse: 0.3737\n",
      "Epoch 10/2000\n",
      " - 25s - loss: 0.3570 - mse: 0.3386 - val_loss: 0.3749 - val_mse: 0.3749\n",
      "Epoch 11/2000\n",
      " - 23s - loss: 0.3541 - mse: 0.3360 - val_loss: 0.3766 - val_mse: 0.3766\n",
      "Epoch 12/2000\n",
      " - 23s - loss: 0.3514 - mse: 0.3334 - val_loss: 0.3776 - val_mse: 0.3776\n",
      "Epoch 13/2000\n",
      " - 66s - loss: 0.3493 - mse: 0.3314 - val_loss: 0.3794 - val_mse: 0.3794\n",
      "Epoch 14/2000\n",
      " - 38s - loss: 0.3467 - mse: 0.3291 - val_loss: 0.3848 - val_mse: 0.3848\n",
      "Epoch 15/2000\n",
      " - 31s - loss: 0.3444 - mse: 0.3270 - val_loss: 0.3855 - val_mse: 0.3855\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 16/2000\n",
      " - 24s - loss: 0.3305 - mse: 0.3141 - val_loss: 0.3798 - val_mse: 0.3798\n",
      "Epoch 17/2000\n",
      " - 24s - loss: 0.3257 - mse: 0.3096 - val_loss: 0.3816 - val_mse: 0.3816\n",
      "Epoch 18/2000\n",
      " - 24s - loss: 0.3237 - mse: 0.3078 - val_loss: 0.3830 - val_mse: 0.3830\n",
      "==================================================\n",
      "Step 7\n",
      "==================================================\n",
      "Train on 670060 samples, validate on 167515 samples\n",
      "Epoch 1/2000\n",
      " - 22s - loss: 0.5794 - mse: 0.5456 - val_loss: 0.4437 - val_mse: 0.4437\n",
      "Epoch 2/2000\n",
      " - 20s - loss: 0.4070 - mse: 0.3837 - val_loss: 0.3883 - val_mse: 0.3883\n",
      "Epoch 3/2000\n",
      " - 21s - loss: 0.3890 - mse: 0.3669 - val_loss: 0.3766 - val_mse: 0.3766\n",
      "Epoch 4/2000\n",
      " - 21s - loss: 0.3788 - mse: 0.3574 - val_loss: 0.3738 - val_mse: 0.3738\n",
      "Epoch 5/2000\n",
      " - 21s - loss: 0.3726 - mse: 0.3516 - val_loss: 0.3718 - val_mse: 0.3718\n",
      "Epoch 6/2000\n",
      " - 20s - loss: 0.3679 - mse: 0.3473 - val_loss: 0.3718 - val_mse: 0.3718\n",
      "Epoch 7/2000\n",
      " - 20s - loss: 0.3637 - mse: 0.3434 - val_loss: 0.3726 - val_mse: 0.3726\n",
      "Epoch 8/2000\n",
      " - 20s - loss: 0.3602 - mse: 0.3402 - val_loss: 0.3726 - val_mse: 0.3726\n",
      "Epoch 9/2000\n",
      " - 23s - loss: 0.3570 - mse: 0.3372 - val_loss: 0.3747 - val_mse: 0.3747\n",
      "Epoch 10/2000\n",
      " - 22s - loss: 0.3543 - mse: 0.3347 - val_loss: 0.3734 - val_mse: 0.3734\n",
      "Epoch 11/2000\n",
      " - 22s - loss: 0.3517 - mse: 0.3323 - val_loss: 0.3738 - val_mse: 0.3738\n",
      "Epoch 12/2000\n",
      " - 21s - loss: 0.3493 - mse: 0.3301 - val_loss: 0.3758 - val_mse: 0.3758\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 13/2000\n",
      " - 20s - loss: 0.3386 - mse: 0.3202 - val_loss: 0.3741 - val_mse: 0.3741\n",
      "Epoch 14/2000\n",
      " - 21s - loss: 0.3349 - mse: 0.3169 - val_loss: 0.3749 - val_mse: 0.3749\n",
      "Epoch 15/2000\n",
      " - 20s - loss: 0.3334 - mse: 0.3155 - val_loss: 0.3757 - val_mse: 0.3757\n",
      "Epoch 16/2000\n",
      " - 21s - loss: 0.3324 - mse: 0.3146 - val_loss: 0.3763 - val_mse: 0.3763\n",
      "==================================================\n",
      "Step 8\n",
      "==================================================\n",
      "Train on 670060 samples, validate on 167515 samples\n",
      "Epoch 1/2000\n",
      " - 46s - loss: 0.5471 - mse: 0.5163 - val_loss: 0.4420 - val_mse: 0.4420\n",
      "Epoch 2/2000\n",
      " - 59s - loss: 0.3899 - mse: 0.3682 - val_loss: 0.3755 - val_mse: 0.3755\n",
      "Epoch 3/2000\n",
      " - 26s - loss: 0.3732 - mse: 0.3530 - val_loss: 0.3656 - val_mse: 0.3656\n",
      "Epoch 4/2000\n",
      " - 24s - loss: 0.3643 - mse: 0.3449 - val_loss: 0.3616 - val_mse: 0.3616\n",
      "Epoch 5/2000\n",
      " - 28s - loss: 0.3583 - mse: 0.3393 - val_loss: 0.3611 - val_mse: 0.3611\n",
      "Epoch 6/2000\n",
      " - 34s - loss: 0.3536 - mse: 0.3351 - val_loss: 0.3609 - val_mse: 0.3609\n",
      "Epoch 7/2000\n",
      " - 46s - loss: 0.3499 - mse: 0.3316 - val_loss: 0.3611 - val_mse: 0.3611\n",
      "Epoch 8/2000\n",
      " - 65s - loss: 0.3467 - mse: 0.3287 - val_loss: 0.3613 - val_mse: 0.3613\n",
      "Epoch 9/2000\n",
      " - 28s - loss: 0.3439 - mse: 0.3260 - val_loss: 0.3626 - val_mse: 0.3626\n",
      "Epoch 10/2000\n",
      " - 24s - loss: 0.3414 - mse: 0.3237 - val_loss: 0.3613 - val_mse: 0.3613\n",
      "Epoch 11/2000\n",
      " - 23s - loss: 0.3389 - mse: 0.3214 - val_loss: 0.3626 - val_mse: 0.3626\n",
      "Epoch 12/2000\n",
      " - 23s - loss: 0.3367 - mse: 0.3194 - val_loss: 0.3626 - val_mse: 0.3626\n",
      "Epoch 13/2000\n",
      " - 23s - loss: 0.3347 - mse: 0.3175 - val_loss: 0.3651 - val_mse: 0.3651\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 14/2000\n",
      " - 27s - loss: 0.3236 - mse: 0.3073 - val_loss: 0.3635 - val_mse: 0.3635\n",
      "Epoch 15/2000\n",
      " - 32s - loss: 0.3204 - mse: 0.3043 - val_loss: 0.3635 - val_mse: 0.3635\n",
      "Epoch 16/2000\n",
      " - 40s - loss: 0.3190 - mse: 0.3030 - val_loss: 0.3642 - val_mse: 0.3642\n",
      "==================================================\n",
      "Step 9\n",
      "==================================================\n",
      "Train on 670060 samples, validate on 167515 samples\n",
      "Epoch 1/2000\n",
      " - 22s - loss: 0.5427 - mse: 0.5113 - val_loss: 0.5250 - val_mse: 0.5250\n",
      "Epoch 2/2000\n",
      " - 20s - loss: 0.3797 - mse: 0.3601 - val_loss: 0.3860 - val_mse: 0.3860\n",
      "Epoch 3/2000\n",
      " - 20s - loss: 0.3601 - mse: 0.3424 - val_loss: 0.3619 - val_mse: 0.3619\n",
      "Epoch 4/2000\n",
      " - 20s - loss: 0.3502 - mse: 0.3334 - val_loss: 0.3573 - val_mse: 0.3573\n",
      "Epoch 5/2000\n",
      " - 20s - loss: 0.3439 - mse: 0.3275 - val_loss: 0.3544 - val_mse: 0.3544\n",
      "Epoch 6/2000\n",
      " - 20s - loss: 0.3395 - mse: 0.3235 - val_loss: 0.3530 - val_mse: 0.3530\n",
      "Epoch 7/2000\n",
      " - 21s - loss: 0.3357 - mse: 0.3200 - val_loss: 0.3537 - val_mse: 0.3537\n",
      "Epoch 8/2000\n",
      " - 26s - loss: 0.3324 - mse: 0.3170 - val_loss: 0.3541 - val_mse: 0.3541\n",
      "Epoch 9/2000\n",
      " - 29s - loss: 0.3301 - mse: 0.3148 - val_loss: 0.3543 - val_mse: 0.3543\n",
      "Epoch 10/2000\n",
      " - 28s - loss: 0.3275 - mse: 0.3123 - val_loss: 0.3568 - val_mse: 0.3568\n",
      "Epoch 11/2000\n",
      " - 22s - loss: 0.3255 - mse: 0.3104 - val_loss: 0.3552 - val_mse: 0.3552\n",
      "Epoch 12/2000\n",
      " - 21s - loss: 0.3230 - mse: 0.3081 - val_loss: 0.3551 - val_mse: 0.3551\n",
      "Epoch 13/2000\n",
      " - 21s - loss: 0.3212 - mse: 0.3064 - val_loss: 0.3577 - val_mse: 0.3577\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 14/2000\n",
      " - 20s - loss: 0.3107 - mse: 0.2967 - val_loss: 0.3533 - val_mse: 0.3533\n",
      "Epoch 15/2000\n",
      " - 20s - loss: 0.3072 - mse: 0.2934 - val_loss: 0.3539 - val_mse: 0.3539\n",
      "Epoch 16/2000\n",
      " - 20s - loss: 0.3059 - mse: 0.2923 - val_loss: 0.3547 - val_mse: 0.3547\n",
      "==================================================\n",
      "Step 10\n",
      "==================================================\n",
      "Train on 670060 samples, validate on 167515 samples\n",
      "Epoch 1/2000\n",
      " - 21s - loss: 0.5798 - mse: 0.5454 - val_loss: 0.4385 - val_mse: 0.4385\n",
      "Epoch 2/2000\n",
      " - 20s - loss: 0.3901 - mse: 0.3685 - val_loss: 0.3906 - val_mse: 0.3906\n",
      "Epoch 3/2000\n",
      " - 21s - loss: 0.3717 - mse: 0.3513 - val_loss: 0.3764 - val_mse: 0.3764\n",
      "Epoch 4/2000\n",
      " - 25s - loss: 0.3625 - mse: 0.3427 - val_loss: 0.3720 - val_mse: 0.3720\n",
      "Epoch 5/2000\n",
      " - 30s - loss: 0.3561 - mse: 0.3368 - val_loss: 0.3708 - val_mse: 0.3708\n",
      "Epoch 6/2000\n",
      " - 35s - loss: 0.3514 - mse: 0.3324 - val_loss: 0.3711 - val_mse: 0.3711\n",
      "Epoch 7/2000\n",
      " - 22s - loss: 0.3478 - mse: 0.3291 - val_loss: 0.3733 - val_mse: 0.3733\n",
      "Epoch 8/2000\n",
      " - 23s - loss: 0.3445 - mse: 0.3260 - val_loss: 0.3693 - val_mse: 0.3693\n",
      "Epoch 9/2000\n",
      " - 21s - loss: 0.3416 - mse: 0.3233 - val_loss: 0.3708 - val_mse: 0.3708\n",
      "Epoch 10/2000\n",
      " - 22s - loss: 0.3388 - mse: 0.3208 - val_loss: 0.3721 - val_mse: 0.3721\n",
      "Epoch 11/2000\n",
      " - 21s - loss: 0.3365 - mse: 0.3186 - val_loss: 0.3709 - val_mse: 0.3709\n",
      "Epoch 12/2000\n",
      " - 22s - loss: 0.3343 - mse: 0.3166 - val_loss: 0.3722 - val_mse: 0.3722\n",
      "Epoch 13/2000\n",
      " - 22s - loss: 0.3323 - mse: 0.3147 - val_loss: 0.3718 - val_mse: 0.3718\n",
      "Epoch 14/2000\n",
      " - 23s - loss: 0.3304 - mse: 0.3129 - val_loss: 0.3734 - val_mse: 0.3734\n",
      "Epoch 15/2000\n",
      " - 21s - loss: 0.3287 - mse: 0.3114 - val_loss: 0.3754 - val_mse: 0.3754\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 16/2000\n",
      " - 22s - loss: 0.3176 - mse: 0.3011 - val_loss: 0.3727 - val_mse: 0.3727\n",
      "Epoch 17/2000\n",
      " - 22s - loss: 0.3134 - mse: 0.2972 - val_loss: 0.3735 - val_mse: 0.3735\n",
      "Epoch 18/2000\n",
      " - 22s - loss: 0.3119 - mse: 0.2958 - val_loss: 0.3735 - val_mse: 0.3735\n",
      "==================================================\n",
      "Step 11\n",
      "==================================================\n",
      "Train on 670060 samples, validate on 167515 samples\n",
      "Epoch 1/2000\n",
      " - 25s - loss: 0.4740 - mse: 0.4471 - val_loss: 0.4333 - val_mse: 0.4333\n",
      "Epoch 2/2000\n",
      " - 22s - loss: 0.3791 - mse: 0.3595 - val_loss: 0.3771 - val_mse: 0.3771\n",
      "Epoch 3/2000\n",
      " - 21s - loss: 0.3635 - mse: 0.3452 - val_loss: 0.3669 - val_mse: 0.3669\n",
      "Epoch 4/2000\n",
      " - 21s - loss: 0.3550 - mse: 0.3374 - val_loss: 0.3635 - val_mse: 0.3635\n",
      "Epoch 5/2000\n",
      " - 21s - loss: 0.3497 - mse: 0.3325 - val_loss: 0.3616 - val_mse: 0.3616\n",
      "Epoch 6/2000\n",
      " - 21s - loss: 0.3456 - mse: 0.3288 - val_loss: 0.3630 - val_mse: 0.3630\n",
      "Epoch 7/2000\n",
      " - 25s - loss: 0.3420 - mse: 0.3254 - val_loss: 0.3645 - val_mse: 0.3645\n",
      "Epoch 8/2000\n",
      " - 20s - loss: 0.3390 - mse: 0.3226 - val_loss: 0.3633 - val_mse: 0.3633\n",
      "Epoch 9/2000\n",
      " - 19s - loss: 0.3355 - mse: 0.3193 - val_loss: 0.3658 - val_mse: 0.3658\n",
      "Epoch 10/2000\n",
      " - 20s - loss: 0.3332 - mse: 0.3172 - val_loss: 0.3660 - val_mse: 0.3660\n",
      "Epoch 11/2000\n",
      " - 20s - loss: 0.3307 - mse: 0.3148 - val_loss: 0.3649 - val_mse: 0.3649\n",
      "Epoch 12/2000\n",
      " - 19s - loss: 0.3285 - mse: 0.3128 - val_loss: 0.3691 - val_mse: 0.3691\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 13/2000\n",
      " - 20s - loss: 0.3170 - mse: 0.3021 - val_loss: 0.3656 - val_mse: 0.3656\n",
      "Epoch 14/2000\n",
      " - 19s - loss: 0.3129 - mse: 0.2983 - val_loss: 0.3671 - val_mse: 0.3671\n",
      "Epoch 15/2000\n",
      " - 19s - loss: 0.3110 - mse: 0.2965 - val_loss: 0.3685 - val_mse: 0.3685\n",
      "==================================================\n",
      "Step 12\n",
      "==================================================\n",
      "Train on 670060 samples, validate on 167515 samples\n",
      "Epoch 1/2000\n",
      " - 36s - loss: 0.5439 - mse: 0.5138 - val_loss: 0.4777 - val_mse: 0.4777\n",
      "Epoch 2/2000\n",
      " - 28s - loss: 0.4192 - mse: 0.3968 - val_loss: 0.4212 - val_mse: 0.4212\n",
      "Epoch 3/2000\n",
      " - 28s - loss: 0.4029 - mse: 0.3816 - val_loss: 0.4140 - val_mse: 0.4140\n",
      "Epoch 4/2000\n",
      " - 28s - loss: 0.3936 - mse: 0.3730 - val_loss: 0.4045 - val_mse: 0.4045\n",
      "Epoch 5/2000\n",
      " - 45s - loss: 0.3865 - mse: 0.3664 - val_loss: 0.3994 - val_mse: 0.3994\n",
      "Epoch 6/2000\n",
      " - 41s - loss: 0.3811 - mse: 0.3614 - val_loss: 0.3989 - val_mse: 0.3989\n",
      "Epoch 7/2000\n",
      " - 58s - loss: 0.3765 - mse: 0.3571 - val_loss: 0.3968 - val_mse: 0.3968\n",
      "Epoch 8/2000\n",
      " - 47s - loss: 0.3725 - mse: 0.3534 - val_loss: 0.4004 - val_mse: 0.4004\n",
      "Epoch 9/2000\n",
      " - 57s - loss: 0.3691 - mse: 0.3502 - val_loss: 0.4008 - val_mse: 0.4008\n",
      "Epoch 10/2000\n",
      " - 49s - loss: 0.3662 - mse: 0.3474 - val_loss: 0.4017 - val_mse: 0.4017\n",
      "Epoch 11/2000\n",
      " - 65s - loss: 0.3628 - mse: 0.3443 - val_loss: 0.4063 - val_mse: 0.4063\n",
      "Epoch 12/2000\n",
      " - 64s - loss: 0.3604 - mse: 0.3420 - val_loss: 0.4038 - val_mse: 0.4038\n",
      "Epoch 13/2000\n",
      " - 69s - loss: 0.3579 - mse: 0.3397 - val_loss: 0.4095 - val_mse: 0.4095\n",
      "Epoch 14/2000\n",
      " - 69s - loss: 0.3551 - mse: 0.3371 - val_loss: 0.4066 - val_mse: 0.4066\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 15/2000\n",
      " - 58s - loss: 0.3414 - mse: 0.3245 - val_loss: 0.4017 - val_mse: 0.4017\n",
      "Epoch 16/2000\n",
      " - 66s - loss: 0.3367 - mse: 0.3200 - val_loss: 0.4038 - val_mse: 0.4038\n",
      "Epoch 17/2000\n",
      " - 72s - loss: 0.3347 - mse: 0.3182 - val_loss: 0.4060 - val_mse: 0.4060\n",
      "==================================================\n",
      "Step 13\n",
      "==================================================\n",
      "Train on 670060 samples, validate on 167515 samples\n",
      "Epoch 1/2000\n",
      " - 135s - loss: 0.5531 - mse: 0.5227 - val_loss: 0.4458 - val_mse: 0.4458\n",
      "Epoch 2/2000\n",
      " - 133s - loss: 0.4321 - mse: 0.4089 - val_loss: 0.4218 - val_mse: 0.4218\n",
      "Epoch 3/2000\n",
      " - 135s - loss: 0.4132 - mse: 0.3914 - val_loss: 0.4150 - val_mse: 0.4150\n",
      "Epoch 4/2000\n",
      " - 116s - loss: 0.4021 - mse: 0.3811 - val_loss: 0.4117 - val_mse: 0.4117\n",
      "Epoch 5/2000\n",
      " - 90s - loss: 0.3941 - mse: 0.3737 - val_loss: 0.4098 - val_mse: 0.4098\n",
      "Epoch 6/2000\n",
      " - 111s - loss: 0.3877 - mse: 0.3678 - val_loss: 0.4099 - val_mse: 0.4099\n",
      "Epoch 7/2000\n",
      " - 125s - loss: 0.3827 - mse: 0.3632 - val_loss: 0.4092 - val_mse: 0.4092\n",
      "Epoch 8/2000\n",
      " - 117s - loss: 0.3785 - mse: 0.3592 - val_loss: 0.4139 - val_mse: 0.4139\n",
      "Epoch 9/2000\n",
      " - 117s - loss: 0.3745 - mse: 0.3555 - val_loss: 0.4106 - val_mse: 0.4106\n",
      "Epoch 10/2000\n",
      " - 130s - loss: 0.3714 - mse: 0.3527 - val_loss: 0.4168 - val_mse: 0.4168\n",
      "Epoch 11/2000\n",
      " - 121s - loss: 0.3679 - mse: 0.3494 - val_loss: 0.4167 - val_mse: 0.4167\n",
      "Epoch 12/2000\n",
      " - 136s - loss: 0.3651 - mse: 0.3467 - val_loss: 0.4181 - val_mse: 0.4181\n",
      "Epoch 13/2000\n",
      " - 133s - loss: 0.3625 - mse: 0.3443 - val_loss: 0.4169 - val_mse: 0.4169\n",
      "Epoch 14/2000\n",
      " - 134s - loss: 0.3598 - mse: 0.3419 - val_loss: 0.4319 - val_mse: 0.4319\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 15/2000\n",
      " - 134s - loss: 0.3458 - mse: 0.3288 - val_loss: 0.4150 - val_mse: 0.4150\n",
      "Epoch 16/2000\n",
      " - 137s - loss: 0.3409 - mse: 0.3243 - val_loss: 0.4162 - val_mse: 0.4162\n",
      "Epoch 17/2000\n",
      " - 130s - loss: 0.3388 - mse: 0.3223 - val_loss: 0.4187 - val_mse: 0.4187\n",
      "==================================================\n",
      "Step 14\n",
      "==================================================\n",
      "Train on 670060 samples, validate on 167515 samples\n",
      "Epoch 1/2000\n",
      " - 95s - loss: 0.5466 - mse: 0.5147 - val_loss: 0.4977 - val_mse: 0.4977\n",
      "Epoch 2/2000\n",
      " - 107s - loss: 0.4131 - mse: 0.3898 - val_loss: 0.4241 - val_mse: 0.4241\n",
      "Epoch 3/2000\n",
      " - 109s - loss: 0.3984 - mse: 0.3761 - val_loss: 0.4071 - val_mse: 0.4071\n",
      "Epoch 4/2000\n",
      " - 118s - loss: 0.3897 - mse: 0.3681 - val_loss: 0.4061 - val_mse: 0.4061\n",
      "Epoch 5/2000\n",
      " - 121s - loss: 0.3839 - mse: 0.3627 - val_loss: 0.4037 - val_mse: 0.4037\n",
      "Epoch 6/2000\n",
      " - 122s - loss: 0.3791 - mse: 0.3583 - val_loss: 0.4026 - val_mse: 0.4026\n",
      "Epoch 7/2000\n",
      " - 119s - loss: 0.3752 - mse: 0.3547 - val_loss: 0.4068 - val_mse: 0.4068\n",
      "Epoch 8/2000\n",
      " - 97s - loss: 0.3714 - mse: 0.3512 - val_loss: 0.4059 - val_mse: 0.4059\n",
      "Epoch 9/2000\n",
      " - 96s - loss: 0.3686 - mse: 0.3485 - val_loss: 0.4055 - val_mse: 0.4055\n",
      "Epoch 10/2000\n",
      " - 97s - loss: 0.3656 - mse: 0.3457 - val_loss: 0.4063 - val_mse: 0.4063\n",
      "Epoch 11/2000\n",
      " - 106s - loss: 0.3631 - mse: 0.3434 - val_loss: 0.4081 - val_mse: 0.4081\n",
      "Epoch 12/2000\n",
      " - 21s - loss: 0.3604 - mse: 0.3410 - val_loss: 0.4071 - val_mse: 0.4071\n",
      "Epoch 13/2000\n",
      " - 83s - loss: 0.3581 - mse: 0.3387 - val_loss: 0.4089 - val_mse: 0.4089\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 14/2000\n",
      " - 75s - loss: 0.3462 - mse: 0.3278 - val_loss: 0.4069 - val_mse: 0.4069\n",
      "Epoch 15/2000\n",
      " - 77s - loss: 0.3418 - mse: 0.3238 - val_loss: 0.4077 - val_mse: 0.4077\n",
      "Epoch 16/2000\n",
      " - 89s - loss: 0.3401 - mse: 0.3222 - val_loss: 0.4088 - val_mse: 0.4088\n",
      "==================================================\n",
      "Step 15\n",
      "==================================================\n",
      "Train on 670060 samples, validate on 167515 samples\n",
      "Epoch 1/2000\n",
      " - 28s - loss: 0.5211 - mse: 0.4911 - val_loss: 0.4526 - val_mse: 0.4526\n",
      "Epoch 2/2000\n",
      " - 28s - loss: 0.4011 - mse: 0.3790 - val_loss: 0.4099 - val_mse: 0.4099\n",
      "Epoch 3/2000\n",
      " - 26s - loss: 0.3858 - mse: 0.3648 - val_loss: 0.3992 - val_mse: 0.3992\n",
      "Epoch 4/2000\n",
      " - 28s - loss: 0.3773 - mse: 0.3570 - val_loss: 0.3949 - val_mse: 0.3949\n",
      "Epoch 5/2000\n",
      " - 26s - loss: 0.3715 - mse: 0.3516 - val_loss: 0.3919 - val_mse: 0.3919\n",
      "Epoch 6/2000\n",
      " - 23s - loss: 0.3674 - mse: 0.3477 - val_loss: 0.3937 - val_mse: 0.3937\n",
      "Epoch 7/2000\n",
      " - 28s - loss: 0.3636 - mse: 0.3442 - val_loss: 0.3909 - val_mse: 0.3909\n",
      "Epoch 8/2000\n",
      " - 32s - loss: 0.3599 - mse: 0.3408 - val_loss: 0.3909 - val_mse: 0.3909\n",
      "Epoch 9/2000\n",
      " - 26s - loss: 0.3570 - mse: 0.3381 - val_loss: 0.3961 - val_mse: 0.3961\n",
      "Epoch 10/2000\n",
      " - 31s - loss: 0.3547 - mse: 0.3359 - val_loss: 0.3937 - val_mse: 0.3937\n",
      "Epoch 11/2000\n",
      " - 23s - loss: 0.3515 - mse: 0.3330 - val_loss: 0.3941 - val_mse: 0.3941\n",
      "Epoch 12/2000\n",
      " - 28s - loss: 0.3493 - mse: 0.3310 - val_loss: 0.3941 - val_mse: 0.3941\n",
      "Epoch 13/2000\n",
      " - 30s - loss: 0.3472 - mse: 0.3290 - val_loss: 0.3961 - val_mse: 0.3961\n",
      "Epoch 14/2000\n",
      " - 26s - loss: 0.3447 - mse: 0.3266 - val_loss: 0.4008 - val_mse: 0.4008\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 15/2000\n",
      " - 33s - loss: 0.3324 - mse: 0.3152 - val_loss: 0.3958 - val_mse: 0.3958\n",
      "Epoch 16/2000\n",
      " - 24s - loss: 0.3278 - mse: 0.3110 - val_loss: 0.3967 - val_mse: 0.3967\n",
      "Epoch 17/2000\n",
      " - 26s - loss: 0.3261 - mse: 0.3095 - val_loss: 0.3985 - val_mse: 0.3985\n",
      "Epoch 18/2000\n",
      " - 28s - loss: 0.3248 - mse: 0.3082 - val_loss: 0.3989 - val_mse: 0.3989\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 2000\n",
    "\n",
    "val_pred = []\n",
    "test_pred = []\n",
    "# wtpath = 'weights.hdf5'  # To save best epoch. But need Keras bug to be fixed first.\n",
    "sample_weights=np.array( pd.concat([items[\"perishable\"]] * num_days) * 0.25 + 1 )\n",
    "for i in range(15):\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Step %d\" % (i+1))\n",
    "    print(\"=\" * 50)\n",
    "    y = y_train[:, i]\n",
    "    y_mean = y.mean()\n",
    "    xv = X_val\n",
    "    yv = y_val[:, i]\n",
    "    model = build_model()\n",
    "\n",
    "    opt = optimizers.Adam(lr=0.001)\n",
    "#     opt = optimizers.RMSprop(learning_rate=0.001, rho=0.9)\n",
    "    model.compile(loss='mse', optimizer=opt, metrics=['mse'])\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=10, verbose=0),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=7, verbose=1, min_delta=1e-4, mode='min')\n",
    "        ]\n",
    "    \n",
    "    #smaller batch size runs faster\n",
    "    #batch_size = 65536\n",
    "    batch_size = 8192\n",
    "\n",
    "    model.fit(X_train, y - y_mean, batch_size = batch_size, epochs = N_EPOCHS, verbose=2,\n",
    "               sample_weight=sample_weights, validation_data=(xv,yv-y_mean), callbacks=callbacks )\n",
    "    val_pred.append(model.predict(X_val)+y_mean)\n",
    "    test_pred.append(model.predict(X_test)+y_mean)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nwrmsle = 0.6099957913412681\n"
     ]
    }
   ],
   "source": [
    "weight = items[\"perishable\"] * 0.25 + 1\n",
    "val_err = (y_val - np.array(val_pred).squeeze(axis=2).transpose())**2\n",
    "val_err = val_err.sum(axis=1) * weight\n",
    "#change to 15 days\n",
    "val_err = np.sqrt(val_err.sum() / weight.sum() / 15)\n",
    "print('nwrmsle = {}'.format(val_err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nwrmsle = 0.6223143411577241\n"
     ]
    }
   ],
   "source": [
    "test_err = (y_test - np.array(test_pred).squeeze(axis=2).transpose())**2\n",
    "test_err = test_err.sum(axis=1) * weight\n",
    "#change to 15 days\n",
    "test_err = np.sqrt(test_err.sum() / weight.sum() / 15)\n",
    "print('nwrmsle = {}'.format(test_err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2017_index = pd.read_csv('../derived_datasets/df_2017_index.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2017_index = df_2017_index.set_index([0,1]).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2017_index.rename(['store_nbr','item_nbr'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_test = pd.DataFrame(np.array(test_pred).squeeze(axis=2).transpose(), \n",
    "                            index = df_2017_index, columns = pd.date_range('2017-08-01',periods=15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_test.to_csv('../derived_datasets/nn_test_pred_model_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
